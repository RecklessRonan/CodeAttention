0	def print_summary ( status ) status_string = status . to_s . humanize . upcase if status == :success heading ( "Result: " , status_string , :green ) level = :info elsif status == :timed_out heading ( "Result: " , status_string , :yellow ) level = :fatal else heading ( "Result: " , status_string , :red ) level = :fatal end if ( actions_sentence = summary . actions_sentence . presence ) public_send ( level , actions_sentence ) blank_line ( level ) end summary . paragraphs . each do | para | msg_lines = para . split ( "\n" ) msg_lines . each { | line | public_send ( level , line ) } blank_line ( level ) unless para == summary . paragraphs . last end end
1	def find_bad_files_from_kubectl_output ( line ) line . scan ( %r{ \S \. \S } ) . each_with_object ( [ ] ) do | matches , bad_files | matches . each do | path | content = File . read ( path ) if File . file? ( path ) bad_files << { filename : File . basename ( path ) , err : line , content : content } end end end
2	def confirm_ejson_keys_not_prunable secret = ejson_provisioner . ejson_keys_secret return unless secret . dig ( "metadata" , "annotations" , KubernetesResource :: LAST_APPLIED_ANNOTATION ) @logger . error ( "Deploy cannot proceed because protected resource " "Secret/#{EjsonSecretProvisioner::EJSON_KEYS_SECRET} would be pruned." ) raise EjsonPrunableError rescue Kubectl :: ResourceNotFoundError => e @logger . debug ( "Secret/#{EjsonSecretProvisioner::EJSON_KEYS_SECRET} does not exist: #{e}" ) end
3	def for_current_system ( compressors ) family = Ohai [ "platform_family" ] if family == "mac_os_x" if compressors . include? ( :dmg ) return DMG end if compressors . include? ( :tgz ) return TGZ end end if compressors . include? ( :tgz ) return TGZ else log . info ( log_key ) { "No compressor defined for `#{family}'." } return Null end end
4	def create_bff_file shellout! ( "sudo chown -Rh 0:0 #{File.join(staging_dir, project.install_dir.match(/^\/?(\w+)/).to_s)}" ) log . info ( log_key ) { "Creating .bff file" } shellout! ( "sudo /usr/sbin/mkinstallp -d #{staging_dir} -T #{File.join(staging_dir, 'gen.template')}" ) log . debug ( log_key ) do "With .inventory file of:\n" + File . read ( "#{File.join( staging_dir, '.info', "#{safe_base_package_name}.inventory" )}" ) end FileSyncer . glob ( File . join ( staging_dir , "tmp/*.bff" ) ) . each do | bff | copy_file ( bff , File . join ( Config . package_dir , create_bff_file_name ) ) end ensure original_uid = shellout! ( "id -u" ) . stdout . chomp original_gid = shellout! ( "id -g" ) . stdout . chomp shellout! ( "sudo chown -Rh #{original_uid}:#{original_gid} #{staging_dir}" ) end
5	def glob ( pattern ) pattern = Pathname . new ( pattern ) . cleanpath . to_s Dir . glob ( pattern , File :: FNM_DOTMATCH ) . sort . reject do | file | basename = File . basename ( file ) IGNORED_FILES . include? ( basename ) end end
6	def sync ( source , destination , options = { } ) unless File . directory? ( source ) raise ArgumentError , "`source' must be a directory, but was a " "`#{File.ftype(source)}'! If you just want to sync a file, use " "the `copy' method instead." end source_files = all_files_under ( source , options ) FileUtils . mkdir_p ( destination ) unless File . directory? ( destination ) source_files . each do | source_file | relative_path = relative_path_for ( source_file , source ) parent = File . join ( destination , File . dirname ( relative_path ) ) FileUtils . mkdir_p ( parent ) unless File . directory? ( parent ) case File . ftype ( source_file ) . to_sym when :directory FileUtils . mkdir_p ( "#{destination}/#{relative_path}" ) when :link target = File . readlink ( source_file ) Dir . chdir ( destination ) do FileUtils . ln_sf ( target , "#{destination}/#{relative_path}" ) end when :file source_stat = File . stat ( source_file ) if hardlink? source_stat if existing = hardlink_sources [ [ source_stat . dev , source_stat . ino ] ] FileUtils . ln ( existing , "#{destination}/#{relative_path}" , force : true ) else begin FileUtils . cp ( source_file , "#{destination}/#{relative_path}" ) rescue Errno :: EACCES FileUtils . cp_r ( source_file , "#{destination}/#{relative_path}" , remove_destination : true ) end hardlink_sources . store ( [ source_stat . dev , source_stat . ino ] , "#{destination}/#{relative_path}" ) end else begin FileUtils . cp ( source_file , "#{destination}/#{relative_path}" ) rescue Errno :: EACCES FileUtils . cp_r ( source_file , "#{destination}/#{relative_path}" , remove_destination : true ) end end else raise "Unknown file type: `File.ftype(source_file)' at `#{source_file}'!" end end destination_files = glob ( "#{destination}/**/*" ) relative_source_files = source_files . map do | file | relative_path_for ( file , source ) end relative_destination_files = destination_files . map do | file | relative_path_for ( file , destination ) end extra_files = relative_destination_files - relative_source_files extra_files . each do | file | FileUtils . rm_rf ( File . join ( destination , file ) ) end true end
7	def relative_path_for ( path , parent ) Pathname . new ( path ) . relative_path_from ( Pathname . new ( parent ) ) . to_s end
8	def clean_disks log . info ( log_key ) { "Cleaning previously mounted disks" } existing_disks = shellout! ( "mount | grep \"/Volumes/#{volume_name}\" | awk '{print $1}'" ) existing_disks . stdout . lines . each do | existing_disk | existing_disk . chomp! Omnibus . logger . debug ( log_key ) do "Detaching disk `#{existing_disk}' before starting dmg packaging." end shellout! ( "hdiutil detach '#{existing_disk}'" ) end end
9	def copy_assets_to_dmg log . info ( log_key ) { "Copying assets into dmg" } FileSyncer . glob ( "#{resources_dir}/*" ) . each do | file | FileUtils . cp_r ( file , "/Volumes/#{volume_name}" ) end end
10	def write_transform_file render_template ( resource_path ( "doc-transform.erb" ) , destination : transform_file , variables : { pathdir : project . install_dir . split ( "/" ) [ 1 ] , } ) end
11	def write_pkg_metadata render_template ( resource_path ( "gen.manifestfile.erb" ) , destination : pkg_metadata_file , variables : { name : safe_base_package_name , fmri_package_name : fmri_package_name , description : project . description , summary : project . friendly_name , arch : safe_architecture , } ) if symlinks_file File . open ( pkg_metadata_file , "a" ) do | symlink | symlink . write ( render_symlinks ) end end log . debug ( log_key ) { "Rendered Template:\n" + File . read ( pkg_metadata_file ) } end
12	def health_check_otool current_library = nil bad_libs = { } read_shared_libs ( "find #{project.install_dir}/ -type f | egrep '\.(dylib|bundle)$' | xargs otool -L" ) do | line | case line when / / current_library = Regexp . last_match [ 1 ] when / \s \( \) / linked = Regexp . last_match [ 1 ] name = File . basename ( linked ) bad_libs = check_for_bad_library ( bad_libs , current_library , name , linked ) end end bad_libs end
13	def health_check_aix current_library = nil bad_libs = { } read_shared_libs ( "find #{project.install_dir}/ -type f | xargs file | grep \"RISC System\" | awk -F: '{print $1}' | xargs -n 1 ldd" ) do | line | case line when / / current_library = Regexp . last_match [ 1 ] log . debug ( log_key ) { "Analyzing dependencies for #{current_library}" } when / \s / name = Regexp . last_match [ 1 ] linked = Regexp . last_match [ 1 ] bad_libs = check_for_bad_library ( bad_libs , current_library , name , linked ) when / / else log . warn ( log_key ) { "Line did not match for #{current_library}\n#{line}" } end end bad_libs end
14	def health_check_ldd regexp_ends = ".*(" + IGNORED_ENDINGS . map { | e | e . gsub ( / \. / , '\.' ) } . join ( "|" ) + ")$" regexp_patterns = IGNORED_PATTERNS . map { | e | ".*" + e . gsub ( / \/ / , '\/' ) + ".*" } . join ( "|" ) regexp = regexp_ends + "|" + regexp_patterns current_library = nil bad_libs = { } read_shared_libs ( "find #{project.install_dir}/ -type f -regextype posix-extended ! -regex '#{regexp}' | xargs ldd" ) do | line | case line when / / current_library = Regexp . last_match [ 1 ] log . debug ( log_key ) { "Analyzing dependencies for #{current_library}" } when / \s \= \> \s \( \) / name = Regexp . last_match [ 1 ] linked = Regexp . last_match [ 2 ] bad_libs = check_for_bad_library ( bad_libs , current_library , name , linked ) when / \s \( \) / next when / \s / next when / \s / next when / \s / next when / \s / next when / \s / else log . warn ( log_key ) do "Line did not match for #{current_library}\n#{line}" end end end bad_libs end
15	def read_shared_libs ( command ) cmd = shellout ( command ) cmd . stdout . each_line do | line | yield line end end
16	def check_for_bad_library ( bad_libs , current_library , name , linked ) safe = nil whitelist_libs = case Ohai [ "platform" ] when "arch" ARCH_WHITELIST_LIBS when "mac_os_x" MAC_WHITELIST_LIBS when "solaris2" SOLARIS_WHITELIST_LIBS when "smartos" SMARTOS_WHITELIST_LIBS when "freebsd" FREEBSD_WHITELIST_LIBS when "aix" AIX_WHITELIST_LIBS else WHITELIST_LIBS end whitelist_libs . each do | reg | safe ||= true if reg . match ( name ) end whitelist_files . each do | reg | safe ||= true if reg . match ( current_library ) end log . debug ( log_key ) { " } log . debug ( log_key ) { " } if ! safe && linked !~ Regexp . new ( project . install_dir ) log . debug ( log_key ) { " -> FAILED: #{current_library} has unsafe dependencies" } bad_libs [ current_library ] ||= { } bad_libs [ current_library ] [ name ] ||= { } if bad_libs [ current_library ] [ name ] . key? ( linked ) bad_libs [ current_library ] [ name ] [ linked ] += 1 else bad_libs [ current_library ] [ name ] [ linked ] = 1 end else log . debug ( log_key ) { " -> PASSED: #{name} is either whitelisted or safely provided." } end bad_libs end
17	def digest ( path , type = :md5 ) digest = digest_from_type ( type ) update_with_file_contents ( digest , path ) digest . hexdigest end
18	def update_with_file_contents ( digest , filename ) File . open ( filename ) do | io | while ( chunk = io . read ( 1024 * 8 ) ) digest . update ( chunk ) end end end
19	def packages @packages ||= begin publish_packages = Array . new build_packages = FileSyncer . glob ( @pattern ) . map { | path | Package . new ( path ) } if @options [ :platform_mappings ] @options [ :platform_mappings ] . each_pair do | build_platform , publish_platforms | build_platform , build_platform_version = build_platform . rpartition ( "-" ) - %w{ - } packages = build_packages . select do | p | p . metadata [ :platform ] == build_platform && p . metadata [ :platform_version ] == build_platform_version end if packages . empty? log . warn ( log_key ) do "Could not locate a package for build platform #{build_platform}-#{build_platform_version}. " "Publishing will be skipped for: #{publish_platforms.join(', ')}" end end publish_platforms . each do | publish_platform | publish_platform , publish_platform_version = publish_platform . rpartition ( "-" ) - %w{ - } packages . each do | p | publish_package = p . dup publish_metadata = p . metadata . dup . to_hash publish_metadata [ :platform ] = publish_platform publish_metadata [ :platform_version ] = publish_platform_version publish_package . metadata = Metadata . new ( publish_package , publish_metadata ) publish_packages << publish_package end end end else publish_packages . concat ( build_packages ) end if publish_packages . empty? log . info ( log_key ) { "No packages found, skipping publish" } end publish_packages end end
20	def write_distribution_file render_template ( resource_path ( "distribution.xml.erb" ) , destination : "#{staging_dir}/Distribution" , mode : 0600 , variables : { friendly_name : project . friendly_name , identifier : safe_identifier , version : safe_version , component_pkg : component_pkg , } ) end
21	def artifact_for ( artifact ) md5 = artifact . respond_to? ( :metadata ) ? artifact . metadata [ :md5 ] : digest ( artifact . path , :md5 ) sha1 = artifact . respond_to? ( :metadata ) ? artifact . metadata [ :sha1 ] : digest ( artifact . path , :sha1 ) Artifactory :: Resource :: Artifact . new ( local_path : artifact . path , client : client , checksums : { "md5" => md5 , "sha1" => sha1 , } ) end
22	def build_for ( packages ) metadata = packages . first . metadata name = metadata [ :name ] manifest = if version_manifest = metadata [ :version_manifest ] Manifest . from_hash ( version_manifest ) else Manifest . new ( metadata [ :version ] , nil , metadata [ :license ] ) end log . info ( log_key ) { "Saving build info for #{name}, Build ##{manifest.build_version}" } Artifactory :: Resource :: Build . new ( client : client , name : name , number : manifest . build_version , vcs_revision : manifest . build_git_revision , build_agent : { name : "omnibus" , version : Omnibus :: VERSION , } , modules : [ { id : [ Config . artifactory_base_path . tr ( "/" , "." ) , name , manifest . build_version , ] . join ( ":" ) , artifacts : packages . map do | package | [ { type : File . extname ( package . path ) . split ( "." ) . last , sha1 : package . metadata [ :sha1 ] , md5 : package . metadata [ :md5 ] , name : package . metadata [ :basename ] , } , { type : File . extname ( package . metadata . path ) . split ( "." ) . last , sha1 : digest ( package . metadata . path , :sha1 ) , md5 : digest ( package . metadata . path , :md5 ) , name : File . basename ( package . metadata . path ) , } , ] end . flatten , } , ] ) end
23	def client @client ||= Artifactory :: Client . new ( endpoint : Config . artifactory_endpoint , username : Config . artifactory_username , password : Config . artifactory_password , ssl_pem_file : Config . artifactory_ssl_pem_file , ssl_verify : Config . artifactory_ssl_verify , proxy_username : Config . artifactory_proxy_username , proxy_password : Config . artifactory_proxy_password , proxy_address : Config . artifactory_proxy_address , proxy_port : Config . artifactory_proxy_port ) end
24	def metadata_properties_for ( package ) metadata = { "omnibus.project" => package . metadata [ :name ] , "omnibus.platform" => package . metadata [ :platform ] , "omnibus.platform_version" => package . metadata [ :platform_version ] , "omnibus.architecture" => package . metadata [ :arch ] , "omnibus.version" => package . metadata [ :version ] , "omnibus.iteration" => package . metadata [ :iteration ] , "omnibus.license" => package . metadata [ :license ] , "omnibus.md5" => package . metadata [ :md5 ] , "omnibus.sha1" => package . metadata [ :sha1 ] , "omnibus.sha256" => package . metadata [ :sha256 ] , "omnibus.sha512" => package . metadata [ :sha512 ] , "md5" => package . metadata [ :md5 ] , "sha1" => package . metadata [ :sha1 ] , "sha256" => package . metadata [ :sha256 ] , "sha512" => package . metadata [ :sha512 ] , } . tap do | h | if build_record? h [ "build.name" ] = package . metadata [ :name ] h [ "build.number" ] = package . metadata [ :version ] end end metadata end
25	def remote_path_for ( package ) File . join ( Config . artifactory_base_path , Config . artifactory_publish_pattern % package . metadata ) end
26	def parameters ( val = NULL ) if null? ( val ) @parameters || { } else unless val . is_a? ( Hash ) raise InvalidValue . new ( :parameters , "be a Hash" ) end @parameters = val end end
27	def wix_light_extension ( extension ) unless extension . is_a? ( String ) raise InvalidValue . new ( :wix_light_extension , "be an String" ) end wix_light_extensions << extension end
28	def wix_light_delay_validation ( val = false ) unless val . is_a? ( TrueClass ) || val . is_a? ( FalseClass ) raise InvalidValue . new ( :iwix_light_delay_validation , "be TrueClass or FalseClass" ) end @delay_validation ||= val unless @delay_validation return "" end "-sval" end
29	def wix_candle_extension ( extension ) unless extension . is_a? ( String ) raise InvalidValue . new ( :wix_candle_extension , "be an String" ) end wix_candle_extensions << extension end
30	def write_localization_file render_template ( resource_path ( "localization-#{localization}.wxl.erb" ) , destination : "#{staging_dir}/localization-#{localization}.wxl" , variables : { name : project . package_name , friendly_name : project . friendly_name , maintainer : project . maintainer , } ) end
31	def write_parameters_file render_template ( resource_path ( "parameters.wxi.erb" ) , destination : "#{staging_dir}/parameters.wxi" , variables : { name : project . package_name , friendly_name : project . friendly_name , maintainer : project . maintainer , upgrade_code : upgrade_code , parameters : parameters , version : windows_package_version , display_version : msi_display_version , } ) end
32	def write_source_file paths = [ ] install_dir = project . install_dir . split ( "/" ) [ 1 .. - 1 ] . join ( "/" ) Pathname . new ( install_dir ) . ascend do | path | paths << path . to_s end hierarchy = paths . reverse . inject ( { } ) do | hash , path | hash [ File . basename ( path ) ] = path . gsub ( / / , "" ) . upcase + "LOCATION" hash end hierarchy [ hierarchy . keys . last ] = "PROJECTLOCATION" wix_install_dir = if hierarchy . size > 1 hierarchy . to_a [ - 2 ] [ 1 ] else "WINDOWSVOLUME" end render_template ( resource_path ( "source.wxs.erb" ) , destination : "#{staging_dir}/source.wxs" , variables : { name : project . package_name , friendly_name : project . friendly_name , maintainer : project . maintainer , hierarchy : hierarchy , fastmsi : fast_msi , wix_install_dir : wix_install_dir , } ) end
33	def write_bundle_file render_template ( resource_path ( "bundle.wxs.erb" ) , destination : "#{staging_dir}/bundle.wxs" , variables : { name : project . package_name , friendly_name : project . friendly_name , maintainer : project . maintainer , upgrade_code : upgrade_code , parameters : parameters , version : windows_package_version , display_version : msi_display_version , msi : windows_safe_path ( Config . package_dir , msi_name ) , } ) end
34	def resolve ( dependency ) if from_dependency? && version_dependency == dependency . name construct_build_version ( dependency ) log . info ( log_key ) { "Build Version is set to '#{build_version}'" } end end
35	def maybe_append_timestamp ( version ) if Config . append_timestamp && ! has_timestamp? ( version ) [ version , Omnibus :: BuildVersion . build_start_time ] . join ( "+" ) else version end end
36	def has_timestamp? ( version ) _ver , build_info = version . split ( "+" ) return false if build_info . nil? build_info . split ( "." ) . any? do | part | begin Time . strptime ( part , Omnibus :: BuildVersion :: TIMESTAMP_FORMAT ) true rescue ArgumentError false end end end
37	def construct_build_version ( version_source = nil ) case source_type when :git version = if version_source Omnibus :: BuildVersion . new ( version_source . project_dir ) else Omnibus :: BuildVersion . new end output = output_method || :semver self . build_version = version . send ( output ) when :version if version_source self . build_version = version_source . version else raise "Please tell me the source to get the version from" end else raise "I don't know how to construct a build_version using source '#{source_type}'" end end
38	def render_template_content ( source , variables = { } ) template = ERB . new ( File . read ( source ) , nil , "-" ) struct = if variables . empty? Struct . new ( "Empty" ) else Struct . new ( * variables . keys ) . new ( * variables . values ) end template . result ( struct . instance_eval { binding } ) end
39	def deprecated ( progname , & block ) meta = Proc . new { "DEPRECATED: #{yield}" } add ( LEVELS . index ( "WARN" ) , progname , & meta ) end
40	def add ( severity , progname , & block ) return true if io . nil? || severity < level message = format_message ( severity , progname , yield ) MUTEX . synchronize { io . write ( message ) } true end
41	def command ( command , options = { } ) warn_for_shell_commands ( command ) build_commands << BuildCommand . new ( "Execute: `#{command}'" ) do shellout! ( command , options ) end end
42	def make ( * args ) options = args . last . is_a? ( Hash ) ? args . pop : { } make = options . delete ( :bin ) || if ! windows? && Omnibus . which ( "gmake" ) env = options . delete ( :env ) || { } env = { "MAKE" => "gmake" } . merge ( env ) options [ :env ] = env "gmake" else "make" end options [ :in_msys_bash ] = true make_cmd = ( [ make ] + args ) . join ( " " ) . strip command ( make_cmd , options ) end
43	def appbundle ( software_name , lockdir : nil , gem : nil , without : nil , extra_bin_files : nil , ** options ) build_commands << BuildCommand . new ( "appbundle `#{software_name}'" ) do bin_dir = "#{install_dir}/bin" appbundler_bin = embedded_bin ( "appbundler" ) lockdir ||= begin app_software = project . softwares . find do | p | p . name == software_name end if app_software . nil? raise "could not find software definition for #{software_name}, add a dependency to it, or pass a lockdir argument to appbundle command." end app_software . project_dir end command = [ appbundler_bin , "'#{lockdir}'" , "'#{bin_dir}'" ] command << [ "'#{gem}'" ] if gem command << [ "--without" , without . join ( "," ) ] unless without . nil? command << [ "--extra-bin-files" , extra_bin_files . join ( "," ) ] unless extra_bin_files . nil? || extra_bin_files . empty? FileUtils . mkdir_p ( bin_dir ) shellout! ( command . join ( " " ) , options ) end end
44	def rake ( command , options = { } ) build_commands << BuildCommand . new ( "rake `#{command}'" ) do bin = embedded_bin ( "rake" ) shellout! ( "#{bin} #{command}" , options ) end end
45	def touch ( file , options = { } ) build_commands << BuildCommand . new ( "touch `#{file}'" ) do Dir . chdir ( software . project_dir ) do parent = File . dirname ( file ) FileUtils . mkdir_p ( parent ) unless File . directory? ( parent ) FileUtils . touch ( file , options ) end end end
46	def delete ( path , options = { } ) build_commands << BuildCommand . new ( "delete `#{path}'" ) do Dir . chdir ( software . project_dir ) do FileSyncer . glob ( path ) . each do | file | FileUtils . rm_rf ( file , options ) end end end end
47	def copy ( source , destination , options = { } ) command = "copy `#{source}' to `#{destination}'" build_commands << BuildCommand . new ( command ) do Dir . chdir ( software . project_dir ) do files = FileSyncer . glob ( source ) if files . empty? log . warn ( log_key ) { "no matched files for glob #{command}" } else files . each do | file | FileUtils . cp_r ( file , destination , options ) end end end end end
48	def update_config_guess ( target : "." , install : [ :config_guess , :config_sub ] ) build_commands << BuildCommand . new ( "update_config_guess `target: #{target} install: #{install.inspect}'" ) do config_guess_dir = "#{install_dir}/embedded/lib/config_guess" %w{ config.guess config.sub } . each do | c | unless File . exist? ( File . join ( config_guess_dir , c ) ) raise "Can not find #{c}. Make sure you add a dependency on 'config_guess' in your software definition" end end destination = File . join ( software . project_dir , target ) FileUtils . mkdir_p ( destination ) FileUtils . cp_r ( "#{config_guess_dir}/config.guess" , destination ) if install . include? :config_guess FileUtils . cp_r ( "#{config_guess_dir}/config.sub" , destination ) if install . include? :config_sub end end
49	def write_tgz contents = gzipped_tarball File . open ( "#{staging_dir}/#{package_name}" , "wb" ) do | tgz | while chunk = contents . read ( 1024 ) tgz . write ( chunk ) end end FileSyncer . glob ( "#{staging_dir}/*.tar.gz" ) . each do | tgz | copy_file ( tgz , Config . package_dir ) end end
50	def tarball tarfile = StringIO . new ( "" ) Gem :: Package :: TarWriter . new ( tarfile ) do | tar | path = "#{staging_dir}/#{packager.package_name}" name = packager . package_name mode = File . stat ( path ) . mode tar . add_file ( name , mode ) do | tf | File . open ( path , "rb" ) do | file | tf . write ( file . read ) end end end tarfile . rewind tarfile end
51	def clean needs_cleaning = File . exist? ( project_dir ) if needs_cleaning log . info ( log_key ) { "Cleaning project directory `#{project_dir}'" } FileUtils . rm_rf ( project_dir ) end create_required_directories deploy needs_cleaning end
52	def deploy if downloaded_file . end_with? ( * ALL_EXTENSIONS ) log . info ( log_key ) { "Extracting `#{safe_downloaded_file}' to `#{safe_project_dir}'" } extract else log . info ( log_key ) { "`#{safe_downloaded_file}' is not an archive - copying to `#{safe_project_dir}'" } if File . directory? ( downloaded_file ) FileUtils . cp_r ( "#{downloaded_file}/." , project_dir ) else FileUtils . cp ( downloaded_file , project_dir ) end end end
53	def extract compression_switch = "" compression_switch = "z" if downloaded_file . end_with? ( "gz" ) compression_switch = "--lzma -" if downloaded_file . end_with? ( "lzma" ) compression_switch = "j" if downloaded_file . end_with? ( "bz2" ) compression_switch = "J" if downloaded_file . end_with? ( "xz" ) if Ohai [ "platform" ] == "windows" if downloaded_file . end_with? ( * TAR_EXTENSIONS ) && source [ :extract ] != :seven_zip returns = [ 0 ] returns << 1 if source [ :extract ] == :lax_tar shellout! ( "tar #{compression_switch}xf #{safe_downloaded_file} -C#{safe_project_dir}" , returns : returns ) elsif downloaded_file . end_with? ( * COMPRESSED_TAR_EXTENSIONS ) Dir . mktmpdir do | temp_dir | log . debug ( log_key ) { "Temporarily extracting `#{safe_downloaded_file}' to `#{temp_dir}'" } shellout! ( "7z.exe x #{safe_downloaded_file} -o#{windows_safe_path(temp_dir)} -r -y" ) fname = File . basename ( downloaded_file , File . extname ( downloaded_file ) ) fname << ".tar" if downloaded_file . end_with? ( "tgz" , "txz" ) next_file = windows_safe_path ( File . join ( temp_dir , fname ) ) log . debug ( log_key ) { "Temporarily extracting `#{next_file}' to `#{safe_project_dir}'" } shellout! ( "7z.exe x #{next_file} -o#{safe_project_dir} -r -y" ) end else shellout! ( "7z.exe x #{safe_downloaded_file} -o#{safe_project_dir} -r -y" ) end elsif downloaded_file . end_with? ( ".7z" ) shellout! ( "7z x #{safe_downloaded_file} -o#{safe_project_dir} -r -y" ) elsif downloaded_file . end_with? ( ".zip" ) shellout! ( "unzip #{safe_downloaded_file} -d #{safe_project_dir}" ) else shellout! ( "#{tar} #{compression_switch}xf #{safe_downloaded_file} -C#{safe_project_dir}" ) end end
54	def digest_type DIGESTS . each do | digest | return digest if source . key? digest end raise ChecksumMissing . new ( self ) end
55	def verify_checksum! log . info ( log_key ) { "Verifying checksum" } expected = checksum actual = digest ( downloaded_file , digest_type ) if expected != actual raise ChecksumMismatch . new ( self , expected , actual ) end end
56	def signing_identity ( thumbprint = NULL , params = NULL ) unless null? ( thumbprint ) @signing_identity = { } unless thumbprint . is_a? ( String ) raise InvalidValue . new ( :signing_identity , "be a String" ) end @signing_identity [ :thumbprint ] = thumbprint if ! null? ( params ) unless params . is_a? ( Hash ) raise InvalidValue . new ( :params , "be a Hash" ) end valid_keys = [ :store , :timestamp_servers , :machine_store , :algorithm ] invalid_keys = params . keys - valid_keys unless invalid_keys . empty? raise InvalidValue . new ( :params , "contain keys from [#{valid_keys.join(', ')}]. " "Found invalid keys [#{invalid_keys.join(', ')}]" ) end if ! params [ :machine_store ] . nil? && ! ( params [ :machine_store ] . is_a? ( TrueClass ) || params [ :machine_store ] . is_a? ( FalseClass ) ) raise InvalidValue . new ( :params , "contain key :machine_store of type TrueClass or FalseClass" ) end else params = { } end @signing_identity [ :store ] = params [ :store ] || "My" @signing_identity [ :algorithm ] = params [ :algorithm ] || "SHA256" servers = params [ :timestamp_servers ] || DEFAULT_TIMESTAMP_SERVERS @signing_identity [ :timestamp_servers ] = [ servers ] . flatten @signing_identity [ :machine_store ] = params [ :machine_store ] || false end @signing_identity end
57	def sign_package ( package_file ) success = false timestamp_servers . each do | ts | success = try_sign ( package_file , ts ) break if success end raise FailedToSignWindowsPackage . new if ! success end
58	def certificate_subject return "CN=#{project.package_name}" unless signing_identity store = machine_store? ? "LocalMachine" : "CurrentUser" cmd = Array . new . tap do | arr | arr << "powershell.exe" arr << "-ExecutionPolicy Bypass" arr << "-NoProfile" arr << "-Command (Get-Item Cert:/#{store}/#{cert_store_name}/#{thumbprint}).Subject" end . join ( " " ) shellout! ( cmd ) . stdout . strip end
59	def manifest_entry @manifest_entry ||= if manifest log . info ( log_key ) { "Using user-supplied manifest entry for #{name}" } manifest . entry_for ( name ) else log . info ( log_key ) { "Resolving manifest entry for #{name}" } to_manifest_entry end end
60	def source ( val = NULL ) unless null? ( val ) unless val . is_a? ( Hash ) raise InvalidValue . new ( :source , "be a kind of `Hash', but was `#{val.class.inspect}'" ) end val = canonicalize_source ( val ) extra_keys = val . keys - [ :git , :file , :path , :url , :md5 , :sha1 , :sha256 , :sha512 , :cookie , :warning , :unsafe , :extract , :cached_name , :authorization , :options , :submodules ] unless extra_keys . empty? raise InvalidValue . new ( :source , "only include valid keys. Invalid keys: #{extra_keys.inspect}" ) end duplicate_keys = val . keys & [ :git , :file , :path , :url ] unless duplicate_keys . size < 2 raise InvalidValue . new ( :source , "not include duplicate keys. Duplicate keys: #{duplicate_keys.inspect}" ) end @source ||= { } @source . merge! ( val ) end override = canonicalize_source ( overrides [ :source ] ) apply_overrides ( :source , override ) end
61	def version ( val = NULL , & block ) final_version = apply_overrides ( :version ) if block_given? if val . equal? ( NULL ) raise InvalidValue . new ( :version , "pass a block when given a version argument" ) else if val == final_version current_license_files = @license_files @license_files = [ ] yield new_license_files = @license_files if new_license_files . empty? @license_files = current_license_files end end end end return if final_version . nil? begin Chef :: Sugar :: Constraints :: Version . new ( final_version ) rescue ArgumentError log . warn ( log_key ) do "Version #{final_version} for software #{name} was not parseable. " "Comparison methods such as #satisfies? will not be available for this version." end final_version end end
62	def whitelist_file ( file ) file = Regexp . new ( file ) unless file . kind_of? ( Regexp ) whitelist_files << file whitelist_files . dup end
63	def project_file if fetcher && fetcher . is_a? ( NetFetcher ) log . deprecated ( log_key ) do "project_file (DSL). This is a property of the NetFetcher and will " "not be publically exposed in the next major release. In general, " "you should not be using this method in your software definitions " "as it is an internal implementation detail of the NetFetcher. If " "you disagree with this statement, you should open an issue on the " "Omnibus repository on GitHub an explain your use case. For now, " "I will return the path to the downloaded file on disk, but please " "rethink the problem you are trying to solve :)." end fetcher . downloaded_file else log . warn ( log_key ) do "Cannot retrieve a `project_file' for software `#{name}'. This " "attribute is actually an internal representation that is unique " "to the NetFetcher class and requires the use of a `source' " "attribute that is declared using a `:url' key. For backwards-" "compatability, I will return `nil', but this is most likely not " "your desired behavior." end nil end end
64	def prepend_path ( * paths ) path_values = Array ( paths ) path_values << ENV [ path_key ] separator = File :: PATH_SEPARATOR || ":" path_values . join ( separator ) end
65	def overrides if null? ( @overrides ) @overrides = { } @overrides = project . overrides [ name . to_sym ] . dup if project . overrides [ name . to_sym ] end @overrides end
66	def version_for_cache @version_for_cache ||= if fetcher . version_for_cache fetcher . version_for_cache elsif version version else log . warn ( log_key ) do "No version given! This is probably a bad thing. I am going to " "assume the version `0.0.0', but that is most certainly not your " "desired behavior. If git caching seems off, this is probably why." end "0.0.0" end end
67	def fetcher @fetcher ||= if source_type == :url && File . basename ( source [ :url ] , "?*" ) . end_with? ( * NetFetcher :: ALL_EXTENSIONS ) Fetcher . fetcher_class_for_source ( source ) . new ( manifest_entry , fetch_dir , build_dir ) else Fetcher . fetcher_class_for_source ( source ) . new ( manifest_entry , project_dir , build_dir ) end end
68	def shasum @shasum ||= begin digest = Digest :: SHA256 . new update_with_string ( digest , project . shasum ) update_with_string ( digest , builder . shasum ) update_with_string ( digest , name ) update_with_string ( digest , version_for_cache ) update_with_string ( digest , FFI_Yajl :: Encoder . encode ( overrides ) ) if filepath && File . exist? ( filepath ) update_with_file_contents ( digest , filepath ) else update_with_string ( digest , "<DYNAMIC>" ) end digest . hexdigest end end
69	def canonicalize_source ( source ) if source . is_a? ( Hash ) && source [ :github ] source = source . dup source [ :git ] = "https://github.com/#{source[:github]}.git" source . delete ( :github ) end source end
70	def write_makeselfinst makeselfinst_staging_path = File . join ( staging_dir , "makeselfinst" ) render_template ( resource_path ( "makeselfinst.erb" ) , destination : makeselfinst_staging_path , variables : { install_dir : project . install_dir , } ) FileUtils . chmod ( 0755 , makeselfinst_staging_path ) end
71	def create_cache_path if File . directory? ( cache_path ) false else create_directory ( File . dirname ( cache_path ) ) git_cmd ( "init -q" ) git_cmd ( "config --local user.name \"Omnibus Git Cache\"" ) git_cmd ( "config --local user.email \"omnibus@localhost\"" ) true end end
72	def tag return @tag if @tag log . internal ( log_key ) { "Calculating tag" } dep_list = software . project . library . build_order . take_while do | dep | if dep . name == software . name && dep . version == software . version false else true end end log . internal ( log_key ) { "dep_list: #{dep_list.map(&:name).inspect}" } shasums = [ dep_list . map ( & :shasum ) , software . shasum ] . flatten suffix = Digest :: SHA256 . hexdigest ( shasums . join ( "|" ) ) @tag = "#{software.name}-#{suffix}-#{SERIAL_NUMBER}" log . internal ( log_key ) { "tag: #{@tag}" } @tag end
73	def incremental log . internal ( log_key ) { "Performing incremental cache" } create_cache_path remove_git_dirs git_cmd ( "add -A -f" ) begin git_cmd ( %Q{commit -q -m "Backup of #{tag}"} ) rescue CommandFailed => e raise unless e . message . include? ( "nothing to commit" ) end git_cmd ( %Q{tag -f "#{tag}"} ) end
74	def remove_git_dirs log . internal ( log_key ) { "Removing git directories" } Dir . glob ( "#{install_dir}/**/{,.*}/config" ) . reject do | path | REQUIRED_GIT_FILES . any? do | required_file | ! File . exist? ( File . join ( File . dirname ( path ) , required_file ) ) end end . each do | path | log . internal ( log_key ) { "Removing git dir `#{path}'" } FileUtils . rm_rf ( File . dirname ( path ) ) end true end
75	def write_manifest_file render_template ( resource_path ( "AppxManifest.xml.erb" ) , destination : "#{windows_safe_path(project.install_dir)}/AppxManifest.xml" , variables : { name : project . package_name , friendly_name : project . friendly_name , version : windows_package_version , maintainer : project . maintainer , certificate_subject : certificate_subject . gsub ( '"' , "&quot;" ) , } ) end
76	def shellout ( * args ) options = args . last . kind_of? ( Hash ) ? args . pop : { } options = SHELLOUT_OPTIONS . merge ( options ) command_string = args . join ( " " ) in_msys = options . delete ( :in_msys_bash ) && ENV [ "MSYSTEM" ] command_string = "bash -c \'#{command_string}\'" if in_msys log_level = options . delete ( :log_level ) options [ :live_stream ] ||= log . live_stream ( :internal ) if options [ :env ] options [ :environment ] = options . fetch ( :environment , { } ) . merge ( options [ :env ] ) end unless options [ :environment ] . empty? log . public_send ( log_level , log_key ) { "Environment:" } options [ :environment ] . sort . each do | key , value | log . public_send ( log_level , log_key ) { " #{key}=#{value.inspect}" } end end log . public_send ( log_level , log_key ) { "$ #{command_string}" } cmd = Mixlib :: ShellOut . new ( command_string , options ) cmd . environment [ "HOME" ] = "/tmp" unless ENV [ "HOME" ] cmd . run_command cmd end
77	def shellout! ( * args ) cmd = shellout ( * args ) cmd . error! cmd rescue Mixlib :: ShellOut :: ShellCommandFailed raise CommandFailed . new ( cmd ) rescue Mixlib :: ShellOut :: CommandTimeout raise CommandTimeout . new ( cmd ) end
78	def retry_block ( logstr , retried_exceptions = [ ] , retries = Omnibus :: Config . fetcher_retries , & block ) yield rescue Exception => e raise e unless retried_exceptions . any? { | eclass | e . is_a? ( eclass ) } if retries != 0 log . info ( log_key ) { "Retrying failed #{logstr} due to #{e} (#{retries} retries left)..." } retries -= 1 retry else log . error ( log_key ) { "#{logstr} failed - #{e.class}!" } raise end end
79	def windows_safe_path ( * pieces ) path = File . join ( * pieces ) if File :: ALT_SEPARATOR path . gsub ( File :: SEPARATOR , File :: ALT_SEPARATOR ) else path end end
80	def compiler_safe_path ( * pieces ) path = File . join ( * pieces ) path = path . sub ( / \/ / , "/\\1/" ) if ENV [ "MSYSTEM" ] path end
81	def create_directory ( * paths ) path = File . join ( * paths ) log . debug ( log_key ) { "Creating directory `#{path}'" } FileUtils . mkdir_p ( path ) path end
82	def remove_directory ( * paths ) path = File . join ( * paths ) log . debug ( log_key ) { "Remove directory `#{path}'" } FileUtils . rm_rf ( path ) path end
83	def copy_file ( source , destination ) log . debug ( log_key ) { "Copying `#{source}' to `#{destination}'" } FileUtils . cp ( source , destination ) destination end
84	def remove_file ( * paths ) path = File . join ( * paths ) log . debug ( log_key ) { "Removing file `#{path}'" } FileUtils . rm_f ( path ) path end
85	def create_file ( * paths , & block ) path = File . join ( * paths ) log . debug ( log_key ) { "Creating file `#{path}'" } FileUtils . mkdir_p ( File . dirname ( path ) ) if block File . open ( path , "wb" ) { | f | f . write ( yield ) } else FileUtils . touch ( path ) end path end
86	def create_link ( a , b ) log . debug ( log_key ) { "Linking `#{a}' to `#{b}'" } FileUtils . ln_s ( a , b ) end
87	def validate_license_info if project . license == "Unspecified" licensing_warning ( "Project '#{project.name}' does not contain licensing information." ) end if project . license != "Unspecified" && project . license_file . nil? licensing_warning ( "Project '#{project.name}' does not point to a license file." ) end if project . license != "Unspecified" && ! STANDARD_LICENSES . include? ( project . license ) licensing_info ( "Project '#{project.name}' is using '#{project.license}' which is not one of the standard licenses identified in https://opensource.org/licenses/alphabetical. Consider using one of the standard licenses." ) end license_map . each do | software_name , license_info | if license_info [ :license ] == "Unspecified" licensing_warning ( "Software '#{software_name}' does not contain licensing information." ) end if license_info [ :license ] != "Unspecified" && license_info [ :license_files ] . empty? licensing_warning ( "Software '#{software_name}' does not point to any license files." ) end if license_info [ :license ] != "Unspecified" && ! STANDARD_LICENSES . include? ( license_info [ :license ] ) licensing_info ( "Software '#{software_name}' uses license '#{license_info[:license]}' which is not one of the standard licenses identified in https://opensource.org/licenses/alphabetical. Consider using one of the standard licenses." ) end end end
88	def project_license_content project . license_file . nil? ? "" : IO . read ( File . join ( Config . project_root , project . license_file ) ) end
89	def license_map @license_map ||= begin map = { } project . library . each do | component | next if component . license == :project_license map [ component . name ] = { license : component . license , license_files : component . license_files , version : component . version , project_dir : component . project_dir , } end map end end
90	def process_transitive_dependency_licensing_info Dir . glob ( "#{cache_dir}/*/*-dependency-licenses.json" ) . each do | license_manifest_path | license_manifest_data = FFI_Yajl :: Parser . parse ( File . read ( license_manifest_path ) ) project_name = license_manifest_data [ "project_name" ] dependency_license_dir = File . dirname ( license_manifest_path ) license_manifest_data [ "dependency_managers" ] . each do | dep_mgr_name , dependencies | dep_license_map [ dep_mgr_name ] ||= { } dependencies . each do | dependency | dependency [ "license_files" ] . each do | f | license_path = File . join ( dependency_license_dir , f ) output_path = File . join ( output_dir , f ) FileUtils . cp ( license_path , output_path ) end dep_name = dependency [ "name" ] dep_version = dependency [ "version" ] if dep_license_map [ dep_mgr_name ] [ dep_name ] && dep_license_map [ dep_mgr_name ] [ dep_name ] [ dep_version ] dep_license_map [ dep_mgr_name ] [ dep_name ] [ dep_version ] [ "dependency_of" ] << project_name else dep_license_map [ dep_mgr_name ] [ dep_name ] ||= { } dep_license_map [ dep_mgr_name ] [ dep_name ] [ dep_version ] = { "license" => dependency [ "license" ] , "license_files" => dependency [ "license_files" ] , "dependency_of" => [ project_name ] , } end end end end FileUtils . rm_rf ( cache_dir ) end
91	def collect_licenses_for ( software ) return nil if software . license == :project_license software_name = software . name license_data = license_map [ software_name ] license_files = license_data [ :license_files ] license_files . each do | license_file | if license_file output_file = license_package_location ( software_name , license_file ) if local? ( license_file ) input_file = File . expand_path ( license_file , license_data [ :project_dir ] ) if File . exist? ( input_file ) FileUtils . cp ( input_file , output_file ) File . chmod 0644 , output_file unless windows? else licensing_warning ( "License file '#{input_file}' does not exist for software '#{software_name}'." ) raise_if_warnings_fatal! end else begin download_file! ( license_file , output_file , enable_progress_bar : false ) File . chmod 0644 , output_file unless windows? rescue SocketError , Errno :: ECONNREFUSED , Errno :: ECONNRESET , Errno :: ENETUNREACH , Timeout :: Error , OpenURI :: HTTPError , OpenSSL :: SSL :: SSLError licensing_warning ( "Can not download license file '#{license_file}' for software '#{software_name}'." ) raise_if_warnings_fatal! end end end end end
92	def write_prototype_file shellout! "cd #{install_dirname} && find #{install_basename} -print > #{staging_dir_path('files')}" File . open staging_dir_path ( "files.clean" ) , "w+" do | fout | File . open staging_dir_path ( "files" ) do | fin | fin . each_line do | line | if line . chomp =~ / \s / log . warn ( log_key ) { "Skipping packaging '#{line}' file due to whitespace in filename" } else fout . write ( line ) end end end end File . open staging_dir_path ( "Prototype" ) , "w+" do | f | f . write <<-EOF . gsub ( / / , "" ) EOF end shellout! "cd #{install_dirname} && pkgproto < #{staging_dir_path('files.clean')} > #{staging_dir_path('Prototype.files')}" shellout! "awk '{ $5 = \"root\"; $6 = \"root\"; print }' < #{staging_dir_path('Prototype.files')} >> #{staging_dir_path('Prototype')}" end
93	def content @content ||= IO . read ( path ) rescue Errno :: ENOENT raise NoPackageFile . new ( path ) end
94	def validate! unless File . exist? ( path ) raise NoPackageFile . new ( path ) end unless File . exist? ( metadata . path ) raise NoPackageMetadataFile . new ( metadata . path ) end true end
95	def key_for ( package , * stuff ) File . join ( Config . s3_publish_pattern % package . metadata , * stuff ) end
96	def semver build_tag = version_tag if prerelease_version? prerelease = prerelease_tag . tr ( "-" , "." ) build_tag << "-" << prerelease end build_version_items = [ ] if Config . append_timestamp build_version_items << build_start_time end unless commits_since_tag == 0 build_version_items << [ "git" , commits_since_tag , git_sha_tag ] . join ( "." ) end unless build_version_items . empty? build_tag << "+" << build_version_items . join ( "." ) end build_tag end
97	def build_start_time @build_start_time ||= begin if ENV [ "BUILD_TIMESTAMP" ] begin Time . strptime ( ENV [ "BUILD_TIMESTAMP" ] , "%Y-%m-%d_%H-%M-%S" ) rescue ArgumentError error_message = "BUILD_TIMESTAMP environment variable " error_message << "should be in YYYY-MM-DD_hh-mm-ss " error_message << "format." raise ArgumentError , error_message end elsif ENV [ "BUILD_ID" ] begin Time . strptime ( ENV [ "BUILD_ID" ] , "%Y-%m-%d_%H-%M-%S" ) rescue ArgumentError error_message = "BUILD_ID environment variable " error_message << "should be in YYYY-MM-DD_hh-mm-ss " error_message << "format." raise ArgumentError , error_message end else Time . now . utc end end . strftime ( TIMESTAMP_FORMAT ) end
98	def save File . open ( path , "w+" ) do | f | f . write ( FFI_Yajl :: Encoder . encode ( to_hash , pretty : true ) ) end true end
99	def vendor ( val = NULL ) if null? ( val ) @vendor || "Omnibus <omnibus@getchef.com>" else unless val . is_a? ( String ) raise InvalidValue . new ( :vendor , "be a String" ) end @vendor = val end end
100	def license ( val = NULL ) if null? ( val ) @license || project . license else unless val . is_a? ( String ) raise InvalidValue . new ( :license , "be a String" ) end @license = val end end
101	def build_filepath ( path ) filepath = rpm_safe ( "/" + path . gsub ( "#{build_dir}/" , "" ) ) return if config_files . include? ( filepath ) full_path = build_dir + filepath . gsub ( "[%]" , "%" ) full_path . delete! ( '"' ) return mark_filesystem_directories ( filepath ) if ! File . symlink? ( full_path ) && File . directory? ( full_path ) filepath end
102	def with_rpm_signing ( & block ) directory = Dir . mktmpdir destination = "#{directory}/sign-rpm" render_template ( resource_path ( "signing.erb" ) , destination : destination , mode : 0700 , variables : { passphrase : signing_passphrase , } ) yield ( destination ) ensure remove_file ( destination ) remove_directory ( directory ) end
103	def publish ( klass , pattern , options ) if options [ :platform_mappings ] options [ :platform_mappings ] = FFI_Yajl :: Parser . parse ( File . read ( File . expand_path ( options [ :platform_mappings ] ) ) ) end klass . publish ( pattern , options ) do | package | say ( "Published '#{package.name}' for #{package.metadata[:platform]}-#{package.metadata[:platform_version]}" , :green ) end end
104	def build_version ( val = NULL , & block ) if block && ! null? ( val ) raise Error , "You cannot specify additional parameters to " "#build_version when a block is given!" end if block @build_version_dsl = BuildVersionDSL . new ( & block ) else if null? ( val ) @build_version_dsl . build_version else @build_version_dsl = BuildVersionDSL . new ( val ) end end end
105	def package ( id , & block ) unless block raise InvalidValue . new ( :package , "have a block" ) end packagers [ id ] << block end
106	def compress ( id , & block ) if block compressors [ id ] << block else compressors [ id ] << Proc . new { } end end
107	def override ( name , val = NULL ) if null? ( val ) overrides [ name . to_sym ] else overrides [ name . to_sym ] = val end end
108	def license_file_path ( path = NULL ) if null? ( path ) @license_file_path || File . join ( install_dir , "LICENSE" ) else @license_file_path = File . join ( install_dir , path ) end end
109	def dependency? ( software ) name = software . is_a? ( Software ) ? software . name : software dependencies . include? ( name ) end
110	def built_manifest log . info ( log_key ) { "Building version manifest" } m = Omnibus :: Manifest . new ( build_version , build_git_revision , license ) softwares . each do | software | m . add ( software . name , software . manifest_entry ) end m end
111	def write_text_manifest File . open ( text_manifest_path , "w" ) do | f | f . puts "#{name} #{build_version}" f . puts "" f . puts Omnibus :: Reports . pretty_version_map ( self ) end end
112	def write_conffiles_file return if project . config_files . empty? render_template ( resource_path ( "conffiles.erb" ) , destination : File . join ( debian_dir , "conffiles" ) , variables : { config_files : project . config_files , } ) end
113	def package_size @package_size ||= begin path = "#{project.install_dir}/**/*" total = FileSyncer . glob ( path ) . inject ( 0 ) do | size , path | unless File . directory? ( path ) || File . symlink? ( path ) size += File . size ( path ) end size end total / 1024 end end
114	def dir_empty? ( dir ) Dir . entries ( dir ) . reject { | d | [ "." , ".." ] . include? ( d ) } . empty? end
115	def force_recreate_project_dir! log . warn ( log_key ) { "Removing existing directory #{project_dir} before cloning" } FileUtils . rm_rf ( project_dir ) Dir . mkdir ( project_dir ) end
116	def current_revision cmd = git ( "rev-parse HEAD" ) cmd . stdout . strip rescue CommandFailed log . debug ( log_key ) { "unable to determine current revision" } nil end
117	def contains_revision? ( rev ) cmd = git ( "cat-file -t #{rev}" ) cmd . stdout . strip == "commit" rescue CommandFailed log . debug ( log_key ) { "unable to determine presence of commit #{rev}" } false end
118	def to_ssh if zero? return [ 0 ] . pack ( "N" ) else buf = to_s ( 2 ) if buf . getbyte ( 0 ) [ 7 ] == 1 return [ buf . length + 1 , 0 , buf ] . pack ( "NCA*" ) else return [ buf . length , buf ] . pack ( "NA*" ) end end end
119	def compute_need_bits need_bits = data [ :need_bytes ] * 8 * 2 + 1 data [ :minimum_dh_bits ] ||= MINIMUM_BITS if need_bits < data [ :minimum_dh_bits ] need_bits = data [ :minimum_dh_bits ] elsif need_bits > MAXIMUM_BITS need_bits = MAXIMUM_BITS end data [ :need_bits ] = need_bits data [ :need_bytes ] = need_bits / 8 end
120	def get_parameters compute_need_bits buffer = Net :: SSH :: Buffer . from ( :byte , KEXDH_GEX_REQUEST , :long , data [ :minimum_dh_bits ] , :long , data [ :need_bits ] , :long , MAXIMUM_BITS ) connection . send_message ( buffer ) buffer = connection . next_message raise Net :: SSH :: Exception , "expected KEXDH_GEX_GROUP, got #{buffer.type}" unless buffer . type == KEXDH_GEX_GROUP p = buffer . read_bignum g = buffer . read_bignum [ p , g ] end
121	def build_signature_buffer ( result ) response = Net :: SSH :: Buffer . new response . write_string data [ :client_version_string ] , data [ :server_version_string ] , data [ :client_algorithm_packet ] , data [ :server_algorithm_packet ] , result [ :key_blob ] response . write_long MINIMUM_BITS , data [ :need_bits ] , MAXIMUM_BITS response . write_bignum dh . p , dh . g , dh . pub_key , result [ :server_dh_pubkey ] , result [ :shared_secret ] response end
122	def when_loaded previously_loaded = loaded self . loaded = loaded? raise SitePrism :: FailedLoadValidationError , load_error unless loaded yield self if block_given? ensure self . loaded = previously_loaded end
123	def load_validations_pass? self . class . load_validations . all? do | validation | passed , message = instance_eval ( & validation ) self . load_error = message if message && ! passed passed end end
124	def raise_if_block ( obj , name , has_block , type ) return unless has_block SitePrism . logger . debug ( "Type passed in: #{type}" ) SitePrism . logger . warn ( 'section / iFrame can only accept blocks.' ) SitePrism . logger . error ( "#{obj.class}##{name} does not accept blocks" ) raise SitePrism :: UnsupportedBlockError end
125	def merge_args ( find_args , runtime_args , visibility_args = { } ) find_args = find_args . dup runtime_args = runtime_args . dup options = visibility_args . dup SitePrism . logger . debug ( "Initial args: #{find_args}, #{runtime_args}." ) recombine_args ( find_args , runtime_args , options ) return [ * find_args , * runtime_args ] if options . empty? [ * find_args , * runtime_args , options ] end
126	def recombine_args ( find_args , runtime_args , options ) options . merge! ( find_args . pop ) if find_args . last . is_a? Hash options . merge! ( runtime_args . pop ) if runtime_args . last . is_a? Hash options [ :wait ] = wait_time unless wait_key_present? ( options ) end
127	def elements_to_check if _expected_items SitePrism . logger . debug ( 'Expected Items has been set.' ) _mapped_items . select { | item_name | _expected_items . include? ( item_name ) } else _mapped_items end end
128	def matches? ( url , expected_mappings = { } ) actual_mappings = mappings ( url ) return false unless actual_mappings expected_mappings . empty? || all_expected_mappings_match? ( expected_mappings , actual_mappings ) end
129	def component_matches ( component , uri ) component_template = component_templates [ component ] return { } unless component_template component_url = uri . public_send ( component ) . to_s mappings = component_template . extract ( component_url ) return mappings if mappings prefix = component_prefixes [ component ] return nil unless prefix component_template . extract ( prefix + component_url ) end
130	def to_substituted_uri url = pattern substitutions . each_pair { | slug , value | url = url . sub ( slug , value ) } begin Addressable :: URI . parse ( url ) rescue Addressable :: URI :: InvalidURIError SitePrism . logger . warn ( "Ensure you don't use templated port numbers." ) raise SitePrism :: InvalidUrlMatcherError end end
131	def substitution_value ( index ) sha = Digest :: SHA1 . digest ( index . to_s ) Base64 . urlsafe_encode64 ( sha ) . gsub ( / / , '' ) [ 0 .. 5 ] end
132	def build_times_enumerator ( number , cursor : ) raise ArgumentError , "First argument must be an Integer" unless number . is_a? ( Integer ) wrap ( self , build_array_enumerator ( number . times . to_a , cursor : cursor ) ) end
133	def build_array_enumerator ( enumerable , cursor : ) unless enumerable . is_a? ( Array ) raise ArgumentError , "enumerable must be an Array" end if enumerable . any? { | i | defined? ( ActiveRecord ) && i . is_a? ( ActiveRecord :: Base ) } raise ArgumentError , "array cannot contain ActiveRecord objects" end drop = if cursor . nil? 0 else cursor + 1 end wrap ( self , enumerable . each_with_index . drop ( drop ) . to_enum { enumerable . size } ) end
134	def build_lock_queue_enumerator ( lock_queue , at_most_once : ) unless lock_queue . is_a? ( BackgroundQueue :: LockQueue :: RedisQueue ) || lock_queue . is_a? ( BackgroundQueue :: LockQueue :: RolloutRedisQueue ) raise ArgumentError , "an argument to #build_lock_queue_enumerator must be a LockQueue" end wrap ( self , BackgroundQueue :: LockQueueEnumerator . new ( lock_queue , at_most_once : at_most_once ) . to_enum ) end
135	def build_active_record_enumerator_on_records ( scope , cursor : , ** args ) enum = build_active_record_enumerator ( scope , cursor : cursor , ** args ) . records wrap ( self , enum ) end
136	def build_active_record_enumerator_on_batches ( scope , cursor : , ** args ) enum = build_active_record_enumerator ( scope , cursor : cursor , ** args ) . batches wrap ( self , enum ) end
137	def batches ( batch_size : , cursor : ) @csv . lazy . each_slice ( batch_size ) . each_with_index . drop ( cursor . to_i ) . to_enum { ( count_rows_in_file . to_f / batch_size ) . ceil } end
138	def reify ( options = { } ) unless self . class . column_names . include? "object" raise "reify can't be called without an object column" end return nil if object . nil? :: PaperTrail :: Reifier . reify ( self , options ) end
139	def version_limit if self . class . item_subtype_column_present? klass = ( item_subtype || item_type ) . constantize if klass &. paper_trail_options &. key? ( :limit ) return klass . paper_trail_options [ :limit ] end end PaperTrail . config . version_limit end
140	def on_create @model_class . after_create { | r | r . paper_trail . record_create if r . paper_trail . save_version? } return if @model_class . paper_trail_options [ :on ] . include? ( :create ) @model_class . paper_trail_options [ :on ] << :create end
141	def on_destroy ( recording_order = "before" ) unless %w[ after before ] . include? ( recording_order . to_s ) raise ArgumentError , 'recording order can only be "after" or "before"' end if recording_order . to_s == "after" && cannot_record_after_destroy? raise E_CANNOT_RECORD_AFTER_DESTROY end @model_class . send ( "#{recording_order}_destroy" , lambda do | r | return unless r . paper_trail . save_version? r . paper_trail . record_destroy ( recording_order ) end ) return if @model_class . paper_trail_options [ :on ] . include? ( :destroy ) @model_class . paper_trail_options [ :on ] << :destroy end
142	def on_update @model_class . before_save { | r | r . paper_trail . reset_timestamp_attrs_for_update_if_needed } @model_class . after_update { | r | if r . paper_trail . save_version? r . paper_trail . record_update ( force : false , in_after_callback : true , is_touch : false ) end } @model_class . after_update { | r | r . paper_trail . clear_version_instance } return if @model_class . paper_trail_options [ :on ] . include? ( :update ) @model_class . paper_trail_options [ :on ] << :update end
143	def on_touch @model_class . after_touch { | r | r . paper_trail . record_update ( force : true , in_after_callback : true , is_touch : true ) } end
144	def check_presence_of_item_subtype_column ( options ) return unless options . key? ( :limit ) return if version_class . item_subtype_column_present? raise format ( E_MODEL_LIMIT_REQUIRES_ITEM_SUBTYPE , @model_class . name ) end
145	def save_version? if_condition = @record . paper_trail_options [ :if ] unless_condition = @record . paper_trail_options [ :unless ] ( if_condition . blank? || if_condition . call ( @record ) ) && ! unless_condition . try ( :call , @record ) end
146	def _squash_changes ( changes ) changes = changes . map { | change , dir , path | [ change , dir + path ] } actions = changes . group_by ( & :last ) . map do | path , action_list | [ _logical_action_for ( path , action_list . map ( & :first ) ) , path . to_s ] end config . debug ( "listen: raw changes: #{actions.inspect}" ) { modified : [ ] , added : [ ] , removed : [ ] } . tap do | squashed | actions . each do | type , path | squashed [ type ] << path unless type . nil? end config . debug ( "listen: final changes: #{squashed.inspect}" ) end end
147	def to_node object if object . is_a? ( self . ancestry_base_class ) then object else unscoped_where { | scope | scope . find object } end end
148	def scope_depth depth_options , depth depth_options . inject ( self . ancestry_base_class ) do | scope , option | scope_name , relative_depth = option if [ :before_depth , :to_depth , :at_depth , :from_depth , :after_depth ] . include? scope_name scope . send scope_name , depth + relative_depth else raise Ancestry :: AncestryException . new ( "Unknown depth option: #{scope_name}." ) end end end
149	def orphan_strategy = orphan_strategy if [ :rootify , :adopt , :restrict , :destroy ] . include? orphan_strategy class_variable_set :@@orphan_strategy , orphan_strategy else raise Ancestry :: AncestryException . new ( "Invalid orphan strategy, valid ones are :rootify,:adopt, :restrict and :destroy." ) end end
150	def arrange options = { } if ( order = options . delete ( :order ) ) arrange_nodes self . ancestry_base_class . order ( order ) . where ( options ) else arrange_nodes self . ancestry_base_class . where ( options ) end end
151	def arrange_serializable options = { } , nodes = nil , & block nodes = arrange ( options ) if nodes . nil? nodes . map do | parent , children | if block_given? yield parent , arrange_serializable ( options , children , & block ) else parent . serializable_hash . merge 'children' => arrange_serializable ( options , children ) end end end
152	def build_ancestry_from_parent_ids! parent_id = nil , ancestry = nil unscoped_where do | scope | scope . where ( :parent_id => parent_id ) . find_each do | node | node . without_ancestry_callbacks do node . update_attribute ancestry_column , ancestry end build_ancestry_from_parent_ids! node . id , if ancestry . nil? then "#{node.id}" else "#{ancestry}/#{node.id}" end end end end
153	def rebuild_depth_cache! raise Ancestry :: AncestryException . new ( "Cannot rebuild depth cache for model without depth caching." ) unless respond_to? :depth_cache_column self . ancestry_base_class . transaction do unscoped_where do | scope | scope . find_each do | node | node . update_attribute depth_cache_column , node . depth end end end end
154	def indirect_conditions ( object ) t = arel_table node = to_node ( object ) if ActiveRecord :: VERSION :: MAJOR >= 5 t [ ancestry_column ] . matches ( "#{node.child_ancestry}/%" , nil , true ) else t [ ancestry_column ] . matches ( "#{node.child_ancestry}/%" ) end end
155	def request_defaults ( sudo = nil ) self . class . default_params sudo : sudo raise Error :: MissingCredentials , 'Please set an endpoint to API' unless @endpoint self . class . default_params . delete ( :sudo ) if sudo . nil? end
156	def options VALID_OPTIONS_KEYS . inject ( { } ) do | option , key | option . merge! ( key => send ( key ) ) end end
157	def reset self . endpoint = ENV [ 'GITLAB_API_ENDPOINT' ] self . private_token = ENV [ 'GITLAB_API_PRIVATE_TOKEN' ] || ENV [ 'GITLAB_API_AUTH_TOKEN' ] self . httparty = get_httparty_config ( ENV [ 'GITLAB_API_HTTPARTY_OPTIONS' ] ) self . sudo = nil self . user_agent = DEFAULT_USER_AGENT end
158	def get_httparty_config ( options ) return if options . nil? httparty = Gitlab :: CLI :: Helpers . yaml_load ( options ) raise ArgumentError , 'HTTParty config should be a Hash.' unless httparty . is_a? Hash Gitlab :: CLI :: Helpers . symbolize_keys httparty end
159	def start_timer ( timer = DEFAULT_TIMER . new ) raise Socketry :: InternalError , "timer already started" if defined? ( @timer ) raise Socketry :: InternalError , "deadline already set" if defined? ( @deadline ) @deadline = nil @timer = timer @timer . start true end
160	def set_timeout ( timeout ) raise Socketry :: InternalError , "deadline already set" if @deadline return unless timeout raise Socketry :: TimeoutError , "time expired" if timeout < 0 @deadline = lifetime + timeout end
161	def time_remaining ( timeout ) return unless timeout raise Socketry :: InternalError , "no deadline set" unless @deadline remaining = @deadline - lifetime raise Socketry :: TimeoutError , "time expired" if remaining <= 0 remaining end
162	def build_schemas ( parent_schema ) schema = parent_schema . schema if schema [ "$ref" ] load_ref_schema ( parent_schema , schema [ "$ref" ] ) end case schema [ "extends" ] when String load_ref_schema ( parent_schema , schema [ "extends" ] ) when Array schema [ 'extends' ] . each do | type | handle_schema ( parent_schema , type ) end end [ "type" , "disallow" ] . each do | key | if schema [ key ] . is_a? ( Array ) schema [ key ] . each do | type | if type . is_a? ( Hash ) handle_schema ( parent_schema , type ) end end end end %w[ definitions properties patternProperties ] . each do | key | next unless value = schema [ key ] value . each do | k , inner_schema | handle_schema ( parent_schema , inner_schema ) end end %w[ additionalProperties additionalItems dependencies extends ] . each do | key | next unless schema [ key ] . is_a? ( Hash ) handle_schema ( parent_schema , schema [ key ] ) end %w[ allOf anyOf oneOf not ] . each do | key | next unless value = schema [ key ] Array ( value ) . each do | inner_schema | handle_schema ( parent_schema , inner_schema ) end end if schema [ "items" ] items = schema [ "items" ] . clone items = [ items ] unless items . is_a? ( Array ) items . each do | item | handle_schema ( parent_schema , item ) end end if schema [ "enum" ] . is_a? ( Array ) schema [ "enum" ] = ArraySet . new ( schema [ "enum" ] ) end end
163	def handle_schema ( parent_schema , obj ) if obj . is_a? ( Hash ) schema_uri = parent_schema . uri . dup schema = JSON :: Schema . new ( obj , schema_uri , parent_schema . validator ) if obj [ 'id' ] self . class . add_schema ( schema ) end build_schemas ( schema ) end end
164	def matches_conditions? ( action , subject , extra_args ) if @match_all call_block_with_all ( action , subject , extra_args ) elsif @block && ! subject_class? ( subject ) @block . call ( subject , * extra_args ) elsif @conditions . kind_of? ( Hash ) && subject . class == Hash nested_subject_matches_conditions? ( subject ) elsif @conditions . kind_of? ( Hash ) && ! subject_class? ( subject ) matches_conditions_hash? ( subject ) else @conditions . empty? ? true : @base_behavior end end
165	def alias_action ( * args ) target = args . pop [ :to ] validate_target ( target ) aliased_actions [ target ] ||= [ ] aliased_actions [ target ] += args end
166	def expand_actions ( actions ) actions . map do | action | aliased_actions [ action ] ? [ action , * expand_actions ( aliased_actions [ action ] ) ] : action end . flatten end
167	def aliases_for_action ( action ) results = [ action ] aliased_actions . each do | aliased_action , actions | results += aliases_for_action ( aliased_action ) if actions . include? action end results end
168	def relevant_rules ( action , subject ) rules . reverse . select do | rule | rule . expanded_actions = expand_actions ( rule . actions ) rule . relevant? action , subject end end
169	def create_missing_file raise Errno :: EISDIR , path . to_s if File . directory? ( @path ) return if File . exist? ( @path ) dirname = RealFile . dirname @path unless dirname == '.' dir = FileSystem . find dirname raise Errno :: ENOENT , path . to_s unless dir . is_a? FakeDir end @file = FileSystem . add ( path , FakeFile . new ) end
170	def each_filename return to_enum ( __method__ ) unless block_given? _prefix , names = split_names ( @path ) names . each { | filename | yield filename } nil end
171	def descend vs = [ ] ascend { | v | vs << v } vs . reverse_each { | v | yield v } nil end
172	def ascend path = @path yield self while ( r = chop_basename ( path ) ) path , _name = r break if path . empty? yield self . class . new ( del_trailing_separator ( path ) ) end end
173	def c_checksum sum = 0 checksum_values . each_with_index do | value , index | sum += ( ( index % 20 ) + 1 ) * value end sum % 47 end
174	def k_checksum sum = 0 checksum_values_with_c_checksum . each_with_index do | value , index | sum += ( ( index % 15 ) + 1 ) * value end sum % 47 end
175	def annotate_pdf ( pdf , options = { } ) with_options options do xpos , ypos = x , y orig_xpos = xpos if barcode . two_dimensional? boolean_groups . reverse_each do | groups | groups . each do | bar , amount | if bar pdf . move_to ( xpos , ypos ) . line_to ( xpos , ypos + xdim ) . line_to ( xpos + ( xdim * amount ) , ypos + xdim ) . line_to ( xpos + ( xdim * amount ) , ypos ) . line_to ( xpos , ypos ) . fill end xpos += ( xdim * amount ) end xpos = orig_xpos ypos += xdim end else boolean_groups . each do | bar , amount | if bar pdf . move_to ( xpos , ypos ) . line_to ( xpos , ypos + height ) . line_to ( xpos + ( xdim * amount ) , ypos + height ) . line_to ( xpos + ( xdim * amount ) , ypos ) . line_to ( xpos , ypos ) . fill end xpos += ( xdim * amount ) end end end pdf end
176	def characters chars = raw_characters extended ? chars . map { | c | EXTENDED_ENCODINGS [ c ] . split ( / / ) } . flatten : chars end
177	def characters chars = data . split ( / /n ) if type == 'C' result = [ ] count = 0 while count < chars . size if chars [ count ] =~ / \d / result << "#{chars[count]}#{chars[count+1]}" count += 2 else result << chars [ count ] count += 1 end end result else chars end end
178	def checksum pos = 0 ( numbers + extra_numbers ) . inject ( start_num ) do | sum , number | pos += 1 sum + ( number * pos ) end % 103 end
179	def encoding_for_bars ( * bars ) wide , narrow , space = wide_encoding , narrow_encoding , space_encoding bars . flatten . inject '' do | enc , bar | enc + ( bar == WIDE ? wide : narrow ) + space end end
180	def render_to_cairo_context ( context , options = { } ) if context . respond_to? ( :have_current_point? ) and context . have_current_point? current_x , current_y = context . current_point else current_x = x ( options ) || margin ( options ) current_y = y ( options ) || margin ( options ) end _xdim = xdim ( options ) _height = height ( options ) original_current_x = current_x context . save do context . set_source_color ( :black ) context . fill do if barcode . two_dimensional? boolean_groups . each do | groups | groups . each do | bar , amount | current_width = _xdim * amount if bar context . rectangle ( current_x , current_y , current_width , _xdim ) end current_x += current_width end current_x = original_current_x current_y += _xdim end else boolean_groups . each do | bar , amount | current_width = _xdim * amount if bar context . rectangle ( current_x , current_y , current_width , _height ) end current_x += current_width end end end end context end
181	def to_png ( options = { } ) output_to_string_io do | io | Cairo :: ImageSurface . new ( options [ :format ] , full_width ( options ) , full_height ( options ) ) do | surface | render ( surface , options ) surface . write_to_png ( io ) end end end
182	def to_ps ( options = { } ) output_to_string_io do | io | Cairo :: PSSurface . new ( io , full_width ( options ) , full_height ( options ) ) do | surface | surface . eps = options [ :eps ] if surface . respond_to? ( :eps= ) render ( surface , options ) end end end
183	def to_pdf ( options = { } ) output_to_string_io do | io | Cairo :: PDFSurface . new ( io , full_width ( options ) , full_height ( options ) ) do | surface | render ( surface , options ) end end end
184	def to_svg ( options = { } ) output_to_string_io do | io | Cairo :: SVGSurface . new ( io , full_width ( options ) , full_height ( options ) ) do | surface | render ( surface , options ) end end end
185	def max_threads = ( number ) @max_threads = number . to_i . positive? && throttle . zero? ? number . to_i : 1 hydra . max_concurrency = @max_threads end
186	def online? ( path = nil ) NS :: Browser . get ( url ( path ) ) . code . nonzero? ? true : false end
187	def head_and_get ( path , codes = [ 200 ] , params = { } ) url_to_get = url ( path ) head_params = ( params [ :head ] || { } ) . merge ( head_or_get_params ) head_res = NS :: Browser . forge_request ( url_to_get , head_params ) . run codes . include? ( head_res . code ) ? NS :: Browser . get ( url_to_get , params [ :get ] || { } ) : head_res end
188	def db return @db unless @db . nil? Sequel . single_threaded = true @db = Sequel . connect ( config ( :sql_url ) , :encoding => 'utf8' ) if @db . tables . empty? dir = File . join ( File . dirname ( __FILE__ ) , 'migrations' ) puts "Database empty, running migrations from #{dir}" Sequel . extension :migration Sequel :: Migrator . apply ( @db , dir ) end @db end
189	def ensure_commit ( repo , sha , user , comments = true ) ensure_repo ( user , repo ) c = retrieve_commit ( repo , sha , user ) if c . nil? warn "Commit #{user}/#{repo} -> #{sha} does not exist" return end stored = store_commit ( c , repo , user ) ensure_parents ( c ) if not c [ 'commit' ] [ 'comment_count' ] . nil? and c [ 'commit' ] [ 'comment_count' ] > 0 ensure_commit_comments ( user , repo , sha ) if comments end ensure_repo_commit ( user , repo , sha ) stored end
190	def ensure_parents ( commit ) commits = db [ :commits ] parents = db [ :commit_parents ] commit [ 'parents' ] . map do | p | save do url = p [ 'url' ] . split ( / \/ / ) this = commits . first ( :sha => commit [ 'sha' ] ) parent = commits . first ( :sha => url [ 7 ] ) if parent . nil? c = retrieve_commit ( url [ 5 ] , url [ 7 ] , url [ 4 ] ) if c . nil? warn "Could not retrieve commit_parent #{url[4]}/#{url[5]} -> #{url[7]} to #{this[:sha]}" next end parent = store_commit ( c , url [ 5 ] , url [ 4 ] ) end if parent . nil? warn "Could not find #{url[4]}/#{url[5]} -> #{url[7]}, parent to commit #{this[:sha]}" next end if parents . first ( :commit_id => this [ :id ] , :parent_id => parent [ :id ] ) . nil? parents . insert ( :commit_id => this [ :id ] , :parent_id => parent [ :id ] ) info "Added commit_parent #{parent[:sha]} to commit #{this[:sha]}" else debug "Parent #{parent[:sha]} for commit #{this[:sha]} exists" end parents . first ( :commit_id => this [ :id ] , :parent_id => parent [ :id ] ) end end . select { | x | ! x . nil? } end
191	def ensure_user_followers ( followed ) curuser = ensure_user ( followed , false , false ) followers = db . from ( :followers , :users ) . where ( Sequel . qualify ( 'followers' , 'follower_id' ) => Sequel . qualify ( 'users' , 'id' ) ) . where ( Sequel . qualify ( 'followers' , 'user_id' ) => curuser [ :id ] ) . select ( :login ) . all retrieve_user_followers ( followed ) . reduce ( [ ] ) do | acc , x | if followers . find { | y | y [ :login ] == x [ 'login' ] } . nil? acc << x else acc end end . map { | x | save { ensure_user_follower ( followed , x [ 'login' ] ) } } . select { | x | ! x . nil? } end
192	def ensure_user_follower ( followed , follower , date_added = nil ) follower_user = ensure_user ( follower , false , false ) followed_user = ensure_user ( followed , false , false ) if followed_user . nil? or follower_user . nil? warn "Could not find follower #{follower} or user #{followed}" return end followers = db [ :followers ] follower_id = follower_user [ :id ] followed_id = followed_user [ :id ] follower_exists = followers . first ( :user_id => followed_id , :follower_id => follower_id ) if follower_exists . nil? added = if date_added . nil? max ( follower_user [ :created_at ] , followed_user [ :created_at ] ) else date_added end retrieved = retrieve_user_follower ( followed , follower ) if retrieved . nil? warn "Could not retrieve follower #{follower} for #{followed}" return end followers . insert ( :user_id => followed_id , :follower_id => follower_id , :created_at => added ) info "Added follower #{follower} to #{followed}" else debug "Follower #{follower} for user #{followed} exists" end unless date_added . nil? followers . filter ( :user_id => followed_id , :follower_id => follower_id ) . update ( :created_at => date ( date_added ) ) info "Updated follower #{followed} -> #{follower}, created_at -> #{date(date_added)}" end followers . first ( :user_id => followed_id , :follower_id => follower_id ) end
193	def ensure_user_byemail ( email , name ) users = db [ :users ] usr = users . first ( :email => email ) if usr . nil? u = retrieve_user_byemail ( email , name ) if u . nil? or u [ 'login' ] . nil? warn "Could not retrieve user #{email} through search API query" login = ( 0 ... 8 ) . map { 65 . + ( rand ( 25 ) ) . chr } . join users . insert ( :email => email , :name => name , :login => login , :fake => true , :deleted => false , :created_at => Time . now ) info "Added user fake #{login} -> #{email}" users . first ( :login => login ) else in_db = users . first ( :login => u [ 'login' ] ) geo = geolocate ( location : u [ 'location' ] ) if in_db . nil? users . insert ( :login => u [ 'login' ] , :name => u [ 'name' ] , :company => u [ 'company' ] , :email => u [ 'email' ] , :long => geo [ :long ] , :lat => geo [ :lat ] , :country_code => geo [ :country_code ] , :state => geo [ :state ] , :city => geo [ :city ] , :fake => false , :deleted => false , :created_at => date ( u [ 'created_at' ] ) ) info "Added user #{u['login']} (#{email}) through search API query" else in_db . update ( :name => u [ 'name' ] , :company => u [ 'company' ] , :email => u [ 'email' ] , :long => geo [ :long ] , :lat => geo [ :lat ] , :country_code => geo [ :country_code ] , :state => geo [ :state ] , :city => geo [ :city ] , :fake => false , :deleted => false , :created_at => date ( u [ 'created_at' ] ) ) debug "User #{u['login']} with email #{email} exists" end users . first ( :login => u [ 'login' ] ) end else debug "User with email #{email} exists" usr end end
194	def ensure_repo ( user , repo , recursive = false ) repos = db [ :projects ] curuser = ensure_user ( user , false , false ) if curuser . nil? warn "Could not find user #{user}" return end currepo = repos . first ( :owner_id => curuser [ :id ] , :name => repo ) unless currepo . nil? debug "Repo #{user}/#{repo} exists" return refresh_repo ( user , repo , currepo ) end r = retrieve_repo ( user , repo , true ) if r . nil? warn "Could not retrieve repo #{user}/#{repo}" return end if r [ 'owner' ] [ 'login' ] != curuser [ :login ] info "Repo changed owner from #{curuser[:login]} to #{r['owner']['login']}" curuser = ensure_user ( r [ 'owner' ] [ 'login' ] , false , false ) end repos . insert ( :url => r [ 'url' ] , :owner_id => curuser [ :id ] , :name => r [ 'name' ] , :description => unless r [ 'description' ] . nil? then r [ 'description' ] [ 0 .. 254 ] else nil end , :language => r [ 'language' ] , :created_at => date ( r [ 'created_at' ] ) , :updated_at => date ( Time . now ) , :etag => unless r [ 'etag' ] . nil? then r [ 'etag' ] end ) unless r [ 'parent' ] . nil? parent_owner = r [ 'parent' ] [ 'owner' ] [ 'login' ] parent_repo = r [ 'parent' ] [ 'name' ] parent = ensure_repo ( parent_owner , parent_repo ) if parent . nil? warn "Could not find repo #{parent_owner}/#{parent_repo}, parent of: #{user}/#{repo}" repos . filter ( :owner_id => curuser [ :id ] , :name => repo ) . update ( :forked_from => - 1 ) else repos . filter ( :owner_id => curuser [ :id ] , :name => repo ) . update ( :forked_from => parent [ :id ] ) info "Repo #{user}/#{repo} is a fork of #{parent_owner}/#{parent_repo}" unless ensure_fork_point ( user , repo ) . nil? warn "Could not find fork point for #{user}/#{repo}, fork of #{parent_owner}/#{parent_repo}" end end end if recursive and not ensure_repo_recursive ( user , repo ) warn "Could retrieve #{user}/#{repo} recursively" return nil end info "Added repo #{user}/#{repo}" return repos . first ( :owner_id => curuser [ :id ] , :name => repo ) end
195	def ensure_languages ( owner , repo ) currepo = ensure_repo ( owner , repo ) langs = retrieve_languages ( owner , repo ) if langs . nil? or langs . empty? warn "Could not find languages for repo #{owner}/#{repo}" return end ts = Time . now langs . keys . each do | lang | db [ :project_languages ] . insert ( :project_id => currepo [ :id ] , :language => lang . downcase , :bytes => langs [ lang ] , :created_at => ts ) info "Added project_language #{owner}/#{repo} -> #{lang} (#{langs[lang]} bytes)" end db [ :project_languages ] . where ( :project_id => currepo [ :id ] ) . where ( :created_at => ts ) . all end
196	def ensure_fork_commits ( owner , repo , parent_owner , parent_repo ) currepo = ensure_repo ( owner , repo ) if currepo . nil? warn "Could not find repo #{owner}/#{repo}" return end parent = ensure_repo ( parent_owner , parent_repo ) if parent . nil? warn "Could not find repo #{parent_owner}/#{parent_repo}, parent of #{owner}/#{repo}" return end strategy = case when config ( :fork_commits ) . match ( / /i ) :all when config ( :fork_commits ) . match ( / /i ) :fork_point when config ( :fork_commits ) . match ( / /i ) :none else :fork_point end fork_commit = ensure_fork_point ( owner , repo ) if fork_commit . nil? or fork_commit . empty? warn "Could not find fork commit for repo #{owner}/#{repo}. Retrieving all commits." return ensure_commits ( owner , repo , fork_all : true ) end debug "Retrieving commits for fork #{owner}/#{repo}: strategy is #{strategy}" return if strategy == :none if strategy == :fork_point info "Retrieving commits for #{owner}/#{repo} until fork commit #{fork_commit[:sha]}" master_branch = retrieve_default_branch ( parent_owner , parent_repo ) return if master_branch . nil? sha = master_branch found = false while not found commits = retrieve_commits ( repo , sha , owner , 1 ) if commits . size == 0 break end if commits . size == 1 and commits [ 0 ] [ 'sha' ] == sha break end for c in commits ensure_commit ( repo , c [ 'sha' ] , owner ) sha = c [ 'sha' ] if c [ 'sha' ] == fork_commit [ :sha ] found = true break end end end end if strategy == :all shared_commit = db [ :commits ] . first ( :sha => fork_commit ) copied = 0 to_copy = db . from ( :project_commits , :commits ) . where ( Sequel . qualify ( 'project_commits' , 'commit_id' ) => Sequel . qualify ( 'commits' , 'id' ) ) . where ( Sequel . qualify ( 'project_commits' , 'project_id' ) => parent [ :id ] ) . where ( 'commits.created_at < ?' , shared_commit [ :created_at ] ) . select ( Sequel . qualify ( 'commits' , 'id' ) ) to_copy . each do | c | copied += 1 begin db [ :project_commits ] . insert ( :project_id => currepo [ :id ] , :commit_id => c [ :id ] ) debug "Copied commit #{c[:sha]} #{parent_owner}/#{parent_repo} -> #{owner}/#{repo} (#{copied} total)" rescue StandardError => e warn "Could not copy commit #{c[:sha]} #{parent_owner}/#{parent_repo} -> #{owner}/#{repo} : #{e.message}" end end info "Finished copying commits from #{parent_owner}/#{parent_repo} -> #{owner}/#{repo}: #{copied} total" end end
197	def ensure_fork_point ( owner , repo ) fork = ensure_repo ( owner , repo , false ) if fork [ :forked_from ] . nil? warn "Repo #{owner}/#{repo} is not a fork" return nil end unless fork [ :forked_commit_id ] . nil? commit = db [ :commits ] . where ( :id => fork [ :forked_commit_id ] ) . first return commit unless commit . nil? end parent = db . from ( :projects , :users ) . where ( Sequel . qualify ( 'projects' , 'owner_id' ) => Sequel . qualify ( 'users' , 'id' ) ) . where ( Sequel . qualify ( 'projects' , 'id' ) => fork [ :forked_from ] ) . select ( Sequel . qualify ( 'users' , 'login' ) , Sequel . qualify ( 'projects' , 'name' ) ) . first if parent . nil? warn "Unknown parent for repo #{owner}/#{repo}" return nil end default_branch = retrieve_default_branch ( parent [ :login ] , parent [ :name ] ) diff = retrieve_master_branch_diff ( owner , repo , default_branch , parent [ :login ] , parent [ :name ] , default_branch ) if diff . nil? or diff . empty? default_branch = retrieve_default_branch ( parent [ :login ] , parent [ :name ] , true ) diff = retrieve_master_branch_diff ( owner , repo , default_branch , parent [ :login ] , parent [ :name ] , default_branch ) end if diff . nil? or diff . empty? warn "No common ancestor between #{parent[:login]}/#{parent[:name]} and #{owner}/#{repo}" return nil else debug "Fork #{owner}/#{repo} is #{diff['ahead_by']} commits ahead and #{diff['behind_by']} commits behind #{parent[:login]}/#{parent[:name]}" end if diff [ 'ahead_by' ] . to_i > 0 earliest_diverging = diff [ 'commits' ] . sort_by { | x | x [ 'commit' ] [ 'author' ] [ 'date' ] } . first if earliest_diverging [ 'parents' ] . nil? likely_fork_point = ensure_commit ( parent [ :name ] , earliest_diverging [ 'sha' ] , parent [ 'login' ] ) else likely_fork_point = earliest_diverging [ 'parents' ] . map { | x | ensure_commit ( parent [ :name ] , x [ 'sha' ] , parent [ :login ] ) } . select { | x | ! x . nil? } . sort_by { | x | x [ :created_at ] } . last end forked_sha = likely_fork_point [ :sha ] else forked_sha = diff [ 'merge_base_commit' ] [ 'sha' ] end forked_commit = ensure_commit ( repo , forked_sha , owner ) ; debug "Fork commit for #{owner}/#{repo} is #{forked_sha}" unless forked_commit . nil? db [ :projects ] . filter ( :id => fork [ :id ] ) . update ( :forked_commit_id => forked_commit [ :id ] ) info "Repo #{owner}/#{repo} was forked at #{parent[:login]}/#{parent[:name]}:#{forked_sha}" end db [ :commits ] . where ( :sha => forked_sha ) . first end
198	def ensure_orgs ( user ) retrieve_orgs ( user ) . map { | o | save { ensure_participation ( user , o [ 'login' ] ) } } . select { | x | ! x . nil? } end
199	def ensure_participation ( user , organization , members = true ) org = ensure_org ( organization , members ) if org . nil? warn "Could not find organization #{organization}" return end usr = ensure_user ( user , false , false ) org_members = db [ :organization_members ] participates = org_members . first ( :user_id => usr [ :id ] , :org_id => org [ :id ] ) if participates . nil? org_members . insert ( :user_id => usr [ :id ] , :org_id => org [ :id ] ) info "Added participation #{organization} -> #{user}" org_members . first ( :user_id => usr [ :id ] , :org_id => org [ :id ] ) else debug "Participation #{organization} -> #{user} exists" participates end end
200	def ensure_org ( organization , members = true ) org = db [ :users ] . first ( :login => organization , :type => 'org' ) if org . nil? org = ensure_user ( organization , false , false ) if org [ :type ] != 'ORG' warn "User #{organization} is not an organization" return nil end end if members retrieve_org_members ( organization ) . map do | x | ensure_participation ( ensure_user ( x [ 'login' ] , false , false ) [ :login ] , organization , false ) end end org end
201	def ensure_commit_comments ( user , repo , sha ) commit_id = db [ :commits ] . first ( :sha => sha ) [ :id ] stored_comments = db [ :commit_comments ] . filter ( :commit_id => commit_id ) commit_comments = retrieve_commit_comments ( user , repo , sha ) not_saved = commit_comments . reduce ( [ ] ) do | acc , x | if stored_comments . find { | y | y [ :comment_id ] == x [ 'id' ] } . nil? acc << x else acc end end not_saved . map { | x | save { ensure_commit_comment ( user , repo , sha , x [ 'id' ] ) } } . select { | x | ! x . nil? } end
202	def ensure_watchers ( owner , repo ) currepo = ensure_repo ( owner , repo ) if currepo . nil? warn "Could not find repo #{owner}/#{repo} for retrieving watchers" return end watchers = db . from ( :watchers , :users ) . where ( Sequel . qualify ( 'watchers' , 'user_id' ) => Sequel . qualify ( 'users' , 'id' ) ) . where ( Sequel . qualify ( 'watchers' , 'repo_id' ) => currepo [ :id ] ) . select ( :login ) . all retrieve_watchers ( owner , repo ) . reduce ( [ ] ) do | acc , x | if watchers . find { | y | y [ :login ] == x [ 'login' ] } . nil? acc << x else acc end end . map { | x | save { ensure_watcher ( owner , repo , x [ 'login' ] ) } } . select { | x | ! x . nil? } end
203	def ensure_pull_requests ( owner , repo , refresh = false ) currepo = ensure_repo ( owner , repo ) if currepo . nil? warn "Could not find repo #{owner}/#{repo} for retrieving pull requests" return end raw_pull_reqs = if refresh retrieve_pull_requests ( owner , repo , refresh = true ) else pull_reqs = db [ :pull_requests ] . filter ( :base_repo_id => currepo [ :id ] ) . all retrieve_pull_requests ( owner , repo ) . reduce ( [ ] ) do | acc , x | if pull_reqs . find { | y | y [ :pullreq_id ] == x [ 'number' ] } . nil? acc << x else acc end end end raw_pull_reqs . map { | x | save { ensure_pull_request ( owner , repo , x [ 'number' ] ) } } . select { | x | ! x . nil? } end
204	def ensure_pull_request_history ( id , ts , act , actor ) user = unless actor . nil? ensure_user ( actor , false , false ) end pull_req_history = db [ :pull_request_history ] entry = if [ 'opened' , 'merged' ] . include? act pull_req_history . first ( :pull_request_id => id , :action => act ) else pull_req_history . first ( :pull_request_id => id , :created_at => ( ts - 3 ) .. ( ts + 3 ) , :action => act ) end if entry . nil? pull_req_history . insert ( :pull_request_id => id , :created_at => ts , :action => act , :actor_id => unless user . nil? then user [ :id ] end ) info "Added pullreq_event (#{id}) -> (#{act}) by (#{actor}) timestamp #{ts}" else debug "Pull request (#{id}) event (#{act}) by (#{actor}) timestamp #{ts} exists" if entry [ :actor_id ] . nil? and not user . nil? pull_req_history . where ( :pull_request_id => id , :created_at => ( ts - 3 ) .. ( ts + 3 ) , :action => act ) . update ( :actor_id => user [ :id ] ) info "Updated pull request (#{id}) event (#{act}) timestamp #{ts}, actor -> #{user[:login]}" end end end
205	def pr_is_intra_branch ( req ) return false unless pr_has_head_repo ( req ) if req [ 'head' ] [ 'repo' ] [ 'owner' ] [ 'login' ] == req [ 'base' ] [ 'repo' ] [ 'owner' ] [ 'login' ] and req [ 'head' ] [ 'repo' ] [ 'full_name' ] == req [ 'base' ] [ 'repo' ] [ 'full_name' ] true else false end end
206	def ensure_forks ( owner , repo ) currepo = ensure_repo ( owner , repo ) if currepo . nil? warn "Could not find repo #{owner}/#{repo} for retrieving forks" return end existing_forks = db . from ( :projects , :users ) . where ( Sequel . qualify ( 'users' , 'id' ) => Sequel . qualify ( 'projects' , 'owner_id' ) ) . where ( Sequel . qualify ( 'projects' , 'forked_from' ) => currepo [ :id ] ) . select ( Sequel . qualify ( 'projects' , 'name' ) , :login ) . all retrieve_forks ( owner , repo ) . reduce ( [ ] ) do | acc , x | if existing_forks . find do | y | forked_repo_owner = x [ 'url' ] . split ( / \/ / ) [ 4 ] forked_repo_name = x [ 'url' ] . split ( / \/ / ) [ 5 ] y [ :login ] == forked_repo_owner && y [ :name ] == forked_repo_name end . nil? acc << x else acc end end . map { | x | save { ensure_fork ( owner , repo , x [ 'id' ] ) } } . select { | x | ! x . nil? } end
207	def ensure_fork ( owner , repo , fork_id ) fork = retrieve_fork ( owner , repo , fork_id ) if fork . nil? warn "Could not retrieve fork #{owner}/#{repo} -> #{fork_id}" return end fork_name = if fork [ 'full_name' ] . nil? then fork [ 'url' ] . split ( / \/ / ) [ 4 .. 5 ] . join ( '/' ) else fork [ 'full_name' ] end fork_owner = fork_name . split ( / \/ / ) [ 0 ] fork_name = fork_name . split ( / \/ / ) [ 1 ] r = ensure_repo ( fork_owner , fork_name , true ) if r . nil? warn "Could not add #{fork_owner}/#{fork_name} as fork of #{owner}/#{repo}" else info "Added fork #{fork_owner}/#{fork_name} of #{owner}/#{repo}" end r end
208	def ensure_issues ( owner , repo ) currepo = ensure_repo ( owner , repo ) if currepo . nil? warn "Could not find repo #{owner}/#{repo} for retrieving issues" return end issues = db [ :issues ] . filter ( :repo_id => currepo [ :id ] ) . all raw_issues = retrieve_issues ( owner , repo ) . reduce ( [ ] ) do | acc , x | if issues . find { | y | y [ :issue_id ] == x [ 'number' ] } . nil? acc << x else acc end end raw_issues . map { | x | save { ensure_issue ( owner , repo , x [ 'number' ] ) } } . select { | x | ! x . nil? } end
209	def ensure_issue ( owner , repo , issue_id , events = true , comments = true , labels = true ) issues = db [ :issues ] repository = ensure_repo ( owner , repo ) if repository . nil? warn "Could not find repo #{owner}/#{repo} for retrieving issue #{issue_id}" return end cur_issue = issues . first ( :issue_id => issue_id , :repo_id => repository [ :id ] ) retrieved = retrieve_issue ( owner , repo , issue_id ) if retrieved . nil? warn "Could not retrieve issue #{owner}/#{repo} -> #{issue_id}" return end pull_req = unless retrieved [ 'pull_request' ] . nil? or retrieved [ 'pull_request' ] [ 'patch_url' ] . nil? debug "Issue #{owner}/#{repo}->#{issue_id} is a pull request" ensure_pull_request ( owner , repo , issue_id , false , false , false ) end if cur_issue . nil? reporter = ensure_user ( retrieved [ 'user' ] [ 'login' ] , false , false ) assignee = unless retrieved [ 'assignee' ] . nil? ensure_user ( retrieved [ 'assignee' ] [ 'login' ] , false , false ) end issues . insert ( :repo_id => repository [ :id ] , :assignee_id => unless assignee . nil? then assignee [ :id ] end , :reporter_id => reporter [ :id ] , :issue_id => issue_id , :pull_request => if pull_req . nil? then false else true end , :pull_request_id => unless pull_req . nil? then pull_req [ :id ] end , :created_at => date ( retrieved [ 'created_at' ] ) ) info "Added issue #{owner}/#{repo} -> #{issue_id}" else debug "Issue #{owner}/#{repo}->#{issue_id} exists" if cur_issue [ :pull_request ] == false and not pull_req . nil? info "Updated issue #{owner}/#{repo}->#{issue_id} as pull request" issues . filter ( :issue_id => issue_id , :repo_id => repository [ :id ] ) . update ( :pull_request => true , :pull_request_id => pull_req [ :id ] ) end end ensure_issue_events ( owner , repo , issue_id ) if events ensure_issue_comments ( owner , repo , issue_id ) if comments ensure_issue_labels ( owner , repo , issue_id ) if labels issues . first ( :issue_id => issue_id , :repo_id => repository [ :id ] ) end
210	def ensure_issue_events ( owner , repo , issue_id ) currepo = ensure_repo ( owner , repo ) if currepo . nil? warn "Could not find repository #{owner}/#{repo} for retrieving events for issue #{issue_id}" return end issue = ensure_issue ( owner , repo , issue_id , false , false , false ) if issue . nil? warn "Could not find issue #{owner}/#{repo} -> #{issue_id} for retrieving events" return end retrieve_issue_events ( owner , repo , issue_id ) . reduce ( [ ] ) do | acc , x | if db [ :issue_events ] . first ( :issue_id => issue [ :id ] , :event_id => x [ 'id' ] ) . nil? acc << x else acc end end . map { | x | save { ensure_issue_event ( owner , repo , issue_id , x [ 'id' ] ) } } . select { | x | ! x . nil? } end
211	def ensure_issue_event ( owner , repo , issue_id , event_id ) issue = ensure_issue ( owner , repo , issue_id , false , false , false ) if issue . nil? warn "Could not find issue #{owner}/#{repo} -> #{issue_id} for retrieving event #{event_id}" return end issue_event_str = "#{owner}/#{repo} -> #{issue_id}/#{event_id}" curevent = db [ :issue_events ] . first ( :issue_id => issue [ :id ] , :event_id => event_id ) if curevent . nil? retrieved = retrieve_issue_event ( owner , repo , issue_id , event_id ) if retrieved . nil? warn "Could not retrieve issue_event #{owner}/#{repo} -> #{issue_id}/#{issue_event_str}" return elsif retrieved [ 'actor' ] . nil? warn "Could not find issue_event_actor #{owner}/#{repo} -> #{issue_id}/#{issue_event_str}" return end actor = ensure_user ( retrieved [ 'actor' ] [ 'login' ] , false , false ) action_specific = case retrieved [ 'event' ] when "referenced" then retrieved [ 'commit_id' ] when "merged" then retrieved [ 'commit_id' ] when "closed" then retrieved [ 'commit_id' ] else nil end if retrieved [ 'event' ] == 'assigned' def update_assignee ( owner , repo , issue , actor ) db [ :issues ] . first ( :id => issue [ :id ] ) . update ( :assignee_id => actor [ :id ] ) info "Updated #{owner}/#{repo} -> #{issue[:id]}, assignee -> #{actor[:id]}" end if issue [ :assignee_id ] . nil? then update_assignee ( owner , repo , issue , actor ) else existing = db [ :issue_events ] . filter ( :issue_id => issue [ :id ] , :action => 'assigned' ) . order ( Sequel . desc ( :created_at ) ) . first if existing . nil? update_assignee ( owner , repo , issue , actor ) elsif date ( existing [ :created_at ] ) < date ( retrieved [ 'created_at' ] ) update_assignee ( owner , repo , issue , actor ) end end end db [ :issue_events ] . insert ( :event_id => event_id , :issue_id => issue [ :id ] , :actor_id => unless actor . nil? then actor [ :id ] end , :action => retrieved [ 'event' ] , :action_specific => action_specific , :created_at => date ( retrieved [ 'created_at' ] ) ) info "Added issue_event #{owner}/#{repo} -> #{issue_id}/#{issue_event_str}" db [ :issue_events ] . first ( :issue_id => issue [ :id ] , :event_id => event_id ) else debug "Issue event #{owner}/#{repo} -> #{issue_id}/#{issue_event_str} exists" curevent end end
212	def ensure_issue_comments ( owner , repo , issue_id , pull_req_id = nil ) currepo = ensure_repo ( owner , repo ) if currepo . nil? warn "Could not find repository #{owner}/#{repo} for retrieving issue comments for issue #{issue_id}" return end issue = if pull_req_id . nil? ensure_issue ( owner , repo , issue_id , false , false , false ) else db [ :issues ] . first ( :pull_request_id => pull_req_id ) end if issue . nil? warn "Could not find issue #{owner}/#{repo} -> #{issue_id} for retrieving issue comments" return end retrieve_issue_comments ( owner , repo , issue_id ) . reduce ( [ ] ) do | acc , x | if db [ :issue_comments ] . first ( :issue_id => issue [ :id ] , :comment_id => x [ 'id' ] ) . nil? acc << x else acc end end . map { | x | save { ensure_issue_comment ( owner , repo , issue_id , x [ 'id' ] , pull_req_id ) } } . select { | x | ! x . nil? } end
213	def ensure_issue_comment ( owner , repo , issue_id , comment_id , pull_req_id = nil ) issue = if pull_req_id . nil? ensure_issue ( owner , repo , issue_id , false , false , false ) else db [ :issues ] . first ( :pull_request_id => pull_req_id ) end if issue . nil? warn "Could not find issue #{owner}/#{repo} -> #{issue_id} for retrieving comment #{comment_id}" return end issue_comment_str = "#{owner}/#{repo} -> #{issue_id}/#{comment_id}" curcomment = db [ :issue_comments ] . first ( :issue_id => issue [ :id ] , :comment_id => comment_id ) if curcomment . nil? retrieved = retrieve_issue_comment ( owner , repo , issue_id , comment_id ) if retrieved . nil? warn "Could not retrieve issue_comment #{issue_comment_str}" return end user = ensure_user ( retrieved [ 'user' ] [ 'login' ] , false , false ) db [ :issue_comments ] . insert ( :comment_id => comment_id , :issue_id => issue [ :id ] , :user_id => unless user . nil? then user [ :id ] end , :created_at => date ( retrieved [ 'created_at' ] ) ) info "Added issue_comment #{issue_comment_str}" db [ :issue_comments ] . first ( :issue_id => issue [ :id ] , :comment_id => comment_id ) else debug "Issue comment #{issue_comment_str} exists" curcomment end end
214	def ensure_labels ( owner , repo ) currepo = ensure_repo ( owner , repo ) if currepo . nil? warn "Could not find #{owner}/#{repo} for retrieving issue labels" return end repo_labels = db [ :repo_labels ] . filter ( :repo_id => currepo [ :id ] ) . all retrieve_repo_labels ( owner , repo ) . reduce ( [ ] ) do | acc , x | if repo_labels . find { | y | y [ :name ] == x [ 'name' ] } . nil? acc << x else acc end end . map { | x | save { ensure_repo_label ( owner , repo , x [ 'name' ] ) } } . select { | x | ! x . nil? } end
215	def ensure_repo_label ( owner , repo , name ) currepo = ensure_repo ( owner , repo ) if currepo . nil? warn "Could not find #{owner}/#{repo} for retrieving label #{name}" return end label = db [ :repo_labels ] . first ( :repo_id => currepo [ :id ] , :name => name ) if label . nil? retrieved = retrieve_repo_label ( owner , repo , name ) if retrieved . nil? warn "Could not retrieve repo_label #{owner}/#{repo} -> #{name}" return end db [ :repo_labels ] . insert ( :repo_id => currepo [ :id ] , :name => name ) info "Added repo_label #{owner}/#{repo} -> #{name}" db [ :repo_labels ] . first ( :repo_id => currepo [ :id ] , :name => name ) else label end end
216	def ensure_issue_labels ( owner , repo , issue_id ) issue = ensure_issue ( owner , repo , issue_id , false , false , false ) if issue . nil? warn "Could not find issue #{owner}/#{repo} -> #{issue_id} for retrieving labels" return end issue_labels = db . from ( :issue_labels , :repo_labels ) . where ( Sequel . qualify ( 'issue_labels' , 'label_id' ) => Sequel . qualify ( 'repo_labels' , 'id' ) ) . where ( Sequel . qualify ( 'issue_labels' , 'issue_id' ) => issue [ :id ] ) . select ( Sequel . qualify ( 'repo_labels' , 'name' ) ) . all retrieve_issue_labels ( owner , repo , issue_id ) . reduce ( [ ] ) do | acc , x | if issue_labels . find { | y | y [ :name ] == x [ 'name' ] } . nil? acc << x else acc end end . map { | x | save { ensure_issue_label ( owner , repo , issue [ :issue_id ] , x [ 'name' ] ) } } . select { | x | ! x . nil? } end
217	def ensure_issue_label ( owner , repo , issue_id , name ) issue = ensure_issue ( owner , repo , issue_id , false , false , false ) if issue . nil? warn "Could not find issue #{owner}/#{repo} -> #{issue_id} to assign label #{name}" return end label = ensure_repo_label ( owner , repo , name ) if label . nil? warn "Could not find repo label #{owner}/#{repo} -> #{name}" return end issue_lbl = db [ :issue_labels ] . first ( :label_id => label [ :id ] , :issue_id => issue [ :id ] ) if issue_lbl . nil? db [ :issue_labels ] . insert ( :label_id => label [ :id ] , :issue_id => issue [ :id ] , ) info "Added issue_label #{name} to issue #{owner}/#{repo} -> #{issue_id}" db [ :issue_labels ] . first ( :label_id => label [ :id ] , :issue_id => issue [ :id ] ) else debug "Issue label #{name} to issue #{owner}/#{repo} -> #{issue_id} exists" issue_lbl end end
218	def transaction ( & block ) db persister result = nil start_time = Time . now begin db . transaction ( :rollback => :reraise , :isolation => :repeatable , :retry_on => @retry_on_error , :num_retries => 3 ) do result = yield block end total = Time . now . to_ms - start_time . to_ms debug "Transaction committed (#{total} ms)" result rescue StandardError => e total = Time . now . to_ms - start_time . to_ms warn "Transaction failed (#{total} ms)" raise e ensure GC . start end end
219	def store_commit ( c , repo , user ) commits = db [ :commits ] commit = commits . first ( :sha => c [ 'sha' ] ) if commit . nil? author = commit_user ( c [ 'author' ] , c [ 'commit' ] [ 'author' ] ) commiter = commit_user ( c [ 'committer' ] , c [ 'commit' ] [ 'committer' ] ) repository = ensure_repo ( user , repo ) if repository . nil? warn "Could not find repo #{user}/#{repo} for storing commit #{c['sha']}" end commits . insert ( :sha => c [ 'sha' ] , :author_id => author [ :id ] , :committer_id => commiter [ :id ] , :project_id => if repository . nil? then nil else repository [ :id ] end , :created_at => date ( c [ 'commit' ] [ 'author' ] [ 'date' ] ) ) info "Added commit #{user}/#{repo} -> #{c['sha']} " commits . first ( :sha => c [ 'sha' ] ) else debug "Commit #{user}/#{repo} -> #{c['sha']} exists" commit end end
220	def log ( level , msg ) case level when :fatal then loggerr . fatal ( retrieve_caller + msg ) when :error then loggerr . error ( retrieve_caller + msg ) when :warn then loggerr . warn ( retrieve_caller + msg ) when :info then loggerr . info ( retrieve_caller + msg ) when :debug then loggerr . debug ( retrieve_caller + msg ) else loggerr . debug ( retrieve_caller + msg ) end end
221	def paged_api_request ( url , pages = config ( :mirror_history_pages_back ) , last = nil ) url = ensure_max_per_page ( url ) data = api_request_raw ( url ) return [ ] if data . nil? unless data . meta [ 'link' ] . nil? links = parse_links ( data . meta [ 'link' ] ) last = links [ 'last' ] if last . nil? if pages > 0 pages = pages - 1 if pages == 0 return parse_request_result ( data ) end end if links [ 'next' ] . nil? parse_request_result ( data ) else parse_request_result ( data ) | paged_api_request ( links [ 'next' ] , pages , last ) end else parse_request_result ( data ) end end
222	def last_updated ( url , etag ) begin ts = Time . now response = do_request ( url , '' , etag ) info "Successful etag request. URL: #{url}, Etag: #{etag}, Remaining: #{@remaining}, Total: #{Time.now.to_ms - ts.to_ms} ms" rescue OpenURI :: HTTPError => e response = e . io if response . status . first != '304' etag_request_error_message ( url , e , etag ) raise e end end return Time . parse ( response . meta [ 'last-modified' ] ) unless response . meta [ 'last-modified' ] . nil? return Time . at ( 86400 ) end
223	def num_pages ( url ) url = ensure_max_per_page ( url ) data = api_request_raw ( url ) if data . nil? or data . meta . nil? or data . meta [ 'link' ] . nil? return 1 end links = parse_links ( data . meta [ 'link' ] ) if links . nil? or links [ 'last' ] . nil? return 1 end params = CGI :: parse ( URI :: parse ( links [ 'last' ] ) . query ) params [ 'page' ] [ 0 ] . to_i end
224	def parse_links ( links ) links . split ( / / ) . reduce ( { } ) do | acc , x | matches = x . strip . match ( / \" \" / ) acc [ matches [ 2 ] ] = matches [ 1 ] acc end end
225	def parse_request_result ( result ) if result . nil? [ ] else json = result . read if json . nil? [ ] else r = JSON . parse ( json ) if result . meta [ 'etag' ] and r . class != Array r [ 'etag' ] = result . meta [ 'etag' ] end r end end end
226	def api_request_raw ( url , media_type = '' ) begin start_time = Time . now contents = do_request ( url , media_type ) total = Time . now . to_ms - start_time . to_ms info "Successful request. URL: #{url}, Remaining: #{@remaining}, Total: #{total} ms" contents rescue OpenURI :: HTTPError => e @remaining = e . io . meta [ 'x-ratelimit-remaining' ] . to_i @reset = e . io . meta [ 'x-ratelimit-reset' ] . to_i case e . io . status [ 0 ] . to_i when 400 , 403 , 404 , 409 , 422 then warn request_error_msg ( url , e ) return nil when 401 warn request_error_msg ( url , e ) warn "Unauthorised request with token: #{@token}" raise e when 451 warn request_error_msg ( url , e ) warn "Repo was taken down (DMCA)" return nil else warn request_error_msg ( url , e ) raise e end rescue StandardError => e warn error_msg ( url , e ) raise e ensure if @remaining < @req_limit to_sleep = @reset - Time . now . to_i + 2 warn "Request limit reached, reset in: #{to_sleep} secs" t = Thread . new do slept = 0 while true do debug "Sleeping for #{to_sleep - slept} seconds" sleep 1 slept += 1 end end sleep ( [ 0 , to_sleep ] . max ) t . exit end end end
227	def attach_to ( ip ) TCPSocket . instance_eval do ( class << self ; self ; end ) . instance_eval do alias_method :original_open , :open case RUBY_VERSION when / / , / / define_method ( :open ) do | conn_address , conn_port | original_open ( conn_address , conn_port , ip ) end else define_method ( :open ) do | conn_address , conn_port , local_host , local_port | original_open ( conn_address , conn_port , ip , local_port ) end end end end result = begin yield rescue StandardError => e raise e ensure TCPSocket . instance_eval do ( class << self ; self ; end ) . instance_eval do alias_method :open , :original_open remove_method :original_open end end end result end
228	def connect ( adapter , settings ) driver = ADAPTERS [ adapter . intern ] driver . new ( settings ) end
229	def retrieve_commit ( repo , sha , user ) commit = persister . find ( :commits , { 'sha' => "#{sha}" } ) if commit . empty? url = ghurl "repos/#{user}/#{repo}/commits/#{sha}" c = api_request ( url ) if c . nil? or c . empty? return end if config ( :commit_handling ) == 'trim' c [ 'files' ] . each { | file | file . delete ( 'patch' ) } end persister . store ( :commits , c ) info "Added commit #{user}/#{repo} -> #{sha}" c else debug "Commit #{user}/#{repo} -> #{sha} exists" commit . first end end
230	def retrieve_commits ( repo , sha , user , pages = - 1 ) url = if sha . nil? ghurl "repos/#{user}/#{repo}/commits" else ghurl "repos/#{user}/#{repo}/commits?sha=#{sha}" end commits = restricted_page_request ( url , pages ) commits . map do | c | retrieve_commit ( repo , c [ 'sha' ] , user ) end . select { | x | not x . nil? } end
231	def retrieve_orgs ( user ) url = ghurl "users/#{user}/orgs" orgs = paged_api_request ( url ) orgs . map { | o | retrieve_org ( o [ 'login' ] ) } end
232	def retrieve_watchers ( user , repo ) repo_bound_items ( user , repo , :watchers , [ "repos/#{user}/#{repo}/stargazers" ] , { 'repo' => repo , 'owner' => user } , 'login' , item = nil , refresh = false , order = :desc ) end
233	def retrieve_watcher ( user , repo , watcher ) repo_bound_item ( user , repo , watcher , :watchers , [ "repos/#{user}/#{repo}/stargazers" ] , { 'repo' => repo , 'owner' => user } , 'login' , order = :desc ) end
234	def get_repo_events ( owner , repo ) url = ghurl ( "repos/#{owner}/#{repo}/events" ) r = paged_api_request ( url ) r . each do | e | unless get_event ( e [ 'id' ] ) . empty? debug "Repository event #{owner}/#{repo} -> #{e['type']}-#{e['id']} already exists" else persister . store ( :events , e ) info "Added event for repository #{owner}/#{repo} -> #{e['type']}-#{e['id']}" end end persister . find ( :events , { 'repo.name' => "#{owner}/#{repo}" } ) end
235	def retrieve_master_branch_diff ( owner , repo , branch , parent_owner , parent_repo , parent_branch ) branch = retrieve_default_branch ( owner , repo ) if branch . nil? parent_branch = retrieve_default_branch ( parent_owner , parent_repo ) if parent_branch . nil? return nil if branch . nil? or parent_branch . nil? cmp_url = "https://api.github.com/repos/#{parent_owner}/#{parent_repo}/compare/#{parent_branch}...#{owner}:#{branch}" api_request ( cmp_url ) end
236	def retrieve_default_branch ( owner , repo , refresh = false ) retrieved = retrieve_repo ( owner , repo , refresh ) return nil if retrieved . nil? master_branch = 'master' if retrieved [ 'default_branch' ] . nil? retrieved = retrieve_repo ( owner , repo , true ) return nil if retrieved . nil? end master_branch = retrieved [ 'default_branch' ] unless retrieved . nil? master_branch end
237	def process_options command = self @options = Trollop :: options ( command . args ) do command . prepare_options ( self ) banner <<-END END opt :config , 'config.yaml file location' , :short => 'c' , :default => 'config.yaml' opt :verbose , 'verbose mode' , :short => 'v' opt :addr , 'IP address to use for performing requests' , :short => 'a' , :type => String opt :token , 'GitHub OAuth token' , :type => String , :short => 't' opt :req_limit , 'Number or requests to leave on any provided account (in reqs/hour)' , :type => Integer , :short => 'l' opt :uniq , 'Unique name for this command. Will appear in logs.' , :type => String , :short => 'u' end end
238	def validate if options [ :config ] . nil? unless ( File . exist? ( "config.yaml" ) ) Trollop :: die "No config file in default location (#{Dir.pwd}). You need to specify the #{:config} parameter. Read the documentation on how to create a config.yaml file." end else Trollop :: die "Cannot find file #{options[:config]}" unless File . exist? ( options [ :config ] ) end unless @options [ :user ] . nil? if not Process . uid == 0 Trollop :: die "Option --user (-u) can only be specified by root" end begin Etc . getpwnam ( @options [ :user ] ) rescue ArgumentError Trollop :: die "No such user: #{@options[:user]}" end end end
239	def queue_client ( queue , key = queue , ack = :after , block ) stopped = false while not stopped begin conn = Bunny . new ( :host => config ( :amqp_host ) , :port => config ( :amqp_port ) , :username => config ( :amqp_username ) , :password => config ( :amqp_password ) ) conn . start ch = conn . create_channel debug "Queue setting prefetch to #{config(:amqp_prefetch)}" ch . prefetch ( config ( :amqp_prefetch ) ) debug "Queue connection to #{config(:amqp_host)} succeeded" x = ch . topic ( config ( :amqp_exchange ) , :durable => true , :auto_delete => false ) q = ch . queue ( queue , :durable => true ) q . bind ( x , :routing_key => key ) q . subscribe ( :block => true , :manual_ack => true ) do | delivery_info , properties , msg | if ack == :before ch . acknowledge ( delivery_info . delivery_tag ) end begin block . call ( msg ) ensure if ack != :before ch . acknowledge ( delivery_info . delivery_tag ) end end end rescue Bunny :: TCPConnectionFailed => e warn "Connection to #{config(:amqp_host)} failed. Retrying in 1 sec" sleep ( 1 ) rescue Bunny :: PossibleAuthenticationFailureError => e warn "Could not authenticate as #{conn.username}" rescue Bunny :: NotFound , Bunny :: AccessRefused , Bunny :: PreconditionFailed => e warn "Channel error: #{e}. Retrying in 1 sec" sleep ( 1 ) rescue Interrupt => _ stopped = true rescue StandardError => e raise e end end ch . close unless ch . nil? conn . close unless conn . nil? end
240	def read_value ( from , key ) return from if key . nil? or key == "" key . split ( / \. / ) . reduce ( { } ) do | acc , x | unless acc . nil? if acc . empty? acc = from [ x ] else if acc . has_key? ( x ) acc = acc [ x ] else return nil end end else return nil end end end
241	def location_filter ( location ) return nil if location . nil? location . strip . downcase . tr ( '#"<>[]' , '' ) . gsub ( / \/ / , '' ) . gsub ( / / , ' ' ) . gsub ( / / , '\1' ) end
242	def validate_usage! registered_topics = self . class . topics . map do | name , topic | topic . to_h . merge! ( usage_count : messages_buffer [ name ] &. count || 0 ) end used_topics = messages_buffer . map do | name , usage | topic = self . class . topics [ name ] || Responders :: Topic . new ( name , registered : false ) topic . to_h . merge! ( usage_count : usage . count ) end result = Karafka :: Schemas :: ResponderUsage . call ( registered_topics : registered_topics , used_topics : used_topics ) return if result . success? raise Karafka :: Errors :: InvalidResponderUsageError , result . errors end
243	def validate_options! return true unless self . class . options_schema messages_buffer . each_value do | messages_set | messages_set . each do | message_data | result = self . class . options_schema . call ( message_data . last ) next if result . success? raise Karafka :: Errors :: InvalidResponderMessageOptionsError , result . errors end end end
244	def deliver! messages_buffer . each_value do | data_elements | data_elements . each do | data , options | mapped_topic = Karafka :: App . config . topic_mapper . outgoing ( options [ :topic ] ) external_options = options . merge ( topic : mapped_topic ) producer ( options ) . call ( data , external_options ) end end end
245	def notice_signal ( signal ) Thread . new do Karafka . monitor . instrument ( 'process.notice_signal' , caller : self , signal : signal ) end end
246	def embedding_lookup ( params , ids , partition_strategy : "mod" , name : nil , validate_indices : true , max_norm : nil ) _embedding_lookup_and_transform ( params , ids , partition_strategy : partition_strategy , name : name , max_norm : max_norm , transform_fn : nil ) end
247	def _embedding_lookup_and_transform ( params , ids , partition_strategy : "mod" , name : nil , max_norm : nil , transform_fn : nil ) raise TensorStream :: ValueError , "Need at least one param" if params . nil? params = [ params ] unless params . is_a? ( Array ) TensorStream . name_scope ( name , "embedding_lookup" , values : params + [ ids ] ) do | name | np = params . size ids = TensorStream . convert_to_tensor ( ids , name : "ids" ) if ( np == 1 ) && ( transform_fn . nil? || ( ids . shape . size == 1 ) ) result = nil TensorStream . colocate_with ( params [ 0 ] ) do result = _clip ( TensorStream . gather ( params [ 0 ] , ids , name : name ) , ids , max_norm ) result = transform_fn . call ( result ) if transform_fn end return TensorStream . identity ( result ) else flat_ids = TensorStream . reshape ( ids , [ - 1 ] ) original_indices = TensorStream . range ( TensorStream . size ( flat_ids ) ) p_assignments = nil new_ids = nil if partition_strategy == "mod" p_assignments = flat_ids % np new_ids = floor_div ( flat_ids , np ) elsif partition_strategy == "div" raise "not yet supported!" else raise TensorStream :: ValueError , "Unrecognized partition strategy: " + partition_strategy end p_assignments = TensorStream . cast ( p_assignments , :int32 ) gather_ids = TensorStream . dynamic_partition ( new_ids , p_assignments , np ) pindices = TensorStream . dynamic_partition ( original_indices , p_assignments , np ) partitioned_result = [ ] ( 0 ... np ) . each do | p | pids = gather_ids [ p ] result = nil TensorStream . colocate_with ( params [ p ] ) do result = TensorStream . gather ( params [ p ] , pids ) if transform_fn result = transform_fn . call ( _clip ( result , pids , max_norm ) ) end end partitioned_result << result end ret = TensorStream . dynamic_stitch ( pindices , partitioned_result , name : name ) if transform_fn . nil? element_shape_s = params [ 0 ] . shape [ 1 .. - 1 ] params [ 1 .. - 1 ] . each { | p | element_shape_s = element_shape_s . merge_with ( p . shape [ 1 .. - 1 ] ) } else element_shape_s = ret . shape [ 1 .. - 1 ] end element_shape_d = if element_shape_s . fully_defined? element_shape_s elsif transform_fn . nil? TensorStream . colocate_with ( params [ 0 ] ) do params_shape = TensorStream . shape ( params [ 0 ] ) params_shape [ 1 .. - 1 ] end else TensorStream . shape ( ret ) [ 1 .. - 1 ] end ret = TensorStream . reshape ( ret , TensorStream . concat ( [ TensorStream . shape ( ids ) , element_shape_d ] , 0 ) ) ret = _clip ( ret , ids , max_norm ) unless transform_fn ret end end end
248	def load ( pbfile ) f = File . new ( pbfile , "r" ) lines = [ ] while ! f . eof? && ( str = f . readline . strip ) lines << str end evaluate_lines ( lines ) end
249	def assert_equal ( x , y , data : nil , summarize : nil , message : nil , name : nil ) _op ( :assert_equal , x , y , data : data , summarize : summarize , message : message , name : name ) end
250	def gradients ( tensor_ys , wrt_xs , name : "gradients" , stop_gradients : nil ) tensor_ys = tensor_ys . op gs = wrt_xs . map ( & :op ) . collect { | x | stops = stop_gradients ? stop_gradients . map ( & :name ) . join ( "_" ) : "" gradient_program_name = "grad_#{tensor_ys.name}_#{x.name}_#{stops}" . to_sym tensor_graph = tensor_ys . graph tensor_program = if tensor_graph . node_added? ( gradient_program_name ) tensor_graph . get_node ( gradient_program_name ) else tensor_graph . name_scope ( "gradient_wrt_#{x.name}" ) do derivative_ops = TensorStream :: MathGradients . derivative ( tensor_ys , x , graph : tensor_graph , stop_gradients : stop_gradients ) tensor_graph . add_node! ( gradient_program_name , derivative_ops ) end end tensor_program } gs end
251	def random_normal ( shape , dtype : :float32 , mean : 0.0 , stddev : 1.0 , seed : nil , name : nil ) options = { dtype : dtype , mean : mean , stddev : stddev , seed : seed , name : name } _op ( :random_standard_normal , shape , options ) end
252	def eye ( num_rows , num_columns : nil , dtype : :float32 , name : nil ) _op ( :eye , num_rows , num_columns || num_rows , data_type : dtype , name : name ) end
253	def glorot_uniform_initializer ( seed : nil , dtype : nil ) TensorStream :: Initializer . new ( -> { _op ( :glorot_uniform , seed : seed , data_type : dtype ) } ) end
254	def random_uniform_initializer ( minval : 0 , maxval : 1 , seed : nil , dtype : nil ) TensorStream :: Initializer . new ( -> { _op ( :random_uniform , minval : 0 , maxval : 1 , seed : seed , data_type : dtype ) } ) end
255	def slice ( input , start , size , name : nil ) _op ( :slice , input , start , size : size , name : name ) end
256	def ones ( shape , dtype : :float32 , name : nil ) _op ( :ones , shape , data_type : dtype , name : name ) end
257	def logical_and ( input_a , input_b , name : nil ) check_data_types ( input_a , input_b ) _op ( :logical_and , input_a , input_b , name : name ) end
258	def reduce_mean ( input_tensor , axis = nil , keepdims : false , name : nil ) reduce ( :mean , input_tensor , axis , keepdims : keepdims , name : name ) end
259	def concat ( values , axis , name : "concat" ) if values . is_a? ( Array ) _op ( :concat , axis , * values , name : name ) else _op ( :concat , axis , values , name : name ) end end
260	def dynamic_partition ( data , partitions , num_partitions , name : nil ) result = _op ( :dynamic_partition , data , partitions , num_partitions : num_partitions , name : nil ) num_partitions . times . map do | index | result [ index ] end end
261	def where ( condition , true_t = nil , false_t = nil , name : nil ) _op ( :where , condition , true_t , false_t , name : name ) end
262	def asin ( input , name : nil ) check_allowed_types ( input , FLOATING_POINT_TYPES ) _op ( :asin , input , name : name ) end
263	def acos ( input , name : nil ) check_allowed_types ( input , FLOATING_POINT_TYPES ) _op ( :acos , input , name : name ) end
264	def atan ( input , name : nil ) check_allowed_types ( input , FLOATING_POINT_TYPES ) _op ( :atan , input , name : name ) end
265	def cast ( input , dtype , name : nil ) input = convert_to_tensor ( input ) return input if input . data_type == dtype _op ( :cast , input , data_type : dtype , name : name ) end
266	def print ( input , data , message : nil , name : nil ) _op ( :print , input , data , message : message , name : name ) end
267	def sec ( input , name : nil ) check_allowed_types ( input , FLOATING_POINT_TYPES ) _op ( :sec , input , name : name ) end
268	def sqrt ( input , name : nil ) check_allowed_types ( input , FLOATING_POINT_TYPES ) _op ( :sqrt , input , name : name ) end
269	def log ( input , name : nil ) check_allowed_types ( input , FLOATING_POINT_TYPES ) _op ( :log , input , name : name ) end
270	def exp ( input , name : nil ) check_allowed_types ( input , FLOATING_POINT_TYPES ) _op ( :exp , input , name : name ) end
271	def pad ( tensor , paddings , mode : "CONSTANT" , name : nil ) _op ( :pad , tensor , paddings , mode : mode , name : name ) end
272	def gather ( params , indices , validate_indices : nil , name : nil , axis : 0 ) _op ( :gather , params , indices , validate_indices : validate_indices , name : name , axis : axis ) end
273	def pack ( values , axis : 0 , name : "pack" ) _op ( :stack , * values , axis : axis , name : name ) end
274	def unpack ( value , num : nil , axis : 0 , name : "unpack" ) unstack ( value , num : num , axis : axis , name : name ) end
275	def case ( args = { } ) args = args . dup default = args . delete ( :default ) exclusive = args . delete ( :exclusive ) strict = args . delete ( :strict ) name = args . delete ( :name ) predicates = [ ] functions = [ ] args . each do | k , v | raise "Invalid argment or option #{k}" unless k . is_a? ( Tensor ) predicates << k functions << ( v . is_a? ( Proc ) ? v . call : v ) end _op ( :case , predicates , default , * functions , exclusive : exclusive , strict : strict , name : name ) end
276	def i_op ( code , * args ) options = if args . last . is_a? ( Hash ) args . pop else { } end args << options . merge ( internal : true ) Graph . get_default_graph . add_op! ( code . to_sym , * args ) end
277	def broadcast_dimensions ( input , dims = [ ] ) return input if dims . empty? d = dims . shift if input . is_a? ( Array ) && ( get_rank ( input ) - 1 ) == dims . size row_to_dup = input . collect { | item | broadcast_dimensions ( item , dims . dup ) } row_to_dup + Array . new ( d ) { row_to_dup } . flatten ( 1 ) elsif input . is_a? ( Array ) Array . new ( d ) { broadcast_dimensions ( input , dims . dup ) } else Array . new ( d + 1 ) { input } end end
278	def vector_op ( vector , vector2 , switch = false , safe = true , & block ) if get_rank ( vector ) < get_rank ( vector2 ) duplicated = Array . new ( vector2 . size ) { vector } return vector_op ( duplicated , vector2 , switch , & block ) end return yield ( vector , vector2 ) unless vector . is_a? ( Array ) vector . each_with_index . collect { | input , index | next vector_op ( input , vector2 , switch , & block ) if input . is_a? ( Array ) && get_rank ( vector ) > get_rank ( vector2 ) if safe && vector2 . is_a? ( Array ) next nil if vector2 . size != 1 && index >= vector2 . size end z = if vector2 . is_a? ( Array ) if index < vector2 . size vector2 [ index ] else raise "incompatible tensor shapes used during op" if vector2 . size != 1 vector2 [ 0 ] end else vector2 end if input . is_a? ( Array ) vector_op ( input , z , switch , & block ) else switch ? yield ( z , input ) : yield ( input , z ) end } . compact end
279	def transpose_with_perm ( arr , new_arr , shape , new_shape , perm ) arr_size = shape . reduce ( :* ) divisors = shape . dup . drop ( 1 ) . reverse . inject ( [ 1 ] ) { | a , s | a << s * a . last } . reverse multipliers = new_shape . dup . drop ( 1 ) . reverse . inject ( [ 1 ] ) { | a , s | a << s * a . last } . reverse arr_size . times do | p | ptr = p index = [ ] divisors . each_with_object ( index ) do | div , a | a << ( ptr / div . to_f ) . floor ptr = ptr % div end remaped = perm . map { | x | index [ x ] } ptr2 = 0 multipliers . each_with_index do | m , idx | ptr2 += remaped [ idx ] * m end new_arr [ ptr2 ] = arr [ p ] end [ new_arr , new_shape ] end
280	def add ( input_a , input_b , name : nil ) input_a , input_b = apply_data_type_coercion ( input_a , input_b ) _op ( :add , input_a , input_b , name : name ) end
281	def argmax ( input_a , axis = nil , name : nil , dimension : nil , output_type : :int32 ) check_allowed_types ( input_a , TensorStream :: Ops :: NUMERIC_TYPES ) check_allowed_types ( axis , TensorStream :: Ops :: INTEGER_TYPES ) _op ( :argmax , input_a , axis , name : name , dimension : dimension , output_type : output_type ) end
282	def ceil ( input_a , name : nil ) check_allowed_types ( input_a , TensorStream :: Ops :: FLOATING_POINT_TYPES ) _op ( :ceil , input_a , name : name ) end
283	def cos ( input_a , name : nil ) check_allowed_types ( input_a , TensorStream :: Ops :: FLOATING_POINT_TYPES ) _op ( :cos , input_a , name : name ) end
284	def floor ( input_a , name : nil ) check_allowed_types ( input_a , TensorStream :: Ops :: FLOATING_POINT_TYPES ) _op ( :floor , input_a , name : name ) end
285	def mod ( input_a , input_b , name : nil ) input_a , input_b = apply_data_type_coercion ( input_a , input_b ) _op ( :mod , input_a , input_b , name : name ) end
286	def pow ( input_a , input_b , name : nil ) input_a , input_b = apply_data_type_coercion ( input_a , input_b ) _op ( :pow , input_a , input_b , name : name ) end
287	def prod ( input_a , axis = nil , name : nil , keepdims : false ) check_allowed_types ( axis , TensorStream :: Ops :: INTEGER_TYPES ) input_a = TensorStream . convert_to_tensor ( input_a ) return input_a if input_a . shape . scalar? axis = cast_axis ( input_a , axis ) _op ( :prod , input_a , axis , name : name , keepdims : keepdims ) end
288	def random_uniform ( shape , name : nil , dtype : :float32 , minval : 0 , maxval : 1 , seed : nil ) _op ( :random_uniform , shape , name : name , dtype : dtype , minval : minval , maxval : maxval , seed : seed ) end
289	def range ( start = 0 , limit = 0 , delta = 1 , name : "range" , dtype : nil , output_type : :int32 ) _op ( :range , start , limit , delta , name : name , dtype : dtype , output_type : output_type ) end
290	def rank ( input , name : nil ) input = convert_to_tensor ( input ) return cons ( input . shape . ndims ) if input . shape . known? _op ( :rank , input , name : name ) end
291	def round ( input_a , name : nil ) check_allowed_types ( input_a , TensorStream :: Ops :: FLOATING_POINT_TYPES ) _op ( :round , input_a , name : name ) end
292	def rsqrt ( input_a , name : nil ) check_allowed_types ( input_a , TensorStream :: Ops :: FLOATING_POINT_TYPES ) _op ( :rsqrt , input_a , name : name ) end
293	def shape ( input , name : nil , out_type : :int32 ) return constant ( shape_eval ( input , out_type ) , dtype : out_type , name : "Shape/#{name}" ) if input . is_a? ( Array ) && ! input [ 0 ] . is_a? ( Tensor ) return constant ( input . shape . shape , dtype : out_type , name : "Shape/#{input.name}_c" ) if shape_full_specified ( input ) _op ( :shape , input , name : name , out_type : out_type ) end
294	def sigmoid ( input_a , name : nil ) check_allowed_types ( input_a , TensorStream :: Ops :: FLOATING_POINT_TYPES ) _op ( :sigmoid , input_a , name : name ) end
295	def sin ( input_a , name : nil ) check_allowed_types ( input_a , TensorStream :: Ops :: FLOATING_POINT_TYPES ) _op ( :sin , input_a , name : name ) end
296	def sub ( input_a , input_b , name : nil ) input_a , input_b = apply_data_type_coercion ( input_a , input_b ) _op ( :sub , input_a , input_b , name : name ) end
297	def sum ( input_a , axis_p = nil , axis : nil , name : nil , keepdims : false ) check_allowed_types ( axis_p , TensorStream :: Ops :: INTEGER_TYPES ) input_a = TensorStream . convert_to_tensor ( input_a ) return input_a if input_a . shape . scalar? axis_p = axis_p || axis axis_p = cast_axis ( input_a , axis_p ) _op ( :sum , input_a , axis_p , name : name , keepdims : keepdims ) end
298	def tan ( input_a , name : nil ) check_allowed_types ( input_a , TensorStream :: Ops :: FLOATING_POINT_TYPES ) _op ( :tan , input_a , name : name ) end
299	def tanh ( input_a , name : nil ) check_allowed_types ( input_a , TensorStream :: Ops :: FLOATING_POINT_TYPES ) _op ( :tanh , input_a , name : name ) end
300	def top_k ( input , k = 1 , sorted : true , name : nil ) result = _op ( :top_k , input , k , sorted : sorted , name : name ) [ result [ 0 ] , result [ 1 ] ] end
301	def zeros ( shape , dtype : :float32 , name : nil ) _op ( :zeros , shape , dtype : dtype , name : name ) end
302	def convert ( session , checkpoint_folder , output_file ) model_file = File . join ( checkpoint_folder , "model.yaml" ) TensorStream . graph . as_default do | current_graph | YamlLoader . new . load_from_string ( File . read ( model_file ) ) saver = TensorStream :: Train :: Saver . new saver . restore ( session , checkpoint_folder ) remove_nodes = Set . new ( current_graph . nodes . values . select { | op | op . is_a? ( TensorStream :: Operation ) && op . operation == :assign } . map { | op | op . consumers . to_a } . flatten . uniq ) output_buffer = TensorStream :: Yaml . new . get_string ( current_graph ) { | graph , node_key | node = graph . get_tensor_by_name ( node_key ) case node . operation when :variable_v2 value = node . container options = { value : value , data_type : node . data_type , shape : shape_eval ( value ) , } const_op = TensorStream :: Operation . new ( current_graph , inputs : [ ] , options : options ) const_op . name = node . name const_op . operation = :const const_op . data_type = node . data_type const_op . shape = TensorShape . new ( shape_eval ( value ) ) const_op when :assign nil else remove_nodes . include? ( node . name ) ? nil : node end } File . write ( output_file , output_buffer ) end end
303	def device ( device_name ) Thread . current [ "ts_graph_#{object_id}" ] ||= { } Thread . current [ "ts_graph_#{object_id}" ] [ :default_device ] ||= [ ] Thread . current [ "ts_graph_#{object_id}" ] [ :default_device ] << device_name begin yield ensure Thread . current [ "ts_graph_#{object_id}" ] [ :default_device ] . pop end end
304	def load_from_string ( buffer ) serialized_ops = YAML . safe_load ( buffer , [ Symbol ] , [ ] , true ) serialized_ops . each do | op_def | inputs = op_def [ :inputs ] . map { | i | @graph . get_tensor_by_name ( i ) } options = { } new_var = nil if op_def . dig ( :attrs , :container ) new_var = Variable . new ( op_def . dig ( :attrs , :data_type ) ) var_shape = op_def . dig ( :attrs , :container , :shape ) var_options = op_def . dig ( :attrs , :container , :options ) var_options [ :name ] = op_def [ :name ] new_var . prepare ( var_shape . size , var_shape , TensorStream . get_variable_scope , var_options ) options [ :container ] = new_var @graph . add_variable ( new_var , var_options ) end new_op = Operation . new ( @graph , inputs : inputs , options : op_def [ :attrs ] . merge ( options ) ) new_op . operation = op_def [ :op ] . to_sym new_op . name = op_def [ :name ] new_op . shape = TensorShape . new ( TensorStream :: InferShape . infer_shape ( new_op ) ) new_op . rank = new_op . shape . rank new_op . data_type = new_op . set_data_type ( op_def . dig ( :attrs , :data_type ) ) new_op . is_const = new_op . infer_const new_op . given_name = new_op . name new_var . op = new_op if new_var @graph . add_node ( new_op ) end @graph end
305	def variable ( value , name : nil , initializer : nil , graph : nil , dtype : nil , trainable : true ) op = Graph . get_default_graph . add_op ( :assign , nil , value ) common_options = { initializer : initializer || op , name : name , graph : graph , dtype : dtype , trainable : trainable , } tensor = if value . is_a? ( String ) i_var ( dtype || :string , 0 , [ ] , get_variable_scope , common_options ) elsif value . is_a? ( Integer ) i_var ( dtype || :int32 , 0 , [ ] , get_variable_scope , common_options ) elsif value . is_a? ( Float ) i_var ( dtype || :float32 , 0 , [ ] , get_variable_scope , common_options ) else i_var ( dtype || :float32 , 0 , nil , get_variable_scope , common_options ) end op . set_input ( 0 , tensor . op ) Graph . get_default_graph . add_node ( op ) tensor end
306	def variable_scope ( scope = nil , default_name = nil , reuse : nil , initializer : nil ) Thread . current [ :tensor_stream_variable_scope ] ||= [ VariableScope . new ] if scope . nil? && default_name same_names = get_variable_scope . used_names . select { | s | s . start_with? ( default_name ) } new_name = default_name index = 1 while same_names . include? ( new_name ) new_name = "#{default_name}_#{index}" index += 1 end scope = new_name end variable_scope = VariableScope . new ( name : scope , reuse : reuse , initializer : initializer ) get_variable_scope . register_name ( scope || "" ) Thread . current [ :tensor_stream_variable_scope ] << variable_scope scope_name = __v_scope_name if block_given? begin TensorStream . get_default_graph . name_scope ( scope ) do yield ( scope_name ) end ensure Thread . current [ :tensor_stream_variable_scope ] . pop end else variable_scope end end
307	def session ( evaluator = nil , thread_pool_class : Concurrent :: ImmediateExecutor , log_device_placement : false , profile_enabled : false ) session = TensorStream :: Session . new ( evaluator , thread_pool_class : thread_pool_class , log_device_placement : log_device_placement , profile_enabled : profile_enabled ) yield session if block_given? session end
308	def placeholder ( dtype , shape : nil , name : nil ) TensorStream :: Placeholder . new ( dtype , nil , shape , name : name ) end
309	def check_if_dense ( value , expected_shape = nil ) return unless value . is_a? ( Array ) return if value . empty? expected_shape ||= shape_eval ( value ) s = expected_shape . shift raise TensorStream :: ValueError , "Argument must be a dense tensor: #{value}, expected size #{s} got #{value.size}" if value . size != s return if expected_shape . empty? value . each do | item | check_if_dense ( item , expected_shape . dup ) end end
310	def apply_data_type_coercion ( * args ) coerced_type = check_data_types ( * args ) args . map { | a | a . is_a? ( Tensor ) ? a : convert_to_tensor ( a , dtype : coerced_type ) } end
311	def add_audio ( customization_id : , audio_name : , audio_resource : , contained_content_type : nil , allow_overwrite : nil , content_type : nil ) raise ArgumentError . new ( "customization_id must be provided" ) if customization_id . nil? raise ArgumentError . new ( "audio_name must be provided" ) if audio_name . nil? raise ArgumentError . new ( "audio_resource must be provided" ) if audio_resource . nil? headers = { "Contained-Content-Type" => contained_content_type , "Content-Type" => content_type } sdk_headers = Common . new . get_sdk_headers ( "speech_to_text" , "V1" , "add_audio" ) headers . merge! ( sdk_headers ) params = { "allow_overwrite" => allow_overwrite } data = audio_resource method_url = "/v1/acoustic_customizations/%s/audio/%s" % [ ERB :: Util . url_encode ( customization_id ) , ERB :: Util . url_encode ( audio_name ) ] request ( method : "POST" , url : method_url , headers : headers , params : params , data : data , accept_json : true ) nil end
312	def create_event ( type : , data : ) raise ArgumentError . new ( "type must be provided" ) if type . nil? raise ArgumentError . new ( "data must be provided" ) if data . nil? headers = { } sdk_headers = Common . new . get_sdk_headers ( "discovery" , "V1" , "create_event" ) headers . merge! ( sdk_headers ) params = { "version" => @version } data = { "type" => type , "data" => data } method_url = "/v1/events" response = request ( method : "POST" , url : method_url , headers : headers , params : params , json : data , accept_json : true ) response end
313	def zero_pad ( n , message ) len = message . bytesize if len == n message elsif len > n raise LengthError , "String too long for zero-padding to #{n} bytes" else message + zeros ( n - len ) end end
314	def check_length ( string , length , description ) if string . nil? raise LengthError , "#{description} was nil (Expected #{length.to_int})" , caller end if string . bytesize != length . to_int raise LengthError , "#{description} was #{string.bytesize} bytes (Expected #{length.to_int})" , caller end true end
315	def check_string ( string , length , description ) check_string_validation ( string ) string = string . to_s check_length ( string , length , description ) string end
316	def check_hmac_key ( string , _description ) check_string_validation ( string ) string = string . to_str if string . bytesize . zero? raise LengthError , "#{Description} was #{string.bytesize} bytes (Expected more than 0)" , caller end string end
317	def check_string_validation ( string ) raise TypeError , "can't convert #{string.class} into String with #to_str" unless string . respond_to? :to_str string = string . to_str raise EncodingError , "strings must use BINARY encoding (got #{string.encoding})" if string . encoding != Encoding :: BINARY end
318	def auth ( message ) authenticator = Util . zeros ( tag_bytes ) message = message . to_str compute_authenticator ( authenticator , message ) authenticator end
319	def verify ( authenticator , message ) auth = authenticator . to_s Util . check_length ( auth , tag_bytes , "Provided authenticator" ) verify_message ( auth , message ) || raise ( BadAuthenticatorError , "Invalid authenticator provided, message is corrupt" ) end
320	def box ( message ) nonce = generate_nonce cipher_text = @box . box ( nonce , message ) nonce + cipher_text end
321	def open ( enciphered_message ) nonce , ciphertext = extract_nonce ( enciphered_message . to_s ) @box . open ( nonce , ciphertext ) end
322	def reopen each do | appender | begin next unless appender . respond_to? ( :reopen ) logger . trace "Reopening appender: #{appender.name}" appender . reopen rescue Exception => exc logger . error "Failed to re-open appender: #{appender.inspect}" , exc end end logger . trace 'All appenders re-opened' end
323	def logger @logger ||= begin logger = SemanticLogger :: Processor . logger . clone logger . name = self . class . name logger end end
324	def measure ( level , message , params = { } , & block ) index = Levels . index ( level ) if level_index <= index measure_internal ( level , index , message , params , & block ) elsif block yield ( params ) end end
325	def backtrace ( thread : Thread . current , level : :warn , message : 'Backtrace:' , payload : nil , metric : nil , metric_amount : nil ) log = Log . new ( name , level ) return false unless meets_log_level? ( log ) backtrace = if thread == Thread . current Utils . extract_backtrace else log . thread_name = thread . name log . tags = ( thread [ :semantic_logger_tags ] || [ ] ) . clone log . named_tags = ( thread [ :semantic_logger_named_tags ] || { } ) . clone thread . backtrace end if backtrace message += "\n" message << backtrace . join ( "\n" ) end if log . assign ( message : message , backtrace : backtrace , payload : payload , metric : metric , metric_amount : metric_amount ) && ! filtered? ( log ) self . log ( log ) else false end end
326	def tagged ( * tags , & block ) if tags . size == 1 tag = tags [ 0 ] return yield if tag . nil? || tag == '' return tag . is_a? ( Hash ) ? SemanticLogger . named_tagged ( tag , & block ) : SemanticLogger . fast_tag ( tag . to_s , & block ) end new_tags = tags . flatten . collect ( & :to_s ) . reject ( & :empty? ) SemanticLogger . tagged ( * new_tags , & block ) end
327	def push_tags ( * tags ) new_tags = tags . flatten . collect ( & :to_s ) . reject ( & :empty? ) SemanticLogger . push_tags ( * new_tags ) end
328	def filtered? ( log ) return false if @filter . nil? @filter . is_a? ( Regexp ) ? ( @filter =~ log . name ) . nil? : @filter . call ( log ) != true end
329	def log_internal ( level , index , message = nil , payload = nil , exception = nil , & block ) log = Log . new ( name , level , index ) should_log = if payload . nil? && exception . nil? && message . is_a? ( Hash ) if message . key? ( :message ) || message . key? ( :payload ) || message . key? ( :exception ) || message . key? ( :metric ) log . assign ( message ) else log . assign_positional ( nil , message , nil , & block ) end else log . assign_positional ( message , payload , exception , & block ) end self . log ( log ) if should_log && should_log? ( log ) end
330	def measure_internal ( level , index , message , params ) exception = nil result = nil if params . empty? && message . is_a? ( Hash ) params = message message = nil end start = Process . clock_gettime ( Process :: CLOCK_MONOTONIC ) begin if block_given? result = if ( silence_level = params [ :silence ] ) silence_level = :error if silence_level == true silence ( silence_level ) { yield ( params ) } else yield ( params ) end end rescue Exception => exc exception = exc ensure log = Log . new ( name , level , index ) exception ||= params [ :exception ] message = params [ :message ] if params [ :message ] duration = if block_given? 1_000.0 * ( Process . clock_gettime ( Process :: CLOCK_MONOTONIC ) - start ) else params [ :duration ] || raise ( 'Mandatory block missing when :duration option is not supplied' ) end payload = params [ :payload ] should_log = log . assign ( message : message , payload : payload , min_duration : params [ :min_duration ] || 0.0 , exception : exception , metric : params [ :metric ] , metric_amount : params [ :metric_amount ] , duration : duration , log_exception : params [ :log_exception ] || :partial , on_exception_level : params [ :on_exception_level ] ) self . log ( log ) if should_log && should_log? ( log ) raise exception if exception result end end
331	def measure_method ( index : , level : , message : , min_duration : , metric : , log_exception : , on_exception_level : ) exception = nil start = Process . clock_gettime ( Process :: CLOCK_MONOTONIC ) begin yield rescue Exception => exc exception = exc ensure log = Log . new ( name , level , index ) should_log = log . assign ( message : message , min_duration : min_duration , exception : exception , metric : metric , duration : 1_000.0 * ( Process . clock_gettime ( Process :: CLOCK_MONOTONIC ) - start ) , log_exception : log_exception , on_exception_level : on_exception_level ) log ( log ) if should_log && should_log? ( log ) raise exception if exception end end
332	def log ( log , message = nil , progname = nil , & block ) return add ( log , message , progname , & block ) unless log . is_a? ( SemanticLogger :: Log ) Logger . call_subscribers ( log ) Logger . processor . log ( log ) end
333	def assign ( message : nil , payload : nil , min_duration : 0.0 , exception : nil , metric : nil , metric_amount : nil , duration : nil , backtrace : nil , log_exception : :full , on_exception_level : nil , dimensions : nil ) if duration self . duration = duration return false if ( duration < min_duration ) && exception . nil? end self . message = message if payload && payload . is_a? ( Hash ) self . payload = payload elsif payload self . message = message . nil? ? payload . to_s : "#{message} -- #{payload}" self . payload = nil end if exception case log_exception when :full self . exception = exception when :partial self . message = "#{message} -- Exception: #{exception.class}: #{exception.message}" when nil , :none nil else raise ( ArgumentError , "Invalid value:#{log_exception.inspect} for argument :log_exception" ) end if on_exception_level self . level = on_exception_level self . level_index = Levels . index ( level ) end end if backtrace self . backtrace = Utils . extract_backtrace ( backtrace ) elsif level_index >= SemanticLogger . backtrace_level_index self . backtrace = Utils . extract_backtrace end if metric self . metric = metric self . metric_amount = metric_amount self . dimensions = dimensions end true end
334	def assign_positional ( message = nil , payload = nil , exception = nil ) if exception . nil? && payload . nil? && message . respond_to? ( :backtrace ) && message . respond_to? ( :message ) exception = message message = nil elsif exception . nil? && payload && payload . respond_to? ( :backtrace ) && payload . respond_to? ( :message ) exception = payload payload = nil elsif payload && ! payload . is_a? ( Hash ) message = message . nil? ? payload : "#{message} -- #{payload}" payload = nil end if block_given? && ( result = yield ) if result . is_a? ( String ) message = message . nil? ? result : "#{message} -- #{result}" assign ( message : message , payload : payload , exception : exception ) elsif message . nil? && result . is_a? ( Hash ) && %i[ message payload exception ] . any? { | k | result . key? k } assign ( result ) elsif payload &. respond_to? ( :merge ) assign ( message : message , payload : payload . merge ( result ) , exception : exception ) else assign ( message : message , payload : result , exception : exception ) end else assign ( message : message , payload : payload , exception : exception ) end end
335	def each_exception depth = 0 exceptions = [ ] ex = exception while ! ex . nil? && ! exceptions . include? ( ex ) && exceptions . length < MAX_EXCEPTIONS_TO_UNWRAP exceptions << ex yield ( ex , depth ) depth += 1 ex = if ex . respond_to? ( :cause ) && ex . cause ex . cause elsif ex . respond_to? ( :continued_exception ) && ex . continued_exception ex . continued_exception elsif ex . respond_to? ( :original_exception ) && ex . original_exception ex . original_exception end end end
336	def extract_file_and_line ( stack , short_name = false ) match = CALLER_REGEXP . match ( stack . first ) [ short_name ? File . basename ( match [ 1 ] ) : match [ 1 ] , match [ 2 ] . to_i ] end
337	def message_for ( corrections ) return "" if corrections . empty? output = "\n\n Did you mean? " . dup output << corrections . join ( "\n " ) output << "\n " end
338	def gather_vars ( executor , tconf , message ) return nil if ( tconf . keys & %w[ include_vars exclude_vars ] ) . empty? iv = expand_filter ( tconf [ 'include_vars' ] ) return nil if iv == false ev = expand_filter ( tconf [ 'exclude_vars' ] ) return { } if ev == true vars = executor . vars ( message [ 'nid' ] ) return vars if iv == true vars = vars . select { | k , v | var_match ( k , iv ) } if iv vars = vars . reject { | k , v | var_match ( k , ev ) } if ev vars end
339	def do_run @unit . logger . log_run_start ( self ) counter_next ( 'runs' ) t0 = Time . now ( @unit . conf [ 'exe_max_messages' ] || 77 ) . times do | i | break if @shutdown m = @messages . shift break unless m m = ( @messages << m ) . shift if m [ 'point' ] == 'terminated' && @messages . any? ms = process ( m ) @consumed << m ims , oms = ms . partition { | mm | mm [ 'exid' ] == @exid } counter_add ( 'omsgs' , oms . size ) @messages . concat ( ims ) @unit . storage . put_messages ( oms ) end @alive = false @execution . merge! ( closing_messages : @consumed . select { | m | CLOSING_POINTS . include? ( m [ 'point' ] ) } ) @unit . storage . put_execution ( @execution ) @unit . storage . consume ( @consumed ) @unit . storage . put_messages ( @messages ) du = Time . now - t0 t0 = Flor . tstamp ( t0 ) @unit . logger . log_run_end ( self , t0 , du ) @unit . hooker . notify ( self , make_end_message ( t0 , du , @execution [ 'size' ] ) ) @consumed . clear rescue Exception => exc fn = [ 'flor' , @unit . conf [ 'env' ] , @unit . identifier , @exid , 'r' + counter ( 'runs' ) . to_s ] . collect ( & :to_s ) . join ( '_' ) + '.dump' @unit . logger . error ( "#{self.class}#do_run()" , exc , "(dumping to #{fn})" ) File . open ( fn , 'wb' ) do | f | f . puts ( Flor . to_pretty_s ( { execution : @execution , messages : @messages , consumed : @consumed , traps : @traps . collect ( & :to_h ) , exid : @exid , alive : @alive , shutdown : @shutdown , thread : [ @thread . object_id , @thread . to_s ] } ) ) f . puts ( '-' * 80 ) f . puts ( on_do_run_exc ( exc ) ) end end
340	def route ( name ) if name . is_a? ( String ) [ Flor . dup_and_merge ( @message , 'tasker' => name , 'original_tasker' => @message [ 'tasker' ] , 'routed' => true ) ] else [ Flor . dup_and_merge ( @message , 'routed' => ! ! name ) ] end end
341	def row_waiter? @serie . find { | _ , points | points . find { | po | pos = po . split ( ':' ) pos . length > 1 && ROW_PSEUDO_POINTS . include? ( pos [ 0 ] ) } } end
342	def node ( reload = false ) nid = @values [ :nid ] ; return nil unless nid exe = execution ( reload ) ; return nil unless exe nodes = exe . data [ 'nodes' ] ; return nil unless nodes nodes [ nid ] end
343	def vars ( nid , vs = { } ) n = node ( nid ) ; return vs unless n ( n [ 'vars' ] || { } ) . each { | k , v | vs [ k ] = Flor . dup ( v ) unless vs . has_key? ( k ) } pnid = n [ 'parent' ] if @unit . loader && pnid == nil && n [ 'vdomain' ] != false @unit . loader . variables ( n [ 'vdomain' ] || Flor . domain ( @exid ) ) . each { | k , v | vs [ k ] = Flor . dup ( v ) unless vs . has_key? ( k ) } end if cn = n [ 'cnid' ] ; vars ( cn , vs ) ; end vars ( pnid , vs ) if pnid vs end
344	def lookup_on_error_parent ( message ) nd = Flor :: Node . new ( self , nil , message ) . on_error_parent nd ? nd . to_procedure_node : nil end
345	def decrement c = data [ 'count' ] return false unless c c = c - 1 data [ 'count' ] = c self [ :status ] = s = ( c > 0 ) ? 'active' : 'consumed' self . update ( content : Flor :: Storage . to_blob ( @flor_model_cache_data ) , status : s ) c < 1 end
346	def work queue , job = lock_job if queue && job QC . log_yield ( :at => "work" , :job => job [ :id ] ) do process ( queue , job ) end end end
347	def lock_job log ( :at => "lock_job" ) job = nil while @running @queues . each do | queue | if job = queue . lock return [ queue , job ] end end @conn_adapter . wait ( @wait_interval , * @queues . map { | q | q . name } ) end end
348	def call ( job ) args = job [ :args ] receiver_str , _ , message = job [ :method ] . rpartition ( '.' ) receiver = eval ( receiver_str ) receiver . send ( message , * args ) end
349	def method_missing ( meth , opts = { } ) if meth . to_s == 'to_ary' super end if meth . to_s . end_with? '!' deep_merge_options meth [ 0 .. - 2 ] . to_sym , opts else merge_options meth , opts end end
350	def remove_params ( params ) self . tap do | u | u . query_values = ( u . query_values || { } ) . tap do | qv | params . each do | key , value | qv . delete key end end if u . query_values . empty? u . query_values = nil end end end
351	def parse_user_info ( node ) return nil if node . nil? { } . tap do | hash | node . children . each do | e | unless e . kind_of? ( Nokogiri :: XML :: Text ) || e . name == 'proxies' if e . element_children . count == 0 if hash . has_key? ( e . name ) hash [ e . name ] = [ hash [ e . name ] ] if hash [ e . name ] . is_a? String hash [ e . name ] << e . content else hash [ e . name ] = e . content end elsif e . element_children . count if e . name == 'attributes' hash . merge! ( parse_user_info ( e ) ) else hash [ e . name ] = [ ] if hash [ e . name ] . nil? hash [ e . name ] = [ hash [ e . name ] ] if hash [ e . name ] . is_a? String hash [ e . name ] . push ( parse_user_info ( e ) ) end end end end end end
352	def run_async ( command ) raise 'Async command already in progress' if @started @started = false @user_method . reset session . open_channel do | channel | channel . request_pty channel . on_data do | ch , data | publish_data ( data , 'stdout' ) unless @user_method . filter_password? ( data ) @user_method . on_data ( data , ch ) end channel . on_extended_data { | ch , type , data | publish_data ( data , 'stderr' ) } channel . on_request ( 'exit-status' ) { | ch , data | publish_exit_status ( data . read_long ) } channel . on_request ( 'exit-signal' ) do | ch , data | publish_exit_status ( data . read_string ) ch . close ch . wait end channel . exec ( command ) do | _ , success | @started = true raise ( 'Error initializing command' ) unless success end end session . process ( 0 ) { ! run_started? } return true end
353	def exit_code fail_chance = ENV . fetch ( 'REX_SIMULATE_FAIL_CHANCE' , 0 ) . to_i fail_exitcode = ENV . fetch ( 'REX_SIMULATE_EXIT' , 0 ) . to_i if fail_exitcode == 0 || fail_chance < ( Random . rand * 100 ) . round 0 else fail_exitcode end end
354	def import_method ( source , name , new_name = name ) from = name . to_sym to = new_name . to_sym fn = source . is_a? ( Registry ) ? source . fetch ( from ) : source . method ( from ) self . class . new ( methods . merge ( to => fn ) ) end
355	def import_methods ( source , names ) names . inject ( self ) { | a , e | a . import_method ( source , e ) } end
356	def import_all ( source ) names = source . public_methods - Registry . instance_methods - Module . methods names -= [ :initialize ] names += source . store . methods . keys if source . is_a? Registry import_methods ( source , names ) end
357	def [] ( fn , * args ) fetched = fetch ( fn ) return Function . new ( fetched , args : args , name : fn ) unless already_wrapped? ( fetched ) args . empty? ? fetched : fetched . with ( * args ) end
358	def fetch ( fn ) return fn unless fn . instance_of? Symbol respond_to? ( fn ) ? method ( fn ) : store . fetch ( fn ) rescue raise FunctionNotFoundError . new ( fn , self ) end
359	def to_ast args_ast = args . map { | arg | arg . respond_to? ( :to_ast ) ? arg . to_ast : arg } [ name , args_ast ] end
360	def to_proc if args . size > 0 proc { | * value | fn . call ( * value , * args ) } else fn . to_proc end end
361	def from_pattern_match ( keys , pattern , match ) keys . each_with_index . map do | key , idx | if pattern [ key ] interpolate ( pattern [ key ] , match ) else match [ idx + 1 ] end end end
362	def interpolate ( replacement , match ) group_idx = replacement . index ( '$' ) return replacement if group_idx . nil? group_nbr = replacement [ group_idx + 1 ] replacement . sub ( "$#{group_nbr}" , match [ group_nbr . to_i ] ) end
363	def before ( * commands , & block ) context = ( @_context [ :before ] ||= [ ] ) block_given? ? run_context ( context , & block ) : context . concat ( commands ) end
364	def window ( * args , & block ) key = "window#{@_windows.keys.size}" options = args . extract_options! options [ :name ] = args . first unless args . empty? context = ( @_windows [ key ] = window_hash . merge ( :options => options ) ) run_context context , & block end
365	def tab ( * args , & block ) tabs = @_context [ :tabs ] key = "tab#{tabs.keys.size}" return ( tabs [ key ] = { :commands => args } ) unless block_given? context = ( tabs [ key ] = { :commands => [ ] } ) options = args . extract_options! options [ :name ] = args . first unless args . empty? context [ :options ] = options run_context context , & block @_context = @_windows [ @_windows . keys . last ] end
366	def run ( * commands ) context = case when @_context . is_a? ( Hash ) && @_context [ :tabs ] @_context [ :tabs ] [ 'default' ] [ :commands ] when @_context . is_a? ( Hash ) @_context [ :commands ] else @_context end context << commands . map { | c | c =~ / / ? "(#{c})" : c } . join ( " && " ) end
367	def set_write ( policy , operation , key , bins ) begin_cmd field_count = estimate_key_size ( key , policy ) bins . each do | bin | estimate_operation_size_for_bin ( bin ) end size_buffer write_header_with_policy ( policy , 0 , INFO2_WRITE , field_count , bins . length ) write_key ( key , policy ) bins . each do | bin | write_operation_for_bin ( bin , operation ) end end_cmd end
368	def set_delete ( policy , key ) begin_cmd field_count = estimate_key_size ( key ) size_buffer write_header_with_policy ( policy , 0 , INFO2_WRITE | INFO2_DELETE , field_count , 0 ) write_key ( key ) end_cmd end
369	def set_touch ( policy , key ) begin_cmd field_count = estimate_key_size ( key ) estimate_operation_size size_buffer write_header_with_policy ( policy , 0 , INFO2_WRITE , field_count , 1 ) write_key ( key ) write_operation_for_operation_type ( Aerospike :: Operation :: TOUCH ) end_cmd end
370	def set_exists ( policy , key ) begin_cmd field_count = estimate_key_size ( key ) size_buffer write_header ( policy , INFO1_READ | INFO1_NOBINDATA , 0 , field_count , 0 ) write_key ( key ) end_cmd end
371	def set_read_header ( policy , key ) begin_cmd field_count = estimate_key_size ( key ) estimate_operation_size_for_bin_name ( '' ) size_buffer write_header ( policy , INFO1_READ , 0 , field_count , 1 ) write_key ( key ) write_operation_for_bin_name ( '' , Aerospike :: Operation :: READ ) end_cmd end
372	def set_operate ( policy , key , operations ) begin_cmd field_count = estimate_key_size ( key , policy ) read_attr = 0 write_attr = 0 read_header = false operations . each do | operation | case operation . op_type when Aerospike :: Operation :: READ read_attr |= INFO1_READ read_attr |= INFO1_GET_ALL unless operation . bin_name when Aerospike :: Operation :: READ_HEADER read_attr |= INFO1_READ read_header = true else write_attr = INFO2_WRITE end estimate_operation_size_for_operation ( operation ) end size_buffer if write_attr != 0 write_header_with_policy ( policy , read_attr , write_attr , field_count , operations . length ) else write_header ( policy , read_attr , write_attr , field_count , operations . length ) end write_key ( key , policy ) operations . each do | operation | write_operation_for_operation ( operation ) end write_operation_for_bin ( nil , Aerospike :: Operation :: READ ) if read_header end_cmd end
373	def write_header ( policy , read_attr , write_attr , field_count , operation_count ) read_attr |= INFO1_CONSISTENCY_ALL if policy . consistency_level == Aerospike :: ConsistencyLevel :: CONSISTENCY_ALL @data_buffer . write_byte ( MSG_REMAINING_HEADER_SIZE , 8 ) @data_buffer . write_byte ( read_attr , 9 ) @data_buffer . write_byte ( write_attr , 10 ) i = 11 while i <= 25 @data_buffer . write_byte ( 0 , i ) i = i . succ end @data_buffer . write_int16 ( field_count , 26 ) @data_buffer . write_int16 ( operation_count , 28 ) @data_offset = MSG_TOTAL_HEADER_SIZE end
374	def write_header_with_policy ( policy , read_attr , write_attr , field_count , operation_count ) generation = Integer ( 0 ) info_attr = Integer ( 0 ) case policy . record_exists_action when Aerospike :: RecordExistsAction :: UPDATE when Aerospike :: RecordExistsAction :: UPDATE_ONLY info_attr |= INFO3_UPDATE_ONLY when Aerospike :: RecordExistsAction :: REPLACE info_attr |= INFO3_CREATE_OR_REPLACE when Aerospike :: RecordExistsAction :: REPLACE_ONLY info_attr |= INFO3_REPLACE_ONLY when Aerospike :: RecordExistsAction :: CREATE_ONLY write_attr |= INFO2_CREATE_ONLY end case policy . generation_policy when Aerospike :: GenerationPolicy :: NONE when Aerospike :: GenerationPolicy :: EXPECT_GEN_EQUAL generation = policy . generation write_attr |= INFO2_GENERATION when Aerospike :: GenerationPolicy :: EXPECT_GEN_GT generation = policy . generation write_attr |= INFO2_GENERATION_GT end info_attr |= INFO3_COMMIT_MASTER if policy . commit_level == Aerospike :: CommitLevel :: COMMIT_MASTER read_attr |= INFO1_CONSISTENCY_ALL if policy . consistency_level == Aerospike :: ConsistencyLevel :: CONSISTENCY_ALL write_attr |= INFO2_DURABLE_DELETE if policy . durable_delete @data_buffer . write_byte ( MSG_REMAINING_HEADER_SIZE , 8 ) @data_buffer . write_byte ( read_attr , 9 ) @data_buffer . write_byte ( write_attr , 10 ) @data_buffer . write_byte ( info_attr , 11 ) @data_buffer . write_byte ( 0 , 12 ) @data_buffer . write_byte ( 0 , 13 ) @data_buffer . write_uint32 ( generation , 14 ) @data_buffer . write_uint32 ( policy . ttl , 18 ) @data_buffer . write_byte ( 0 , 22 ) @data_buffer . write_byte ( 0 , 23 ) @data_buffer . write_byte ( 0 , 24 ) @data_buffer . write_byte ( 0 , 25 ) @data_buffer . write_int16 ( field_count , 26 ) @data_buffer . write_int16 ( operation_count , 28 ) @data_offset = MSG_TOTAL_HEADER_SIZE end
375	def all_nodes_done? if @scan command = 'scan-list' else command = 'query-list' end nodes = @cluster . nodes done = false nodes . each do | node | conn = node . get_connection ( 0 ) responseMap , _ = Info . request ( conn , command ) node . put_connection ( conn ) response = responseMap [ command ] find = "job_id=#{@task_id}:" index = response . index ( find ) unless index done = true next end b = index + find . length response = response [ b , response . length ] find = 'job_status=' index = response . index ( find ) next unless index b = index + find . length response = response [ b , response . length ] e = response . index ( ':' ) status = response [ 0 , e ] case status when 'ABORTED' raise raise Aerospike :: Exceptions :: QueryTerminated when 'IN PROGRESS' return false when 'DONE' done = true end end done end
376	def get_connection ( timeout ) loop do conn = @connections . poll if conn . connected? conn . timeout = timeout . to_f return conn end end end
377	def parse_record ( key , op_count , generation , expiration ) bins = op_count > 0 ? { } : nil i = 0 while i < op_count raise Aerospike :: Exceptions :: QueryTerminated . new unless valid? read_bytes ( 8 ) op_size = @data_buffer . read_int32 ( 0 ) . ord particle_type = @data_buffer . read ( 5 ) . ord name_size = @data_buffer . read ( 7 ) . ord read_bytes ( name_size ) name = @data_buffer . read ( 0 , name_size ) . force_encoding ( 'utf-8' ) particle_bytes_size = op_size - ( 4 + name_size ) read_bytes ( particle_bytes_size ) value = Aerospike . bytes_to_particle ( particle_type , @data_buffer , 0 , particle_bytes_size ) bins [ name ] = value i = i . succ end Record . new ( @node , key , bins , generation , expiration ) end
378	def random_node node_array = nodes length = node_array . length i = 0 while i < length index = ( @node_index . update { | v | v + 1 } % node_array . length ) . abs node = node_array [ index ] return node if node . active? i = i . succ end raise Aerospike :: Exceptions :: InvalidNode end
379	def get_node_by_name ( node_name ) node = find_node_by_name ( node_name ) raise Aerospike :: Exceptions :: InvalidNode unless node node end
380	def prepend ( key , bins , options = nil ) policy = create_policy ( options , WritePolicy , default_write_policy ) command = WriteCommand . new ( @cluster , policy , key , hash_to_bins ( bins ) , Aerospike :: Operation :: PREPEND ) execute_command ( command ) end
381	def get_header ( key , options = nil ) policy = create_policy ( options , Policy , default_read_policy ) command = ReadHeaderCommand . new ( @cluster , policy , key ) execute_command ( command ) command . record end
382	def batch_exists ( keys , options = nil ) policy = create_policy ( options , BatchPolicy , default_batch_policy ) results = Array . new ( keys . length ) if policy . use_batch_direct key_map = BatchItem . generate_map ( keys ) execute_batch_direct_commands ( keys ) do | node , batch | BatchDirectExistsCommand . new ( node , batch , policy , key_map , results ) end else execute_batch_index_commands ( keys ) do | node , batch | BatchIndexExistsCommand . new ( node , batch , policy , results ) end end results end
383	def register_udf ( udf_body , server_path , language , options = nil ) policy = create_policy ( options , Policy , default_info_policy ) content = Base64 . strict_encode64 ( udf_body ) . force_encoding ( 'binary' ) str_cmd = "udf-put:filename=#{server_path};content=#{content};" str_cmd << "content-len=#{content.length};udf-type=#{language};" response_map = @cluster . request_info ( policy , str_cmd ) res = { } response_map . each do | k , response | vals = response . to_s . split ( ';' ) vals . each do | pair | k , v = pair . split ( "=" , 2 ) res [ k ] = v end end if res [ 'error' ] raise Aerospike :: Exceptions :: CommandRejected . new ( "Registration failed: #{res['error']}\nFile: #{res['file']}\nLine: #{res['line']}\nMessage: #{res['message']}" ) end UdfRegisterTask . new ( @cluster , server_path ) end
384	def remove_udf ( udf_name , options = nil ) policy = create_policy ( options , Policy , default_info_policy ) str_cmd = "udf-remove:filename=#{udf_name};" response_map = @cluster . request_info ( policy , str_cmd ) _ , response = response_map . first if response == 'ok' UdfRemoveTask . new ( @cluster , udf_name ) else raise Aerospike :: Exceptions :: Aerospike . new ( Aerospike :: ResultCode :: SERVER_ERROR , response ) end end
385	def list_udf ( options = nil ) policy = create_policy ( options , Policy , default_info_policy ) str_cmd = 'udf-list' response_map = @cluster . request_info ( policy , str_cmd ) _ , response = response_map . first vals = response . split ( ';' ) vals . map do | udf_info | next if udf_info . strip! == '' udf_parts = udf_info . split ( ',' ) udf = UDF . new udf_parts . each do | values | k , v = values . split ( '=' , 2 ) case k when 'filename' udf . filename = v when 'hash' udf . hash = v when 'type' udf . language = v end end udf end end
386	def execute_udf_on_query ( statement , package_name , function_name , function_args = [ ] , options = nil ) policy = create_policy ( options , QueryPolicy , default_query_policy ) nodes = @cluster . nodes if nodes . empty? raise Aerospike :: Exceptions :: Aerospike . new ( Aerospike :: ResultCode :: SERVER_NOT_AVAILABLE , "Executing UDF failed because cluster is empty." ) end statement . set_aggregate_function ( package_name , function_name , function_args , false ) nodes . each do | node | Thread . new do Thread . current . abort_on_exception = true begin command = QueryCommand . new ( node , policy , statement , nil ) execute_command ( command ) rescue => e Aerospike . logger . error ( e ) raise e end end end ExecuteTask . new ( @cluster , statement ) end
387	def create_index ( namespace , set_name , index_name , bin_name , index_type , collection_type = nil , options = nil ) if options . nil? && collection_type . is_a? ( Hash ) options , collection_type = collection_type , nil end policy = create_policy ( options , Policy , default_info_policy ) str_cmd = "sindex-create:ns=#{namespace}" str_cmd << ";set=#{set_name}" unless set_name . to_s . strip . empty? str_cmd << ";indexname=#{index_name};numbins=1" str_cmd << ";indextype=#{collection_type.to_s.upcase}" if collection_type str_cmd << ";indexdata=#{bin_name},#{index_type.to_s.upcase}" str_cmd << ";priority=normal" response = send_info_command ( policy , str_cmd ) . upcase if response == 'OK' return IndexTask . new ( @cluster , namespace , index_name ) end if response . start_with? ( 'FAIL:200' ) return IndexTask . new ( @cluster , namespace , index_name , true ) end raise Aerospike :: Exceptions :: Aerospike . new ( Aerospike :: ResultCode :: INDEX_GENERIC , "Create index failed: #{response}" ) end
388	def drop_index ( namespace , set_name , index_name , options = nil ) policy = create_policy ( options , Policy , default_info_policy ) str_cmd = "sindex-delete:ns=#{namespace}" str_cmd << ";set=#{set_name}" unless set_name . to_s . strip . empty? str_cmd << ";indexname=#{index_name}" response = send_info_command ( policy , str_cmd ) . upcase return if response == 'OK' return if response . start_with? ( 'FAIL:201' ) raise Aerospike :: Exceptions :: Aerospike . new ( Aerospike :: ResultCode :: INDEX_GENERIC , "Drop index failed: #{response}" ) end
389	def scan_node ( node , namespace , set_name , bin_names = nil , options = nil ) policy = create_policy ( options , ScanPolicy , default_scan_policy ) new_policy = policy . clone new_policy . max_retries = 0 node = @cluster . get_node_by_name ( node ) unless node . is_a? ( Aerospike :: Node ) recordset = Recordset . new ( policy . record_queue_size , 1 , :scan ) Thread . new do Thread . current . abort_on_exception = true command = ScanCommand . new ( node , new_policy , namespace , set_name , bin_names , recordset ) begin execute_command ( command ) rescue => e Aerospike . logger . error ( e . backtrace . join ( "\n" ) ) unless e == SCAN_TERMINATED_EXCEPTION recordset . cancel ( e ) ensure recordset . thread_finished end end recordset end
390	def drop_user ( user , options = nil ) policy = create_policy ( options , AdminPolicy , default_admin_policy ) command = AdminCommand . new command . drop_user ( @cluster , policy , user ) end
391	def change_password ( user , password , options = nil ) raise Aerospike :: Exceptions :: Aerospike . new ( INVALID_USER ) unless @cluster . user && @cluster . user != "" policy = create_policy ( options , AdminPolicy , default_admin_policy ) hash = AdminCommand . hash_password ( password ) command = AdminCommand . new if user == @cluster . user command . change_password ( @cluster , policy , user , hash ) else command . set_password ( @cluster , policy , user , hash ) end @cluster . change_password ( user , hash ) end
392	def grant_roles ( user , roles , options = nil ) policy = create_policy ( options , AdminPolicy , default_admin_policy ) command = AdminCommand . new command . grant_roles ( @cluster , policy , user , roles ) end
393	def query_users ( options = nil ) policy = create_policy ( options , AdminPolicy , default_admin_policy ) command = AdminCommand . new command . query_users ( @cluster , policy ) end
394	def next_record raise @thread_exception . get unless @thread_exception . get . nil? r = @records . deq set_exception if r . nil? r end
395	def each ( & block ) r = true while r r = next_record unless r . nil? block . call ( r ) else break end end end
396	def intercom_script_tag ( user_details = nil , options = { } ) controller . instance_variable_set ( IntercomRails :: SCRIPT_TAG_HELPER_CALLED_INSTANCE_VARIABLE , true ) if defined? ( controller ) options [ :user_details ] = user_details if user_details . present? options [ :find_current_user_details ] = ! options [ :user_details ] options [ :find_current_company_details ] = ! ( options [ :user_details ] && options [ :user_details ] [ :company ] ) options [ :controller ] = controller if defined? ( controller ) ScriptTag . new ( options ) end
397	def move_free ( aim , speed ) if aim . is_a? Vector x_d = aim . x - @x ; y_d = aim . y - @y distance = Math . sqrt ( x_d ** 2 + y_d ** 2 ) if distance == 0 @speed . x = @speed . y = 0 return end @speed . x = 1.0 * x_d * speed / distance @speed . y = 1.0 * y_d * speed / distance if ( @speed . x < 0 and @x + @speed . x <= aim . x ) or ( @speed . x >= 0 and @x + @speed . x >= aim . x ) @x = aim . x @speed . x = 0 else @x += @speed . x end if ( @speed . y < 0 and @y + @speed . y <= aim . y ) or ( @speed . y >= 0 and @y + @speed . y >= aim . y ) @y = aim . y @speed . y = 0 else @y += @speed . y end else rads = aim * Math :: PI / 180 @speed . x = speed * Math . cos ( rads ) @speed . y = speed * Math . sin ( rads ) @x += @speed . x @y += @speed . y end end
398	def get_absolute_size return Vector . new ( @tile_size . x * @size . x , @tile_size . y * @size . y ) unless @isometric avg = ( @size . x + @size . y ) * 0.5 Vector . new ( avg * @tile_size . x ) . to_i , ( avg * @tile_size . y ) . to_i end
399	def get_screen_pos ( map_x , map_y ) return Vector . new ( map_x * @tile_size . x - @cam . x , map_y * @tile_size . y - @cam . y ) unless @isometric Vector . new ( ( map_x - map_y - 1 ) * @tile_size . x * 0.5 ) - @cam . x + @x_offset , ( ( map_x + map_y ) * @tile_size . y * 0.5 ) - @cam . y end
400	def get_map_pos ( scr_x , scr_y ) return Vector . new ( ( scr_x + @cam . x ) / @tile_size . x , ( scr_y + @cam . y ) / @tile_size . y ) unless @isometric v = get_isometric_position scr_x , scr_y Vector . new ( ( v . x * @inverse_square_size ) . to_i , ( v . y * @inverse_square_size ) . to_i ) end
401	def is_in_map ( v ) v . x >= 0 && v . y >= 0 && v . x < @size . x && v . y < @size . y end
402	def animate_once ( indices , interval ) if @animate_once_control == 2 return if indices == @animate_once_indices && interval == @animate_once_interval @animate_once_control = 0 end unless @animate_once_control == 1 @anim_counter = 0 @img_index = indices [ 0 ] @index_index = 0 @animate_once_indices = indices @animate_once_interval = interval @animate_once_control = 1 return end @anim_counter += 1 return unless @anim_counter >= interval @index_index += 1 @img_index = indices [ @index_index ] @anim_counter = 0 @animate_once_control = 2 if @index_index == indices . length - 1 end
403	def draw ( map = nil , scale_x = 1 , scale_y = 1 , alpha = 0xff , color = 0xffffff , angle = nil , flip = nil , z_index = 0 , round = false ) if map . is_a? Hash scale_x = map . fetch ( :scale_x , 1 ) scale_y = map . fetch ( :scale_y , 1 ) alpha = map . fetch ( :alpha , 0xff ) color = map . fetch ( :color , 0xffffff ) angle = map . fetch ( :angle , nil ) flip = map . fetch ( :flip , nil ) z_index = map . fetch ( :z_index , 0 ) round = map . fetch ( :round , false ) map = map . fetch ( :map , nil ) end color = ( alpha << 24 ) | color if angle @img [ @img_index ] . draw_rot @x - ( map ? map . cam . x : 0 ) + @img [ 0 ] . width * scale_x * 0.5 , @y - ( map ? map . cam . y : 0 ) + @img [ 0 ] . height * scale_y * 0.5 , z_index , angle , 0.5 , 0.5 , ( flip == :horiz ? - scale_x : scale_x ) , ( flip == :vert ? - scale_y : scale_y ) , color else x = @x - ( map ? map . cam . x : 0 ) + ( flip == :horiz ? scale_x * @img [ 0 ] . width : 0 ) y = @y - ( map ? map . cam . y : 0 ) + ( flip == :vert ? scale_y * @img [ 0 ] . height : 0 ) @img [ @img_index ] . draw ( round ? x . round : x ) , ( round ? y . round : y ) , z_index , ( flip == :horiz ? - scale_x : scale_x ) , ( flip == :vert ? - scale_y : scale_y ) , color end end
404	def update return unless @enabled and @visible mouse_over = Mouse . over? @x , @y , @w , @h mouse_press = Mouse . button_pressed? :left mouse_rel = Mouse . button_released? :left if @state == :up if mouse_over @img_index = 1 @state = :over else @img_index = 0 end elsif @state == :over if not mouse_over @img_index = 0 @state = :up elsif mouse_press @img_index = 2 @state = :down else @img_index = 1 end elsif @state == :down if not mouse_over @img_index = 0 @state = :down_out elsif mouse_rel @img_index = 1 @state = :over click else @img_index = 2 end else if mouse_over @img_index = 2 @state = :down elsif mouse_rel @img_index = 0 @state = :up else @img_index = 0 end end end
405	def draw ( alpha = 0xff , z_index = 0 , color = 0xffffff ) return unless @visible color = ( alpha << 24 ) | color text_color = if @enabled if @state == :down @down_text_color else @state == :over ? @over_text_color : @text_color end else @disabled_text_color end text_color = ( alpha << 24 ) | text_color @img [ @img_index ] . draw @x , @y , z_index , @scale_x , @scale_y , color if @img if @text if @center_x or @center_y rel_x = @center_x ? 0.5 : 0 rel_y = @center_y ? 0.5 : 0 @font . draw_text_rel @text , @text_x , @text_y , z_index , rel_x , rel_y , @scale_x , @scale_y , text_color else @font . draw_text @text , @text_x , @text_y , z_index , @scale_x , @scale_y , text_color end end end
406	def text = ( value , trigger_changed = true ) @text = value [ 0 ... @max_length ] @nodes . clear ; @nodes << @text_x x = @nodes [ 0 ] @text . chars . each { | char | x += @font . text_width ( char ) * @scale_x @nodes << x } @cur_node = @nodes . size - 1 @anchor1 = nil @anchor2 = nil set_cursor_visible @on_text_changed . call @text , @params if trigger_changed && @on_text_changed end
407	def set_position ( x , y ) d_x = x - @x d_y = y - @y @x = x ; @y = y @text_x += d_x @text_y += d_y @nodes . map! do | n | n + d_x end end
408	def draw ( alpha = 0xff , z_index = 0 , color = 0xffffff , disabled_color = 0x808080 ) return unless @visible color = ( alpha << 24 ) | ( ( @enabled or @disabled_img ) ? color : disabled_color ) text_color = ( alpha << 24 ) | ( @enabled ? @text_color : @disabled_text_color ) img = ( ( @enabled or @disabled_img . nil? ) ? @img : @disabled_img ) img . draw @x , @y , z_index , @scale_x , @scale_y , color @font . draw_text @text , @text_x , @text_y , z_index , @scale_x , @scale_y , text_color if @anchor1 and @anchor2 selection_color = ( ( alpha / 2 ) << 24 ) | @selection_color G . window . draw_quad @nodes [ @anchor1 ] , @text_y , selection_color , @nodes [ @anchor2 ] + 1 , @text_y , selection_color , @nodes [ @anchor2 ] + 1 , @text_y + @font . height * @scale_y , selection_color , @nodes [ @anchor1 ] , @text_y + @font . height * @scale_y , selection_color , z_index end if @cursor_visible if @cursor_img @cursor_img . draw @nodes [ @cur_node ] - ( @cursor_img . width * @scale_x ) / 2 , @text_y , z_index , @scale_x , @scale_y else cursor_color = alpha << 24 G . window . draw_quad @nodes [ @cur_node ] , @text_y , cursor_color , @nodes [ @cur_node ] + 1 , @text_y , cursor_color , @nodes [ @cur_node ] + 1 , @text_y + @font . height * @scale_y , cursor_color , @nodes [ @cur_node ] , @text_y + @font . height * @scale_y , cursor_color , z_index end end end
409	def draw ( alpha = 0xff , z_index = 0 , color = 0xffffff ) return unless @visible if @bg c = ( alpha << 24 ) | color @bg . draw @x , @y , z_index , @scale_x , @scale_y , c else c = ( alpha << 24 ) | @bg_color G . window . draw_quad @x , @y , c , @x + @w , @y , c , @x + @w , @y + @h , c , @x , @y + @h , c , z_index end if @fg c = ( alpha << 24 ) | color w1 = @fg . width * @scale_x w2 = ( @value . to_f / @max_value * @w ) . round x0 = @x + @fg_margin_x x = 0 while x <= w2 - w1 @fg . draw x0 + x , @y + @fg_margin_y , z_index , @scale_x , @scale_y , c x += w1 end if w2 - x > 0 img = Gosu :: Image . new ( @fg_path , tileable : true , retro : @retro , rect : [ 0 , 0 , ( ( w2 - x ) / @scale_x ) . round , @fg . height ] ) img . draw x0 + x , @y + @fg_margin_y , z_index , @scale_x , @scale_y , c end else c = ( alpha << 24 ) | @fg_color rect_r = @x + ( @value . to_f / @max_value * @w ) . round G . window . draw_quad @x , @y , c , rect_r , @y , c , rect_r , @y + @h , c , @x , @y + @h , c , z_index end if @font c = ( alpha << 24 ) | @text_color @text = @format == '%' ? "#{(@value.to_f / @max_value * 100).round}%" : "#{@value}/#{@max_value}" @font . draw_text_rel @text , @x + @w / 2 , @y + @h / 2 , z_index , 0.5 , 0.5 , @scale_x , @scale_y , c end end
410	def update return unless @enabled and @visible if @open and Mouse . button_pressed? :left and not Mouse . over? ( @x , @y , @w , @max_h ) toggle return end @buttons . each { | b | b . update } end
411	def value = ( val ) if @options . include? val old = @value @value = @buttons [ 0 ] . text = val @on_changed . call ( old , val ) if @on_changed end end
412	def draw ( alpha = 0xff , z_index = 0 , color = 0xffffff , over_color = 0xcccccc ) return unless @visible unless @img bottom = @y + ( @open ? @max_h : @h ) + @scale_y b_color = ( alpha << 24 ) G . window . draw_quad @x - @scale_x , @y - @scale_y , b_color , @x + @w + @scale_x , @y - @scale_y , b_color , @x + @w + @scale_x , bottom , b_color , @x - @scale_x , bottom , b_color , z_index @buttons . each do | b | c = ( alpha << 24 ) | ( b . state == :over ? over_color : color ) G . window . draw_quad b . x , b . y , c , b . x + b . w , b . y , c , b . x + b . w , b . y + b . h , c , b . x , b . y + b . h , c , z_index + 1 if b . visible end end @buttons [ 0 ] . draw ( alpha , z_index , color ) @buttons [ 1 .. - 1 ] . each { | b | b . draw alpha , z_index + 1 , color } end
413	def draw ( alpha = 255 , z_index = 0 , color = 0xffffff ) c = @enabled ? @text_color : @disabled_text_color r1 = c >> 16 g1 = ( c & 0xff00 ) >> 8 b1 = ( c & 0xff ) r2 = color >> 16 g2 = ( color & 0xff00 ) >> 8 b2 = ( color & 0xff ) r1 *= r2 ; r1 /= 255 g1 *= g2 ; g1 /= 255 b1 *= b2 ; b1 /= 255 color = ( alpha << 24 ) | ( r1 << 16 ) | ( g1 << 8 ) | b1 @font . draw_text ( @text , @x , @y , z_index , @scale_x , @scale_y , color ) end
414	def write_line ( text , x = nil , y = nil , mode = :left , color = 0 , alpha = 0xff , effect = nil , effect_color = 0 , effect_size = 1 , effect_alpha = 0xff , z_index = 0 ) if text . is_a? Hash x = text [ :x ] y = text [ :y ] mode = text . fetch ( :mode , :left ) color = text . fetch ( :color , 0 ) alpha = text . fetch ( :alpha , 0xff ) effect = text . fetch ( :effect , nil ) effect_color = text . fetch ( :effect_color , 0 ) effect_size = text . fetch ( :effect_size , 1 ) effect_alpha = text . fetch ( :effect_alpha , 0xff ) z_index = text . fetch ( :z_index , 0 ) text = text [ :text ] end color = ( alpha << 24 ) | color rel = case mode when :left then 0 when :center then 0.5 when :right then 1 else 0 end if effect effect_color = ( effect_alpha << 24 ) | effect_color if effect == :border @font . draw_markup_rel text , x - effect_size , y - effect_size , z_index , rel , 0 , 1 , 1 , effect_color @font . draw_markup_rel text , x , y - effect_size , z_index , rel , 0 , 1 , 1 , effect_color @font . draw_markup_rel text , x + effect_size , y - effect_size , z_index , rel , 0 , 1 , 1 , effect_color @font . draw_markup_rel text , x + effect_size , y , z_index , rel , 0 , 1 , 1 , effect_color @font . draw_markup_rel text , x + effect_size , y + effect_size , z_index , rel , 0 , 1 , 1 , effect_color @font . draw_markup_rel text , x , y + effect_size , z_index , rel , 0 , 1 , 1 , effect_color @font . draw_markup_rel text , x - effect_size , y + effect_size , z_index , rel , 0 , 1 , 1 , effect_color @font . draw_markup_rel text , x - effect_size , y , z_index , rel , 0 , 1 , 1 , effect_color elsif effect == :shadow @font . draw_markup_rel text , x + effect_size , y + effect_size , z_index , rel , 0 , 1 , 1 , effect_color end end @font . draw_markup_rel text , x , y , z_index , rel , 0 , 1 , 1 , color end
415	def write_breaking ( text , x , y , width , mode = :left , color = 0 , alpha = 0xff , z_index = 0 ) color = ( alpha << 24 ) | color text . split ( "\n" ) . each do | p | if mode == :justified y = write_paragraph_justified p , x , y , width , color , z_index else rel = case mode when :left then 0 when :center then 0.5 when :right then 1 else 0 end y = write_paragraph p , x , y , width , rel , color , z_index end end end
416	def add_global ( message ) unless ( slot = @entries . index { | e | e . nil? } ) slot = 0 0 . upto ( 15 ) do | i | if i != slot && @entries [ slot ] . last_use > @entries [ i ] . last_use slot = i end end end @entries [ slot ] = Entry . new ( message , Time . now ) slot end
417	def get_local ( message ) 0 . upto ( 15 ) do | i | if ( entry = @entries [ i ] ) && entry . global_message == message entry . last_use = Time . now return i end end nil end
418	def check last_timestamp = ts_16_offset = nil last_ts_16 = nil @monitorings . each do | record | if last_ts_16 && ts_16_offset && record . timestamp_16 && record . timestamp_16 < last_ts_16 ts_16_offset += 2 ** 16 end if ts_16_offset if record . timestamp_16 record . timestamp = ts_16_offset + record . timestamp_16 last_ts_16 = record . timestamp_16 end else if record . timestamp_16 && last_timestamp ts_16_offset = last_timestamp + 60 - record . timestamp_16 record . timestamp = ts_16_offset + record . timestamp_16 last_ts_16 = record . timestamp_16 else last_timestamp = record . timestamp end end end end
419	def create_global_definition ( fit_entity ) messages = fit_entity . developer_fit_messages unless ( gfm = GlobalFitMessages [ @native_mesg_num ] ) Log . error "Developer field description references unknown global " + "message number #{@native_mesg_num}" return end if @developer_data_index >= fit_entity . top_level_record . developer_data_ids . size Log . error "Developer data index #{@developer_data_index} is too large" return end msg = messages [ @native_mesg_num ] || messages . message ( @native_mesg_num , gfm . name ) unless ( @fit_base_type_id & 0x7F ) < FIT_TYPE_DEFS . size Log . error "fit_base_type_id #{@fit_base_type_id} is too large" return end options = { } options [ :scale ] = @scale if @scale options [ :offset ] = @offset if @offset options [ :array ] = @array if @array options [ :unit ] = @units msg . field ( @field_definition_number , FIT_TYPE_DEFS [ @fit_base_type_id & 0x7F ] [ 1 ] , "_#{@developer_data_index}_#{@field_name}" , options ) end
420	def check ( index ) unless @device_index Log . fatal 'device info record must have a device_index' end if @device_index == 0 unless @manufacturer Log . fatal 'device info record 0 must have a manufacturer field set' end if @manufacturer == 'garmin' unless @garmin_product Log . fatal 'device info record 0 must have a garman_product ' + 'field set' end else unless @product Log . fatal 'device info record 0 must have a product field set' end end if @serial_number . nil? Log . fatal 'device info record 0 must have a serial number set' end end end
421	def open ( io ) begin @@logger = Logger . new ( io ) rescue => e @@logger = Logger . new ( $stderr ) Log . fatal "Cannot open log file: #{e.message}" end end
422	def set_type ( type ) if @top_level_record Log . fatal "FIT file type has already been set to " + "#{@top_level_record.class}" end case type when 4 , 'activity' @top_level_record = Activity . new @type = 'activity' when 32 , 'monitoring_b' @top_level_record = Monitoring_B . new @type = 'monitoring_b' when 44 , 'metrics' @top_level_record = Metrics . new @type = 'metrics' else Log . error "Unsupported FIT file type #{type}" return nil end @top_level_record end
423	def check unless @timestamp && @timestamp >= Time . parse ( '1990-01-01T00:00:00+00:00' ) Log . fatal "Activity has no valid timestamp" end unless @total_timer_time Log . fatal "Activity has no valid total_timer_time" end unless @device_infos . length > 0 Log . fatal "Activity must have at least one device_info section" end @device_infos . each . with_index { | d , index | d . check ( index ) } @sensor_settings . each . with_index { | s , index | s . check ( index ) } unless @num_sessions == @sessions . count Log . fatal "Activity record requires #{@num_sessions}, but " "#{@sessions.length} session records were found in the " "FIT file." end ts = Time . parse ( '1989-12-31' ) distance = nil invalid_records = [ ] @records . each_with_index do | r , idx | Log . fatal "Record has no timestamp" unless r . timestamp if r . timestamp < ts Log . fatal "Record has earlier timestamp than previous record" end if r . distance if distance && r . distance < distance Log . error "Record #{r.timestamp} has smaller distance " + "(#{r.distance}) than an earlier record (#{distance})." ( idx - 1 ) . downto ( 0 ) do | i | if ( ri = @records [ i ] ) . distance > r . distance invalid_records << ri else break end end end distance = r . distance end ts = r . timestamp end unless invalid_records . empty? Log . warn "Discarding #{invalid_records.length} earlier records" @records . delete_if { | r | invalid_records . include? ( r ) } end @laps . each . with_index do | lap , index | lap . check ( index ) @heart_rate_zones [ index ] . check ( index ) if @heart_rate_zones [ index ] end @sessions . each { | s | s . check ( self ) } end
424	def total_gps_distance timer_stops = [ ] @events . each do | e | if e . event == 'timer' && e . event_type == 'stop_all' timer_stops << e . timestamp end end d = 0.0 last_lat = last_long = nil last_timestamp = nil @records . each do | r | if ( lat = r . position_lat ) && ( long = r . position_long ) if last_lat && last_long distance = Fit4Ruby :: GeoMath . distance ( last_lat , last_long , lat , long ) d += distance end if last_timestamp speed = distance / ( r . timestamp - last_timestamp ) end if timer_stops [ 0 ] == r . timestamp last_lat = last_long = nil last_timestamp = nil timer_stops . shift else last_lat = lat last_long = long last_timestamp = r . timestamp end end end d end
425	def vo2max @events . each do | e | return e . vo2max if e . event == 'vo2max' end @user_data . each do | u | return u . metmax * 3.5 if u . metmax end nil end
426	def write ( io , id_mapper ) @file_id . write ( io , id_mapper ) @file_creator . write ( io , id_mapper ) ( @field_descriptions + @developer_data_ids + @device_infos + @sensor_settings + @data_sources + @user_profiles + @physiological_metrics + @events + @sessions + @laps + @records + @heart_rate_zones + @personal_records ) . sort . each do | s | s . write ( io , id_mapper ) end super end
427	def new_fit_data_record ( record_type , field_values = { } ) case record_type when 'file_id' @file_id = ( record = FileId . new ( field_values ) ) when 'field_description' @field_descriptions << ( record = FieldDescription . new ( field_values ) ) when 'developer_data_id' @developer_data_ids << ( record = DeveloperDataId . new ( field_values ) ) when 'epo_data' @epo_data = ( record = EPO_Data . new ( field_values ) ) when 'file_creator' @file_creator = ( record = FileCreator . new ( field_values ) ) when 'device_info' @device_infos << ( record = DeviceInfo . new ( field_values ) ) when 'sensor_settings' @sensor_settings << ( record = SensorSettings . new ( field_values ) ) when 'data_sources' @data_sources << ( record = DataSources . new ( field_values ) ) when 'user_data' @user_data << ( record = UserData . new ( field_values ) ) when 'user_profile' @user_profiles << ( record = UserProfile . new ( field_values ) ) when 'physiological_metrics' @physiological_metrics << ( record = PhysiologicalMetrics . new ( field_values ) ) when 'event' @events << ( record = Event . new ( field_values ) ) when 'session' unless @cur_lap_records . empty? lap_field_values = { } [ :timestamp , :sport ] . each do | f | lap_field_values [ f ] = field_values [ f ] if field_values . include? ( f ) end record = create_new_lap ( lap_field_values ) end @num_sessions += 1 @sessions << ( record = Session . new ( @cur_session_laps , @lap_counter , field_values ) ) @cur_session_laps = [ ] when 'lap' record = create_new_lap ( field_values ) when 'record' @cur_lap_records << ( record = Record . new ( field_values ) ) @records << record when 'hrv' @hrv << ( record = HRV . new ( field_values ) ) when 'heart_rate_zones' @heart_rate_zones << ( record = HeartRateZones . new ( field_values ) ) when 'personal_records' @personal_records << ( record = PersonalRecords . new ( field_values ) ) else record = nil end record end
428	def check ( activity ) unless @first_lap_index Log . fatal 'first_lap_index is not set' end unless @num_laps Log . fatal 'num_laps is not set' end @first_lap_index . upto ( @first_lap_index - @num_laps ) do | i | if ( lap = activity . lap [ i ] ) @laps << lap else Log . fatal "Session references lap #{i} which is not contained in " "the FIT file." end end end
429	def field ( number , type , name , opts = { } ) field = Field . new ( type , name , opts ) register_field_by_name ( field , name ) register_field_by_number ( field , number ) end
430	def alt_field ( number , ref_field , & block ) unless @fields_by_name . include? ( ref_field ) raise "Unknown ref_field: #{ref_field}" end field = AltField . new ( self , ref_field , & block ) register_field_by_number ( field , number ) end
431	def spam? self . class . mail_captcha . each do | field | next if send ( field ) . blank? if defined? ( Rails ) && Rails . env . development? raise ScriptError , "The captcha field #{field} was supposed to be blank" else return true end end false end
432	def deliver! mailer = MailForm :: Notifier . contact ( self ) if mailer . respond_to? ( :deliver_now ) mailer . deliver_now else mailer . deliver end end
433	def mail_form_attributes self . class . mail_attributes . each_with_object ( { } ) do | attr , hash | hash [ attr . to_s ] = send ( attr ) end end
434	def start extract_and_configure if config . managed? exec ( 'start' , p : port , c : config . cloud ) unless status sleep config . poll_interval end after_start end end
435	def restart if config . managed? && started? exec ( 'restart' , p : port , c : config . cloud ) end end
436	def create ( options = { } ) options [ :name ] ||= SecureRandom . hex create_options = { p : port } create_options [ :c ] = options [ :name ] if options [ :name ] create_options [ :n ] = options [ :config_name ] if options [ :config_name ] create_options [ :d ] = options [ :dir ] if options [ :dir ] Retriable . retriable do raise "Not started yet" unless started? end return if options [ :persist ] && create_options [ :c ] && client . exists? ( create_options [ :c ] ) exec ( "create" , create_options ) options [ :name ] end
437	def upconfig ( options = { } ) options [ :name ] ||= SecureRandom . hex options [ :zkhost ] ||= zkhost upconfig_options = { upconfig : true , n : options [ :name ] } upconfig_options [ :d ] = options [ :dir ] if options [ :dir ] upconfig_options [ :z ] = options [ :zkhost ] if options [ :zkhost ] exec 'zk' , upconfig_options options [ :name ] end
438	def downconfig ( options = { } ) options [ :name ] ||= SecureRandom . hex options [ :zkhost ] ||= zkhost downconfig_options = { downconfig : true , n : options [ :name ] } downconfig_options [ :d ] = options [ :dir ] if options [ :dir ] downconfig_options [ :z ] = options [ :zkhost ] if options [ :zkhost ] exec 'zk' , downconfig_options options [ :name ] end
439	def with_collection ( options = { } ) options = config . collection_options . merge ( options ) return yield if options . empty? name = create ( options ) begin yield name ensure delete name unless options [ :persist ] end end
440	def clean! stop remove_instance_dir! FileUtils . remove_entry ( config . download_dir , true ) if File . exist? ( config . download_dir ) FileUtils . remove_entry ( config . tmp_save_dir , true ) if File . exist? config . tmp_save_dir checksum_validator . clean! FileUtils . remove_entry ( config . version_file ) if File . exist? config . version_file end
441	def get_signals all_signals = [ ] current = @klass while current != Qt :: Base meta = Meta [ current . name ] if ! meta . nil? all_signals . concat meta . signals end current = current . superclass end return all_signals end
442	def + ( other ) if Duration === other Duration . new ( value + other . value , @parts + other . parts ) else Duration . new ( value + other , @parts + [ [ :seconds , other ] ] ) end end
443	def days_to_week_start ( start_day = Date . beginning_of_week ) start_day_number = DAYS_INTO_WEEK [ start_day ] current_day_number = wday != 0 ? wday - 1 : 6 ( current_day_number - start_day_number ) % 7 end
444	def reset @width = 0 if no_width @render_period = frequency == 0 ? 0 : 1.0 / frequency @current = 0 @last_render_time = Time . now @last_render_width = 0 @done = false @stopped = false @start_at = Time . now @started = false @tokens = { } @meter . clear end
445	def advance ( progress = 1 , tokens = { } ) return if done? synchronize do emit ( :progress , progress ) if progress . respond_to? ( :to_hash ) tokens , progress = progress , 1 end @start_at = Time . now if @current . zero? && ! @started @current += progress @tokens = tokens @meter . sample ( Time . now , progress ) if ! no_width && @current >= total finish && return end now = Time . now return if ( now - @last_render_time ) < @render_period render end end
446	def iterate ( collection , progress = 1 , & block ) update ( total : collection . count * progress ) unless total progress_enum = Enumerator . new do | iter | collection . each do | elem | advance ( progress ) iter . yield ( elem ) end end block_given? ? progress_enum . each ( & block ) : progress_enum end
447	def update ( options = { } ) synchronize do options . each do | name , val | if @configuration . respond_to? ( "#{name}=" ) @configuration . public_send ( "#{name}=" , val ) end end end end
448	def render return if done? if hide_cursor && @last_render_width == 0 && ! ( @current >= total ) write ( TTY :: Cursor . hide ) end if @multibar characters_in = @multibar . line_inset ( self ) update ( inset : self . class . display_columns ( characters_in ) ) end formatted = @formatter . decorate ( self , @format ) @tokens . each do | token , val | formatted = formatted . gsub ( ":#{token}" , val ) end padded = padout ( formatted ) write ( padded , true ) @last_render_time = Time . now @last_render_width = self . class . display_columns ( formatted ) end
449	def move_to_row if @multibar CURSOR_LOCK . synchronize do if @first_render @row = @multibar . next_row yield if block_given? output . print "\n" @first_render = false else lines_up = ( @multibar . rows + 1 ) - @row output . print TTY :: Cursor . save output . print TTY :: Cursor . up ( lines_up ) yield if block_given? output . print TTY :: Cursor . restore end end else yield if block_given? end end
450	def write ( data , clear_first = false ) return unless tty? move_to_row do output . print ( TTY :: Cursor . column ( 1 ) ) if clear_first characters_in = @multibar . line_inset ( self ) if @multibar output . print ( "#{characters_in}#{data}" ) output . flush end end
451	def finish return if done? @current = total unless no_width render clear ? clear_line : write ( "\n" , false ) ensure @meter . clear @done = true if hide_cursor && @last_render_width != 0 write ( TTY :: Cursor . show , false ) end emit ( :done ) end
452	def stop if hide_cursor && @last_render_width != 0 write ( TTY :: Cursor . show , false ) end return if done? render clear ? clear_line : write ( "\n" , false ) ensure @meter . clear @stopped = true emit ( :stopped ) end
453	def log ( message ) sanitized_message = message . gsub ( / \r \n / , ' ' ) if done? write ( sanitized_message + "\n" , false ) return end sanitized_message = padout ( sanitized_message ) write ( sanitized_message + "\n" , true ) render end
454	def padout ( message ) message_length = self . class . display_columns ( message ) if @last_render_width > message_length remaining_width = @last_render_width - message_length message += ' ' * remaining_width end message end
455	def lock_exclusively! ( max_run_time , worker = worker_name ) now = self . class . db_time_now affected_rows = if locked_by != worker self . class . update_all ( [ "locked_at = ?, locked_by = ?" , now , worker ] , [ "id = ? and (locked_at is null or locked_at < ?)" , id , ( now - max_run_time . to_i ) ] ) else self . class . update_all ( [ "locked_at = ?" , now ] , [ "id = ? and locked_by = ?" , id , worker ] ) end if affected_rows == 1 self . locked_at = now self . locked_by = worker return true else return false end end
456	def setup_tracery dir_path raise "Provided path not a directory" unless Dir . exist? ( dir_path ) @grammar = { } Dir . open ( dir_path ) do | dir | dir . each do | file | next if file =~ / \. \. / @grammar [ file . split ( '.' ) . first ] = createGrammar ( JSON . parse ( File . read ( "#{dir_path}/#{file}" ) ) ) end end unless @grammar [ 'reply' ] . nil? on_reply { | bot | bot . reply_with_mentions ( '#default#' , rules : 'reply' ) } end end
457	def expand_and_post ( text , * options ) opts = Hash [ * options ] rules = opts . fetch ( :rules , 'default' ) actually_post ( @grammar [ rules ] . flatten ( text ) , ** opts . reject { | k | k == :rules } ) end
458	def run_interact @streamer . user do | update | if update . kind_of? Mastodon :: Notification case update . type when 'mention' update . status . class . module_eval { alias_method :content , :strip } if @strip_html store_mention_data update . status @on_reply . call ( self , update . status ) unless @on_reply . nil? when 'reblog' @on_boost . call ( self , update ) unless @on_boost . nil? when 'favourite' @on_fave . call ( self , update ) unless @on_fave . nil? when 'follow' @on_follow . call ( self , update ) unless @on_follow . nil? end end end end
459	def reply ( text , * options ) options = Hash [ * options ] post ( "@#{@mention_data[:account].acct} #{text}" , ** @mention_data . merge ( options ) . reject { | k | k == :mentions or k == :account } ) end
460	def run_reply @streamer . user do | update | next unless update . kind_of? Mastodon :: Notification and update . type == 'mention' update . status . class . module_eval { alias_method :content , :strip } if @strip_html store_mention_data update . status if block_given? yield ( self , update . status ) else @on_reply . call ( self , update . status ) end end end
461	def store_mention_data ( mention ) @mention_data = { reply_id : mention . id , visibility : mention . visibility , spoiler : mention . spoiler_text , hide_media : mention . sensitive? , mentions : mention . mentions , account : mention . account } end
462	def setup_streaming stream_uri = @client . instance ( ) . attributes [ 'urls' ] [ 'streaming_api' ] . gsub ( / / , 'https' ) @streamer = Mastodon :: Streaming :: Client . new ( base_url : stream_uri , bearer_token : ENV [ 'TOKEN' ] ) end
463	def parse_service_name ( path ) parts = Pathname . new ( path ) . each_filename . to_a . reverse! parts . find { | seg | ! COMMON_SEGMENTS [ seg ] } || parts . first end
464	def connect start_time = Time . now retries = 0 close begin connect_to_server ( servers , policy ) logger . info ( message : "Connected to #{address}" , duration : ( Time . now - start_time ) * 1000 ) if respond_to? ( :logger ) rescue ConnectionFailure , ConnectionTimeout => exception cause = exception . is_a? ( ConnectionTimeout ) ? exception : exception . cause if self . class . reconnect_on_errors . include? ( cause . class ) && ( retries < connect_retry_count . to_i ) retries += 1 logger . warn "#connect Failed to connect to any of #{servers.join(',')}. Sleeping:#{connect_retry_interval}s. Retry: #{retries}" if respond_to? ( :logger ) sleep ( connect_retry_interval ) retry else message = "#connect Failed to connect to any of #{servers.join(',')} after #{retries} retries. #{exception.class}: #{exception.message}" logger . benchmark_error ( message , exception : exception , duration : ( Time . now - start_time ) ) if respond_to? ( :logger ) raise ConnectionFailure . new ( message , address . to_s , cause ) end end end
465	def write ( data , timeout = write_timeout ) data = data . to_s if respond_to? ( :logger ) payload = { timeout : timeout } payload [ :data ] = data if logger . trace? logger . benchmark_debug ( '#write' , payload : payload ) do payload [ :bytes ] = socket_write ( data , timeout ) end else socket_write ( data , timeout ) end rescue Exception => exc close if close_on_error raise exc end
466	def read ( length , buffer = nil , timeout = read_timeout ) if respond_to? ( :logger ) payload = { bytes : length , timeout : timeout } logger . benchmark_debug ( '#read' , payload : payload ) do data = socket_read ( length , buffer , timeout ) payload [ :data ] = data if logger . trace? data end else socket_read ( length , buffer , timeout ) end rescue Exception => exc close if close_on_error raise exc end
467	def close socket . close if socket && ! socket . closed? @socket = nil @address = nil true rescue IOError => exception logger . warn "IOError when attempting to close socket: #{exception.class}: #{exception.message}" if respond_to? ( :logger ) false end
468	def alive? return false if socket . nil? || closed? if IO . select ( [ socket ] , nil , nil , 0 ) ! socket . eof? rescue false else true end rescue IOError false end
469	def socket_connect ( socket , address , timeout ) socket_address = Socket . pack_sockaddr_in ( address . port , address . ip_address ) return socket . connect ( socket_address ) if timeout == - 1 deadline = Time . now . utc + timeout begin non_blocking ( socket , deadline ) { socket . connect_nonblock ( socket_address ) } rescue Errno :: EISCONN rescue NonBlockingTimeout raise ConnectionTimeout . new ( "Timed out after #{timeout} seconds trying to connect to #{address}" ) rescue SystemCallError , IOError => exception message = "#connect Connection failure connecting to '#{address.to_s}': #{exception.class}: #{exception.message}" logger . error message if respond_to? ( :logger ) raise ConnectionFailure . new ( message , address . to_s , exception ) end end
470	def socket_write ( data , timeout ) if timeout < 0 socket . write ( data ) else deadline = Time . now . utc + timeout length = data . bytesize total_count = 0 non_blocking ( socket , deadline ) do loop do begin count = socket . write_nonblock ( data ) rescue Errno :: EWOULDBLOCK retry end total_count += count return total_count if total_count >= length data = data . byteslice ( count .. - 1 ) end end end rescue NonBlockingTimeout logger . warn "#write Timeout after #{timeout} seconds" if respond_to? ( :logger ) raise WriteTimeout . new ( "Timed out after #{timeout} seconds trying to write to #{address}" ) rescue SystemCallError , IOError => exception message = "#write Connection failure while writing to '#{address.to_s}': #{exception.class}: #{exception.message}" logger . error message if respond_to? ( :logger ) raise ConnectionFailure . new ( message , address . to_s , exception ) end
471	def ssl_connect ( socket , address , timeout ) ssl_context = OpenSSL :: SSL :: SSLContext . new ssl_context . set_params ( ssl . is_a? ( Hash ) ? ssl : { } ) ssl_socket = OpenSSL :: SSL :: SSLSocket . new ( socket , ssl_context ) ssl_socket . hostname = address . host_name ssl_socket . sync_close = true begin if timeout == - 1 ssl_socket . connect else deadline = Time . now . utc + timeout begin non_blocking ( socket , deadline ) { ssl_socket . connect_nonblock } rescue Errno :: EISCONN rescue NonBlockingTimeout raise ConnectionTimeout . new ( "SSL handshake Timed out after #{timeout} seconds trying to connect to #{address.to_s}" ) end end rescue SystemCallError , OpenSSL :: SSL :: SSLError , IOError => exception message = "#connect SSL handshake failure with '#{address.to_s}': #{exception.class}: #{exception.message}" logger . error message if respond_to? ( :logger ) raise ConnectionFailure . new ( message , address . to_s , exception ) end ssl_verify ( ssl_socket , address ) if ssl_context . verify_mode != OpenSSL :: SSL :: VERIFY_NONE ssl_socket end
472	def party_mode new_master = nil return nil unless speakers . length > 1 new_master = find_party_master if new_master . nil? party_over speakers . each do | slave | next if slave . uid == new_master . uid slave . join new_master end rescan @topology end
473	def discover result = SSDP :: Consumer . new . search ( service : 'urn:schemas-upnp-org:device:ZonePlayer:1' , first_only : true , timeout : @timeout , filter : lambda { | r | r [ :params ] [ "ST" ] . match ( / / ) } ) @first_device_ip = result [ :address ] end
474	def topology self . discover unless @first_device_ip return [ ] unless @first_device_ip doc = Nokogiri :: XML ( open ( "http://#{@first_device_ip}:#{Sonos::PORT}/status/topology" ) ) doc . xpath ( '//ZonePlayers/ZonePlayer' ) . map do | node | TopologyNode . new ( node ) end end
475	def find ( id ) response = RestClient . get ( "#{@type.Resource}/#{id}" ) singular_resource = @type . Resource [ 0 ... - 1 ] if response . body [ singular_resource ] . nil? raise ArgumentError , 'Resource not found' end type . new . from_json ( response . body [ singular_resource ] . to_json ) end
476	def all list = [ ] page = 1 fetch_all = true if @query . has_key? ( :page ) page = @query [ :page ] fetch_all = false end while true response = RestClient . get ( @type . Resource , @query ) data = response . body [ @type . Resource ] if ! data . empty? data . each { | item | list << @type . new . from_json ( item . to_json ) } if ! fetch_all break else where ( page : page += 1 ) end else break end end return list end
477	def validate ( form ) property = attributes . first record = form . model_for_property ( property ) record . send ( "#{property}=" , form . send ( property ) ) @klass = record . class super ( record ) . tap do | res | form . errors . add ( property , record . errors . first . last ) if record . errors . present? end end
478	def validates ( * args , & block ) validation ( name : :default , inherit : true ) { validates * args , & block } end
479	def update_xml ( xml , value ) wrap ( xml ) . tap do | xml | if content? add ( xml , value ) elsif name? xml . name = value elsif array? value . each do | v | add ( XML . add_node ( xml , name ) , v ) end else add ( XML . add_node ( xml , name ) , value ) end end end
480	def ipmt ( rate , per , nper , pv , fv = 0 , end_or_beginning = 0 ) pmt = self . pmt ( rate , nper , pv , fv , end_or_beginning ) fv = self . fv ( rate , ( per - 1 ) , pmt , pv , end_or_beginning ) * rate temp = end_or_beginning == 1 ? fv / ( 1 + rate ) : fv ( per == 1 && end_or_beginning == 1 ) ? 0.0 : temp end
481	def nper ( rate , pmt , pv , fv = 0 , end_or_beginning = 0 ) z = pmt * ( 1 + rate * end_or_beginning ) / rate temp = Math . log ( ( - fv + z ) / ( pv + z ) ) temp / Math . log ( 1 + rate ) end
482	def pmt ( rate , nper , pv , fv = 0 , end_or_beginning = 0 ) temp = ( 1 + rate ) ** nper fact = ( 1 + rate * end_or_beginning ) * ( temp - 1 ) / rate - ( fv + pv * temp ) / fact end
483	def rate ( nper , pmt , pv , fv = 0 , end_or_beginning = 0 , rate_guess = 0.10 ) guess = rate_guess tolerancy = 1e-6 close = false begin temp = newton_iter ( guess , nper , pmt , pv , fv , end_or_beginning ) next_guess = ( guess - temp ) . round ( 20 ) diff = ( next_guess - guess ) . abs close = diff < tolerancy guess = next_guess end while ! close next_guess end
484	def npv ( discount , cashflows ) total = 0 cashflows . each_with_index do | cashflow , index | total += ( cashflow . to_f / ( 1 + discount . to_f ) ** ( index + 1 ) ) end total end
485	def irr ( values ) func = Helpers :: IrrHelper . new ( values ) guess = [ func . eps ] nlsolve ( func , guess ) guess [ 0 ] end
486	def newton_iter ( r , n , p , x , y , w ) t1 = ( r + 1 ) ** n t2 = ( r + 1 ) ** ( n - 1 ) ( ( y + t1 * x + p * ( t1 - 1 ) * ( r * w + 1 ) / r ) / ( n * t2 * x - p * ( t1 - 1 ) * ( r * w + 1 ) / ( r ** 2 ) + n * p * t2 * ( r * w + 1 ) / r + p * ( t1 - 1 ) * w / r ) ) end
487	def event_summary ( trim_at = 100 ) summary = @event [ 'check' ] [ 'notification' ] || @event [ 'check' ] [ 'description' ] if summary . nil? source = @event [ 'check' ] [ 'source' ] || @event [ 'client' ] [ 'name' ] event_context = [ source , @event [ 'check' ] [ 'name' ] ] . join ( '/' ) output = @event [ 'check' ] [ 'output' ] . chomp output = output . length > trim_at ? output [ 0 .. trim_at ] + '...' : output summary = [ event_context , output ] . join ( ' : ' ) end summary end
488	def load @io . rewind header_block = @io . read 512 @header = Header . new header_block @bbat = AllocationTable :: Big . new self bbat_chain = header_block [ Header :: SIZE .. - 1 ] . unpack 'V*' mbat_block = @header . mbat_start @header . num_mbat . times do blocks = @bbat . read ( [ mbat_block ] ) . unpack 'V*' mbat_block = blocks . pop bbat_chain += blocks end @bbat . load @bbat . read ( bbat_chain [ 0 , @header . num_bat ] ) @dirents = @bbat . read ( @header . dirent_start ) . to_enum ( :each_chunk , Dirent :: SIZE ) . map { | str | Dirent . new self , str } class << @dirents def to_tree idx = 0 return [ ] if idx == Dirent :: EOT d = self [ idx ] to_tree ( d . child ) . each { | child | d << child } raise FormatError , "directory #{d.inspect} used twice" if d . idx d . idx = idx to_tree ( d . prev ) + [ d ] + to_tree ( d . next ) end end @root = @dirents . to_tree . first @dirents . reject! { | d | d . type_id == 0 } unused = @dirents . reject ( & :idx ) . length Log . warn "#{unused} unused directories" if unused > 0 @sb_file = RangesIOResizeable . new @bbat , :first_block => @root . first_block , :size => @root . size @sbat = AllocationTable :: Small . new self @sbat . load @bbat . read ( @header . sbat_start ) end
489	def repack temp = :file case temp when :file Tempfile . open 'ole-repack' do | io | io . binmode repack_using_io io end when :mem ; StringIO . open ( '' . dup , & method ( :repack_using_io ) ) else raise ArgumentError , "unknown temp backing #{temp.inspect}" end end
490	def load_relation ( relationship , position = nil ) if objects = @resource . dig ( "_embedded" , relationship ) location = position ? objects [ position ] : objects begin WpApiClient :: Collection . new ( location ) rescue WpApiClient :: ErrorResponse load_from_links ( relationship , position ) end else load_from_links ( relationship , position ) end end
491	def native_representation_of ( response_body ) if response_body . is_a? Array WpApiClient :: Collection . new ( response_body , @headers ) else WpApiClient :: Entities :: Base . build ( response_body ) end end
492	def call_func ( method : , params : [ ] , tx : { } ) data , output_types = function_data_with_ot ( method , * params ) resp = @rpc . call_rpc ( :call , params : [ tx . merge ( data : data , to : address ) , "latest" ] ) result = resp [ "result" ] data = [ Utils . remove_hex_prefix ( result ) ] . pack ( "H*" ) return if data . nil? re = decode_abi output_types , data re . length == 1 ? re . first : re end
493	def send_func ( tx : , private_key : , method : , params : [ ] ) data , _output_types = function_data_with_ot ( method , * params ) transaction = if tx . is_a? ( Hash ) Transaction . from_hash ( tx ) else tx end transaction . data = data resp = @rpc . send_transaction ( transaction , private_key ) resp &. dig ( "result" ) end
494	def parse_url uri = URI . parse ( @url ) @host = uri . host @port = uri . port @scheme = uri . scheme end
495	def call_rpc ( method , jsonrpc : DEFAULT_JSONRPC , params : DEFAULT_PARAMS , id : DEFAULT_ID ) conn . post ( "/" , rpc_params ( method , jsonrpc : jsonrpc , params : params , id : id ) ) end
496	def rpc_params ( method , jsonrpc : DEFAULT_JSONRPC , params : DEFAULT_PARAMS , id : DEFAULT_ID ) { jsonrpc : jsonrpc , id : id , method : method , params : params } . to_json end
497	def conn Faraday . new ( url : url ) do | faraday | faraday . headers [ "Content-Type" ] = "application/json" faraday . request :url_encoded faraday . adapter Faraday . default_adapter end end
498	def transfer ( to : , private_key : , value : , quota : 30_000 ) valid_until_block = block_number [ "result" ] . hex + 88 meta_data = get_meta_data ( "latest" ) [ "result" ] version = meta_data [ "version" ] chain_id = if version . zero? meta_data [ "chainId" ] elsif version == 1 meta_data [ "chainIdV1" ] end transaction = Transaction . new ( nonce : Utils . nonce , valid_until_block : valid_until_block , chain_id : chain_id , to : to , value : value , quota : quota , version : version ) send_transaction ( transaction , private_key ) end
499	def replace ( new ) if String === new @data . replace ( JSON . parse ( new ) ) else @data . replace ( new ) end end
500	def to_json io = StringIO . new ( "{" ) io << JSON . create_id . to_json << ":" << self . class . name . to_json << "," @data . each { | key , value | io << key . to_json . to_s << ":" << value . to_json << "," } io . seek ( - 1 , IO :: SEEK_CUR ) io << "}" io . string end
501	def time ( label , & block ) raise ArgumentError , "no block given" unless block ` ` begin if block . arity == 0 instance_exec ( & block ) else block . call ( self ) end ensure ` ` end end
502	def group ( * args , & block ) raise ArgumentError , "no block given" unless block ` ` begin if block . arity == 0 instance_exec ( & block ) else block . call ( self ) end ensure ` ` end end
503	def group! ( * args , & block ) return unless block_given? ` ` begin if block . arity == 0 instance_exec ( & block ) else block . call ( self ) end ensure ` ` end end
504	def authenticate! options = authentication_handler . call ( self , @options ) @options . merge! ( options ) client . config . soap_header = soap_headers end
505	def new_with_uuid ( klass , uuid ) if klass . is_a? ( String ) klass = Object . const_get ( klass ) end object = klass . new ( self , uuid ) object . initialize_defaults object end
506	def new_reference_with_uuid ( path , uuid , source_tree = :group ) path = Pathname . new ( path ) ref = self . project . new_with_uuid ( PBXFileReference , uuid ) self . children << ref GroupableHelper . set_path_with_source_tree ( ref , path , source_tree ) ref . set_last_known_file_type if ref . path . include? ( '/' ) ref . name = ref . path . split ( '/' ) . last end if File . extname ( ref . path ) . downcase == '.framework' ref . include_in_index = nil end ref end
507	def add_file_reference_with_uuid ( file_ref , uuid , avoid_duplicates = false ) if avoid_duplicates && existing = build_file ( file_ref ) existing else build_file = project . new_with_uuid ( PBXBuildFile , uuid ) build_file . file_ref = file_ref files . insert ( 0 , build_file ) build_file end end
508	def remove_seeds removings = self . locks . keys - self . seeds . keys removings . each do | name | say "Removing #{name} (#{self.locks[name].version})" . red dirname = File . join ( self . root_path , "Seeds" , name ) FileUtils . rm_rf ( dirname ) end end
509	def configure_phase self . project . targets . each do | target | begin phase = target . sources_build_phase resource_phase = target . resources_build_phase next unless phase rescue NoMethodError next end phase . files_references . each do | file | begin file . real_path rescue phase . files . each do | build_file | phase . files . delete ( build_file ) if build_file . file_ref == file end end end resource_phase . files_references . each do | file | begin file . real_path rescue resource_phase . files . each do | build_file | resource_phase . files . delete ( build_file ) if build_file . file_ref == file end end end removings = [ ] addings = [ ] self . targets . keys . sort . each do | seed_name | target_names = self . targets [ seed_name ] if not target_names . include? ( target . name ) removings << seed_name if not removings . include? ( seed_name ) else addings << seed_name if not addings . include? ( seed_name ) end end self . file_references . each do | file | removings . each do | seed_names | next if not seed_names . include? ( file . parent . name ) phase . files . each do | build_file | phase . files . delete ( build_file ) if build_file . file_ref == file end resource_phase . files . each do | build_file | resource_phase . files . delete ( build_file ) if build_file . file_ref == file end end addings . each do | seed_names | next if file . name . end_with? ".h" next if not seed_names . include? ( file . parent . name ) uuid = Xcodeproj :: uuid_with_name "#{target.name}:#{file.name}" if self . valid_source_file? ( file ) phase . add_file_reference_with_uuid ( file , uuid , true ) else resource_phase . add_file_reference_with_uuid ( file , uuid , true ) end end end end end
510	def valid_source_file? filename suffixs = [ ".h" , ".c" , ".m" , ".mm" , ".swift" , ".cpp" ] suffixs . each do | suffix | return true if filename . name . end_with? suffix end return false end
511	def speller return @speller if @speller begin require "raspell" rescue LoadError $stderr . puts "ERROR: Ruby gem \"raspell\" is not installed." exit 1 end @speller = Aspell . new ( "en_US" ) @speller . suggestion_mode = Aspell :: NORMAL @speller . set_option ( "mode" , "html" ) @speller end
512	def files_to_check files = config [ "check" ] . reduce ( [ ] ) { | a , e | a + Dir [ e ] } config [ "ignore" ] . reduce ( files ) { | a , e | a - Dir [ e ] } end
513	def read_spell_config ( file ) return { } unless File . exist? ( file ) puts "Loading config file (#{file})..." if verbose == true require "yaml" YAML . load_file ( file ) end
514	def report_duplicates ( dict1 , dict2 ) duplicates = dict1 & dict2 return if duplicates . empty? $stderr . puts "Warning: Found dictionary duplicates in the local dictionary " "(#{CUSTOM_SPELL_CONFIG_FILE}):\n" duplicates . each { | duplicate | $stderr . puts " #{duplicate}" } $stderr . puts end
515	def config return @config if @config @config = read_spell_config ( GLOBAL_SPELL_CONFIG_FILE ) custom_config = read_spell_config ( CUSTOM_SPELL_CONFIG_FILE ) report_duplicates ( config [ "dictionary" ] , custom_config [ "dictionary" ] . to_a ) custom_config [ "dictionary" ] = @config [ "dictionary" ] + custom_config [ "dictionary" ] . to_a custom_config [ "dictionary" ] . uniq! @config . merge! ( custom_config ) @config end
516	def check_file ( file ) puts "Checking #{file}..." if verbose == true lines = File . read ( file ) . split ( "\n" ) success = true lines . each_with_index do | text , index | misspelled = misspelled_on_line ( text ) next if misspelled . empty? success = false print_misspelled ( misspelled , index , text ) end success end
517	def check_writable ( path ) raise Error , "'#{path}' is not writable" if path . exist? && ! path . writable? || ! path . parent . writable? end
518	def check_option ( opt ) raise Error , "The option is not an OptBase, #{opt.class} supplied" unless opt . is_a? ( OptBase ) raise Error , "The option #{opt.to_sym} is already used !" if @symbols_used . include? ( opt . to_sym ) end
519	def post_processing @opts . each do | opt | raise NoRequiredOption , "The option #{opt} is required" if opt . required? && ! @results . key? ( opt . to_sym ) next if opt . required_unless . empty? || @results . key? ( opt . to_sym ) fail_msg = "One of the following options is required: #{opt}, #{opt.required_unless.join(', ')}" raise NoRequiredOption , fail_msg unless opt . required_unless . any? do | sym | @results . key? ( sym ) end end end
520	def subdir_entities ( dir = @current_dir ) Dir . glob ( dir [ :path ] . gsub ( / \\ \[ \] / , '\\\\\0' ) + '/*' ) . map! { | path | { path : path , time : File . mtime ( path ) , name : File . basename ( path ) } } end
521	def string_to_bytes ( str ) unless @e . nil? || @e == :utf8 if @e == :shift_jis begin str = str . gsub / \\ \uff5e / , '' str . encode! 'Shift_JIS' , :invalid => :replace , :undef => :replace , :replace => '' rescue => e end end end [ str ] . pack ( 'a*' ) end
522	def pack ( files ) entities = Entity . entities_from files return if entities . empty? reset_state pack_entities entities while has_dir? cd next_dir pack_current_dir end end
523	def pack_symlinks reset_state @l . each do | link | if @w . path_exists? Entity . linked_path ( link [ :abs_path ] , File . readlink ( link [ :path ] ) ) link [ :name ] = link [ :abs_path ] pack_symbolic_link_entity link end end end
524	def pack_entities ( entities ) entities . each do | entity | next unless entity . is_a? ( Hash ) && entity [ :path ] path = entity [ :path ] if File . symlink? path postpone_symlink entity elsif File . directory? path postpone_dir entity elsif File . file? path pack_file_entity entity end end end
525	def header content = nil , options = nil , html_options = nil , & block @header = UiBibz :: Ui :: Core :: Lists :: Components :: ListHeader . new content , options , html_options , & block end
526	def body content = nil , options = nil , html_options = nil , & block @body = UiBibz :: Ui :: Core :: Lists :: Components :: ListBody . new content , options , html_options , & block end
527	def td_content record , col content = col . count ? record . send ( col . data_index ) . count : record . send ( col . data_index ) unless content . nil? content = content . strftime ( col . date_format ) unless col . date_format . nil? content = link_to content , action . inject_url ( col . link , record ) unless col . link . nil? content = col . format . call ( @store . records , record ) unless col . format . nil? end content = As . new ( col , record , content , @options ) . render unless col . as . nil? content end
528	def body content = nil , options = nil , html_options = nil , & block options , content = inherit_options ( content , options , block ) if is_tap ( content , options ) content = ( content || { } ) . merge ( collapse : options . try ( :[] , :collapse ) , parent_collapse : @options [ :parent_collapse ] ) @items << UiBibz :: Ui :: Core :: Boxes :: Components :: CardBody . new ( content , options , html_options ) . tap ( & block ) . render else options = ( options || { } ) . merge ( collapse : options . try ( :[] , :collapse ) , parent_collapse : @options [ :parent_collapse ] ) @items << UiBibz :: Ui :: Core :: Boxes :: Components :: CardBody . new ( content , options , html_options , & block ) . render end end
529	def footer content = nil , options = nil , html_options = nil , & block options , content = inherit_options ( content , options , block ) @footer = UiBibz :: Ui :: Core :: Boxes :: Components :: CardFooter . new ( content , options , html_options , & block ) . render end
530	def list_group content = nil , options = nil , html_options = nil , & block @items << UiBibz :: Ui :: Core :: Boxes :: Components :: CardListGroup . new ( content , options , html_options ) . tap ( & block ) . render end
531	def image content = nil , options = nil , html_options = nil , & block @items << UiBibz :: Ui :: Core :: Boxes :: Components :: CardImage . new ( content , options , html_options , & block ) . render end
532	def html content = nil , & block if ! block . nil? context = eval ( "self" , block . binding ) @items << context . capture ( & block ) else @items << content end end
533	def component_html_options super . merge ( { multiple : options [ :multiple ] , disabled : options [ :state ] == :disabled , include_blank : options [ :include_blank ] , prompt : options [ :prompt ] } ) end
534	def nav content = nil , options = { } , html_options = nil , & block @items << UiBibz :: Ui :: Core :: Component . new ( Nav . new ( content , options ) . tap ( & block ) . render , { } , html_options ) end
535	def body content = nil , options = nil , html_options = nil , & block @body = UiBibz :: Ui :: Core :: Notifications :: Components :: AlertBody . new ( content , options , html_options , & block ) . render end
536	def is_tap content , options ( content [ :tap ] if content . kind_of? ( Hash ) ) || ( options [ :tap ] unless options . nil? ) end
537	def component_html_data data_target = html_options . try ( :[] , :data ) . try ( :[] , :target ) || options . try ( :delete , :target ) add_html_data ( :target , data_target ) unless data_target . nil? data_controller = html_options . try ( :[] , :data ) . try ( :[] , :controller ) || options . try ( :delete , :controller ) add_html_data ( :controller , data_controller ) unless data_controller . nil? data_action = html_options . try ( :[] , :data ) . try ( :[] , :action ) || options . try ( :delete , :action ) add_html_data ( :action , data_action ) unless data_action . nil? data_turbolinks = html_options . try ( :[] , :data ) . try ( :[] , :turbolinks ) || options . try ( :delete , :turbolinks ) add_html_data ( :turbolinks , data_turbolinks ) unless data_turbolinks . nil? end
538	def add_html_data name , value = true html_options [ :data ] = { } if html_options [ :data ] . nil? value = value . kind_of? ( String ) ? value . strip : value html_options [ :data ] . update ( Hash [ name , value ] ) end
539	def header column , name = nil @column = column defaults = [ translate_headers_by_defaults , translate_headers_by_defaults_active_record , translate_headers_by_active_record , header_name ( name ) ] @name = UiBibz :: Utils :: Internationalization . new ( translate_headers_by_model , default : defaults ) . translate sortable? ? sortable_link : title end
540	def column data_index = nil , options = nil , html_options = nil , & block @columns << Column . new ( data_index , options , html_options , & block ) end
541	def link content = nil , options = nil , html_options = nil , & block @actions << UiBibz :: Ui :: Core :: Forms :: Dropdowns :: Components :: DropdownLink . new ( content , options , html_options , & block ) . render end
542	def engine_scaffold FileUtils . mkdir_p ( @gem_temp ) Dir . chdir ( @gem_temp ) do response = Open3 . capture3 ( "rails plugin new #{gem} --mountable --dummy-path=site --skip-test-unit" ) if ! response [ 1 ] . empty? puts response [ 1 ] abort "FAILED: Please be sure you have the rails gem installed with `gem install rails`" end remove = %w( mailers models assets channels jobs views ) . map { | f | File . join ( 'app' , f ) } remove . concat %w( cable.yml storage.yml database.yml ) . map { | f | File . join ( 'config' , f ) } remove . each { | f | FileUtils . rm_rf File . join ( @gem , 'site' , f ) , secure : true } end engine_copy end
543	def engine_copy site_path = File . join path , 'site' FileUtils . mkdir_p site_path Dir . chdir "#{@gem_temp}/#{gem}/site" do %w( app config bin config.ru Rakefile public log ) . each do | item | target = File . join site_path , item FileUtils . cp_r item , target action_log "create" , target . sub ( @cwd + '/' , '' ) end end FileUtils . rm_rf @gem_temp end
544	def make_map ( item ) '(' + item . map { | key , value | key . to_s + ':' + convert_to_sass_value ( value ) } . join ( ',' ) + ')' end
545	def add_files ( klass ) ext = asset_ext klass find_files ( ext ) . map do | path | klass . new ( self , path ) end end
546	def find_files ( ext ) files = Dir [ File . join ( paths [ ext . to_sym ] , asset_glob ( ext ) ) ] files . reject { | f | File . basename ( f ) . start_with? ( '_' ) } end
547	def dispatch ( command , * args ) @threads = [ ] send command , * args @threads . each { | thr | thr . join } end
548	def watch ( options = { } ) build ( options ) require 'listen' trap ( "SIGINT" ) { puts "\nspark_engine watcher stopped. Have a nice day!" exit! } @threads . concat SparkEngine . load_plugin . watch ( options ) end
549	def load_setup ( name ) reader = create_fixture_reader ( name ) reader . each do | fixture_name | load ( fixture_name ) end end
550	def avoid_duplicate_image_names ( content ) nodes = content . xpath ( "//draw:frame[@draw:name]" ) nodes . each_with_index do | node , i | node . attribute ( 'name' ) . value = "pic_#{i}" end end
551	def scope_params return { } if dynamic_scaffold . scope . nil? case dynamic_scaffold . scope when Array then dynamic_scaffold . scope . each_with_object ( { } ) do | val , res | if val . is_a? Hash val . each { | k , v | res [ k ] = v } else res [ val ] = params [ val ] end end when Hash then dynamic_scaffold . scope end end
552	def pkey_string_to_hash ( pkey ) pkey . split ( ',' ) . map { | v | v . split ( ':' ) } . each_with_object ( { } ) { | v , res | res [ v . first ] = v . last } end
553	def update_values permitting = [ ] dynamic_scaffold . form . items . reject { | i | i . type? ( :carrierwave_image ) } . each do | item | item . extract_parameters ( permitting ) end permitting . concat ( dynamic_scaffold . form . permit_params ) dynamic_scaffold . form . items . select { | i | i . type? ( :carrierwave_image ) } . each do | item | item . extract_parameters ( permitting ) end values = params . require ( dynamic_scaffold . model . name . underscore ) . permit ( * permitting ) if dynamic_scaffold . scope && ! valid_for_scope? ( values ) raise DynamicScaffold :: Error :: InvalidOperation , "You can update only to #{scope_params} on this scope" end values end
554	def valid_for_scope? ( update_params ) return true if dynamic_scaffold . scope_options [ :changeable ] result = true scope_params . each do | key , value | if update_params . key? ( key ) && update_params [ key ] != value result = false break end end result end
555	def lock ( timeout : nil , & block ) ensure_exists_and_release_stale_locks! success = @redis . with do | conn | if timeout ! conn . blpop ( available_key , timeout . to_i ) . nil? else ! conn . lpop ( available_key ) . nil? end end return false unless success token = SecureRandom . hex ( 16 ) @tokens . push ( token ) @redis . with do | conn | conn . zadd ( grabbed_key , epoch_f ( conn ) , token ) end return_or_yield ( token , & block ) end
556	def unlock ( token = @tokens . pop ) return unless token removed = false @redis . with do | conn | removed = conn . zrem grabbed_key , token if removed conn . lpush available_key , 1 end end removed end
557	def apply_options ( options = { } ) options . each { | key , value | send ( "#{key}=" , value ) if respond_to? ( key ) } yield ( self ) if block_given? end
558	def show! notify_init ( app_name ) or raise "notify_init failed" raw_ptr = notify_notification_new ( summary , body , icon_path , nil ) @notification = :: FFI :: AutoPointer . new ( raw_ptr , method ( :g_object_unref ) ) show end
559	def update ( options = { } , & block ) apply_options ( options , & block ) if @notification notify_notification_update ( @notification , summary , body , icon_path , nil ) show else show! end end
560	def download raise ArgumentError . new ( 'url cannot be nil' ) if @url . nil? raise ArgumentError . new ( 'url cannot be empty' ) if @url . empty? set_information_from_json ( YoutubeDL :: Runner . new ( url , runner_options ) . run ) end
561	def method_missing ( method , * args , & block ) value = information [ method ] if value . nil? super else value end end
562	def options_to_commands commands = [ ] @options . sanitize_keys . each_paramized_key do | key , paramized_key | if @options [ key ] . to_s == 'true' commands . push "--#{paramized_key}" elsif @options [ key ] . to_s == 'false' commands . push "--no-#{paramized_key}" else commands . push "--#{paramized_key} :#{key}" end end commands . push quoted ( url ) commands . join ( ' ' ) end
563	def with ( hash ) merged = Options . new ( @store . merge ( hash . to_h ) ) merged . banned_keys = @banned_keys merged . send ( :remove_banned ) merged end
564	def method_missing ( method , * args , & _block ) remove_banned if method . to_s . include? '=' method = method . to_s . tr ( '=' , '' ) . to_sym return nil if banned? method @store [ method ] = args . first else return nil if banned? method @store [ method ] end end
565	def manipulate_keys! ( & block ) @store . keys . each do | old_name | new_name = block . call ( old_name ) unless new_name == old_name @store [ new_name ] = @store [ old_name ] @store . delete ( old_name ) end end end
566	def sanitize_keys! manipulate_keys! { | key_name | key_name . is_a? ( Symbol ) ? key_name : key_name . to_sym } manipulate_keys! { | key_name | key_name . to_s . tr ( '-' , '_' ) . to_sym } end
567	def representer_for ( format , model , options = { } ) options . delete ( :represent_with ) || self . class . represents_options . for ( format , model , controller_path ) end
568	def variable_text_field ( x , y , params = { } ) x = 0 unless numeric? ( x ) y = 0 unless numeric? ( y ) options = { height : 0.1 , width : 0.1 } . merge! ( params ) self . variable_fields_count += 1 label_data . push ( '^FO' + Integer ( x * printer_dpi ) . to_s + ',' + Integer ( y * printer_dpi ) . to_s ) if params [ :orientation ] == :landscape label_data . push ( '^A0N,' ) else label_data . push ( '^A0B,' ) end label_data . push ( Integer ( options [ :height ] * printer_dpi ) . to_s + ',' + Integer ( options [ :width ] * printer_dpi ) . to_s + '^FN' + variable_fields_count . to_s + '^FS' ) end
569	def home_position ( x , y ) x = 0 unless numeric? ( x ) y = 0 unless numeric? ( y ) label_data . push ( '^LH' + x . to_s + ',' + y . to_s ) end
570	def draw_border ( x , y , height , width ) return unless numeric? ( height ) && numeric? ( width ) x = 0 unless numeric? ( x ) y = 0 unless numeric? ( y ) label_data . push ( '^FO' + Integer ( x * printer_dpi ) . to_s + ',' + Integer ( y * printer_dpi ) . to_s + '^GB' + Integer ( height * printer_dpi ) . to_s + ',' + Integer ( width * printer_dpi ) . to_s + ',1^FS' ) end
571	def reset_barcode_fields_to_default label_data . push ( '^BY' + Integer ( self . barcode_default_module_width ) . to_s + ',' + Float ( self . barcode_default_width_ratio ) . to_s + ',' + Integer ( self . barcode_default_height ) . to_s ) end
572	def draw_bar_code_39 ( bar_code_string , x , y , height ) return unless label_height > 0 && label_width > 0 pdf . bounding_box [ x , Integer ( label_width ) - y - ( height * pdf_dpi ) ] , width : ( height * pdf_dpi ) do barcode = Barby :: Code39 . new ( bar_code_string ) barcode . annotate_pdf ( pdf , height : ( height * pdf_dpi ) ) end end
573	def add_field ( value ) return if value . nil? return if value . strip . empty? self . variable_fields_count += 1 label_data . push ( '^FN' + variable_fields_count . to_s + '^FD' + value + '^FS' ) end
574	def build_slug if localized? begin orig_locale = I18n . locale all_locales . each do | target_locale | I18n . locale = target_locale apply_slug end ensure I18n . locale = orig_locale end else apply_slug end true end
575	def new_with_slugs? if localized? new_record? && _slugs_translations . fetch ( I18n . locale . to_s , [ ] ) . any? else new_record? && _slugs . present? end end
576	def persisted_with_slug_changes? if localized? changes = _slugs_change return ( persisted? && false ) if changes . nil? original = changes . first . try ( :fetch , I18n . locale . to_s , nil ) compare = changes . last . try ( :fetch , I18n . locale . to_s , nil ) persisted? && original != compare else persisted? && _slugs_changed? end end
577	def distance_of_time_in_words ( from_time , to_time = Time . now ) from_time = from_time . to_time if from_time . respond_to? ( :to_time ) to_time = to_time . to_time if to_time . respond_to? ( :to_time ) seconds = ( to_time - from_time ) . round distance_in_days = ( seconds / ( 60 * 60 * 24 ) ) . round seconds = seconds % ( 60 * 60 * 24 ) distance_in_hours = ( seconds / ( 60 * 60 ) ) . round seconds = seconds % ( 60 * 60 ) distance_in_minutes = ( seconds / 60 ) . round seconds = seconds % 60 distance_in_seconds = seconds s = '' s << "#{distance_in_days} days," if distance_in_days > 0 s << "#{distance_in_hours} hours, " if distance_in_hours > 0 s << "#{distance_in_minutes} minutes, " if distance_in_minutes > 0 s << "#{distance_in_seconds} seconds" s end
578	def approximate_distance_of_time_in_words ( from_time , to_time = Time . now , include_seconds = true ) from_time = from_time . to_time if from_time . respond_to? ( :to_time ) to_time = to_time . to_time if to_time . respond_to? ( :to_time ) distance_in_minutes = ( ( ( to_time - from_time ) . abs ) / 60 ) . round distance_in_seconds = ( ( to_time - from_time ) . abs ) . round case distance_in_minutes when 0 .. 1 return ( distance_in_minutes == 0 ) ? 'less than a minute' : '1 minute' unless include_seconds case distance_in_seconds when 0 .. 4 then 'less than 5 seconds' when 5 .. 9 then 'less than 10 seconds' when 10 .. 19 then 'less than 20 seconds' when 20 .. 39 then 'half a minute' when 40 .. 59 then 'less than a minute' else '1 minute' end when 2 .. 44 then "#{distance_in_minutes} minutes" when 45 .. 89 then 'about 1 hour' when 90 .. 1439 then "about #{(distance_in_minutes.to_f / 60.0).round} hours" when 1440 .. 2879 then '1 day' when 2880 .. 43199 then "#{(distance_in_minutes / 1440).round} days" when 43200 .. 86399 then 'about 1 month' when 86400 .. 525959 then "#{(distance_in_minutes / 43200).round} months" when 525960 .. 1051919 then 'about 1 year' else "over #{(distance_in_minutes / 525960).round} years" end end
579	def track_error ( control , msg ) errors << msg control . error_handlers . each do | handler | handler . call ( msg ) end end
580	def process_batch ( batch ) batch = ETL :: Batch :: Batch . resolve ( batch , self ) say "Processing batch #{batch.file}" ETL :: Engine . batch = ETL :: Execution :: Batch . create! ( :batch_file => batch . file , :status => 'executing' ) batch . execute ETL :: Engine . batch . completed_at = Time . now ETL :: Engine . batch . status = ( errors . length > 0 ? 'completed with errors' : 'completed' ) ETL :: Engine . batch . save! end
581	def pre_process ( control ) Engine . logger . debug "Pre-processing #{control.file}" control . pre_processors . each do | processor | processor . process end Engine . logger . debug "Pre-processing complete" end
582	def post_process ( control ) say_on_own_line "Executing post processes" Engine . logger . debug "Post-processing #{control.file}" control . post_processors . each do | processor | processor . process end Engine . logger . debug "Post-processing complete" say "Post-processing complete" end
583	def execute_dependencies ( control ) Engine . logger . debug "Executing dependencies" control . dependencies . flatten . each do | dependency | case dependency when Symbol f = dependency . to_s + '.ctl' Engine . logger . debug "Executing dependency: #{f}" say "Executing dependency: #{f}" process ( f ) when String Engine . logger . debug "Executing dependency: #{f}" say "Executing dependency: #{f}" process ( dependency ) else raise "Invalid dependency type: #{dependency.class}" end end end
584	def execute_screens ( control , timing = :before_post_process ) screens = case timing when :after_post_process control . after_post_process_screens else control . screens end [ :fatal , :error , :warn ] . each do | type | screens [ type ] . each do | block | begin block . call rescue => e case type when :fatal raise FatalScreenError , e when :error raise ScreenError , e when :warn say "Screen warning: #{e}" end end end end end
585	def redis_key * fields @redis_key_config = fields . flatten validate_redis_key remove_redis_autoincrement_key unless redis_user_field_config . include? ( :id ) || @redis_key_config . include? ( :id ) @redis_key_config . each do | field | validates field , :presence => :true if field != :id end end
586	def redis_key_normalize * metrics @redis_key_normalize_conf ||= [ ] metrics . each do | metric | raise ArgumentError , "Please provide valid normalization: #{VALID_NORMALIZATIONS.join(", ")}" unless VALID_NORMALIZATIONS . include? ( metric ) @redis_key_normalize_conf << metric end end
587	def redis_alias name , main_fields , name_of_field_for_order = nil , name_of_field_for_args = nil if name_of_field_for_order && name_of_field_for_args redis_field name_of_field_for_order , :array , [ ] unless redis_fields_config . has_key? ( name_of_field_for_order ) redis_field name_of_field_for_args , :hash , { } unless redis_fields_config . has_key? ( name_of_field_for_args ) end @redis_alias_config ||= { } @redis_alias_config [ name ] = { main_fields : main_fields , order_field : name_of_field_for_order , args_field : name_of_field_for_args , } create_class_alias_method ( name ) end
588	def store_redis_keys args = to_arg redis_old_keys [ :key ] = self . class . generate_key ( args ) redis_old_keys [ :aliases ] = [ ] redis_alias_config . each do | alias_name , fields | redis_old_keys [ :aliases ] << redis_alias_key ( alias_name ) if valid_alias_key? alias_name end end
589	def conf fields = { } redis_fields_config . each do | key , type | fields [ key ] = TYPE_TRANSLATIONS [ type ] if TYPE_TRANSLATIONS . has_key? ( type ) end { fields : fields , required : @required_config . sort , redis_key : redis_key_config , redis_aliases : redis_alias_config . inject ( { } ) { | o , ( k , v ) | o [ k ] = v [ :main_fields ] ; o } , reject_nil_values : ! redis_save_fields_with_nil_conf , } end
590	def exists? args = { } RedisModelExtension :: Database . redis . exists ( self . name . constantize . generate_key ( args ) ) end
591	def alias_exists? alias_name , args = { } RedisModelExtension :: Database . redis . exists ( self . name . constantize . generate_alias_key ( alias_name , args ) ) end
592	def valid_item_for_redis_key? args , key ( args . has_key? ( key ) && ! args [ key ] . nil? ) || redis_fields_config [ key ] == :autoincrement end
593	def validate_redis_key valid_fields = redis_fields_config . select { | k , v | v != :array && v != :hash } . keys bad_fields = redis_key_config - valid_fields raise ArgumentError , "Sorry, but you cannot use as redis key [nonexisting | array | hash] fields: [#{bad_fields.join(",")}], availible are: #{valid_fields.join(", ")}" unless bad_fields . size == 0 end
594	def to_arg redis_fields_config . inject ( { } ) do | args , ( key , type ) | args [ key ] = self . send ( key ) args end end
595	def find_by_alias ( alias_name , args = { } ) raise ArgumentError , "Unknown dynamic alias: '#{alias_name}', use: #{redis_alias_config.keys.join(", ")} " unless redis_alias_config . has_key? ( alias_name . to_sym ) args = HashWithIndifferentAccess . new ( args ) out = [ ] klass = self . name . constantize search_key = klass . generate_alias_key ( alias_name , args ) unless search_key =~ / \* / out = klass . get_by_alias ( alias_name , args ) if klass . alias_exists? ( alias_name , args ) else RedisModelExtension :: Database . redis . keys ( search_key ) . each do | key | out << klass . get_by_alias_key ( key ) end end out . flatten end
596	def get ( args = { } ) args = { id : args } if args . is_a? ( Integer ) args = HashWithIndifferentAccess . new ( args ) klass = self . name . constantize if klass . valid_key? ( args ) && klass . exists? ( args ) klass . new_by_key ( klass . generate_key ( args ) ) else nil end end
597	def get_by_alias_key ( alias_key ) klass = self . name . constantize if RedisModelExtension :: Database . redis . exists ( alias_key ) out = [ ] RedisModelExtension :: Database . redis . smembers ( alias_key ) . each do | key | item = klass . new_by_key ( key ) out << item if item end return out end nil end
598	def new_by_key ( key ) args = RedisModelExtension :: Database . redis . hgetall ( key ) return nil unless args && args . any? args . symbolize_keys! new_instance = new ( args ) new_instance . store_keys return new_instance end
599	def value_to_redis name , value if redis_fields_config . has_key? ( name ) value_transform value , redis_fields_config [ name ] else value end end
600	def value_transform value , type return nil if value . nil? || value . to_s . size == 0 case type when :integer then value . to_i when :autoincrement then value . to_i when :string then value . to_s when :float then value . to_f when :bool then value . to_s when :symbol then value . to_s when :marshal then Marshal . dump ( value ) when :array then Yajl :: Encoder . encode ( value ) when :hash then Yajl :: Encoder . encode ( value ) when :time then Time . parse ( value . to_s ) . strftime ( "%Y.%m.%d %H:%M:%S" ) when :date then Date . parse ( value . to_s ) . strftime ( "%Y-%m-%d" ) else value end end
601	def value_parse value , type return nil if value . nil? || value . to_s . size == 0 case type when :integer then value . to_i when :autoincrement then value . to_i when :string then value . to_s when :float then value . to_f when :bool then value . to_s . to_bool when :symbol then value . to_s . to_sym when :marshal then value . is_a? ( String ) ? Marshal . load ( value ) : value when :array then value . is_a? ( String ) ? Yajl :: Parser . parse ( value ) : value when :hash then value . is_a? ( String ) ? Hashr . new ( Yajl :: Parser . parse ( value ) ) : Hashr . new ( value ) when :time then value . is_a? ( String ) ? Time . parse ( value ) : value when :date then value . is_a? ( String ) ? Date . parse ( value ) : value else value end end
602	def update args args . each do | key , value | method = "#{key}=" . to_sym if self . respond_to? method self . send ( method , value ) end end end
603	def destroy_aliases! if redis_old_keys [ :aliases ] . size > 0 redis_old_keys [ :aliases ] . each do | alias_key | RedisModelExtension :: Database . redis . srem alias_key , redis_old_keys [ :key ] RedisModelExtension :: Database . redis . del ( alias_key ) if RedisModelExtension :: Database . redis . scard ( alias_key ) . to_i == 0 end end end
604	def add ( username , token ) Firim :: AccountManager . new ( user : username , token : token ) . add_to_keychain end
605	def get_nsqds ( lookupd , topic = nil ) uri_scheme = 'http://' unless lookupd . match ( %r( ) ) uri = URI . parse ( "#{uri_scheme}#{lookupd}" ) uri . query = "ts=#{Time.now.to_i}" if topic uri . path = '/lookup' uri . query += "&topic=#{URI.escape(topic)}" else uri . path = '/nodes' end begin body = Net :: HTTP . get ( uri ) data = JSON . parse ( body ) producers = data [ 'producers' ] || ( data [ 'data' ] && data [ 'data' ] [ 'producers' ] ) if producers producers . map do | producer | "#{producer['broadcast_address']}:#{producer['tcp_port']}" end else [ ] end rescue Exception => e error "Error during discovery for #{lookupd}: #{e}" nil end end
606	def discover_repeatedly ( opts = { } ) @discovery_thread = Thread . new do @discovery = Discovery . new ( opts [ :nsqlookupds ] ) loop do begin nsqds = nsqds_from_lookupd ( opts [ :topic ] ) drop_and_add_connections ( nsqds ) rescue DiscoveryException warn 'Could not connect to any nsqlookupd instances in discovery loop' end sleep opts [ :interval ] end end @discovery_thread . abort_on_exception = true end
607	def with_retries ( & block ) base_sleep_seconds = 0.5 max_sleep_seconds = 300 attempts = 0 begin attempts += 1 return block . call ( attempts ) rescue Errno :: ECONNREFUSED , Errno :: ECONNRESET , Errno :: EHOSTUNREACH , Errno :: ENETDOWN , Errno :: ENETUNREACH , Errno :: ETIMEDOUT , Timeout :: Error => ex raise ex if attempts >= 100 sleep_seconds = [ base_sleep_seconds * ( 2 ** ( attempts - 1 ) ) , max_sleep_seconds ] . min sleep_seconds = sleep_seconds * ( 0.5 * ( 1 + rand ( ) ) ) sleep_seconds = [ base_sleep_seconds , sleep_seconds ] . max warn "Failed to connect: #{ex}. Retrying in #{sleep_seconds.round(1)} seconds." snooze ( sleep_seconds ) retry end end
608	def show ( ind = '' ) count = 0 self . to_a . each { | i | puts "#{ind}#{i.name} [#{count}]: #{i.to_s.sub(/^(.{30})(.*?)(.{30})$/, '\1...\3')}" if i . kind_of? ( X12 :: Segment ) && i . nodes [ 0 ] i . find_field ( i . nodes [ 0 ] . name ) end i . nodes . each { | j | case when j . kind_of? ( X12 :: Base ) then j . show ( ind + ' ' ) when j . kind_of? ( X12 :: Field ) then puts "#{ind+' '}#{j.name} -> '#{j.to_s}'" end } count += 1 } end
609	def do_repeats ( s ) if self . repeats . end > 1 possible_repeat = self . dup p_s = possible_repeat . parse ( s ) if p_s s = p_s self . next_repeat = possible_repeat end end s end
610	def find ( e ) case self when X12 :: Loop res = nodes . find { | i | e == i . name } return res if res nodes . each { | i | res = i . find ( e ) if i . kind_of? ( X12 :: Loop ) return res unless res . nil? or EMPTY == res } when X12 :: Segment return find_field ( e ) . to_s end return EMPTY end
611	def method_missing ( meth , * args , & block ) str = meth . id2name str = str [ 1 .. str . length ] if str =~ / \d / if str =~ / / str . chop! case self when X12 :: Segment res = find_field ( str ) throw Exception . new ( "No field '#{str}' in segment '#{self.name}'" ) if EMPTY == res res . content = args [ 0 ] . to_s else throw Exception . new ( "Illegal assignment to #{meth} of #{self.class}" ) end else res = find ( str ) yield res if block_given? res end end
612	def parse ( str ) s = str m = regexp . match ( s ) return nil unless m s = m . post_match self . parsed_str = m [ 0 ] s = do_repeats ( s ) return s end
613	def render self . to_a . inject ( '' ) { | repeat_str , i | if i . repeats . begin < 1 and ! i . has_content? repeat_str else repeat_str += i . name + i . nodes . reverse . inject ( '' ) { | nodes_str , j | field = j . render ( j . required or nodes_str != '' or field != '' ) ? field_separator + field + nodes_str : nodes_str } + segment_separator end } end
614	def regexp unless @regexp if self . nodes . find { | i | i . type =~ / / } re_str = self . nodes . inject ( "^#{name}#{Regexp.escape(field_separator)}" ) { | s , i | field_re = i . simple_regexp ( field_separator , segment_separator ) + Regexp . escape ( field_separator ) + '?' field_re = "(#{field_re})?" unless i . required s + field_re } + Regexp . escape ( segment_separator ) @regexp = Regexp . new ( re_str ) else @regexp = Regexp . new ( "^#{name}#{Regexp.escape(field_separator)}[^#{Regexp.escape(segment_separator)}]*#{Regexp.escape(segment_separator)}" ) end end @regexp end
615	def find_field ( str ) field_num = nil self . nodes . each_index { | i | field_num = i if str == self . nodes [ i ] . name } return EMPTY if field_num . nil? unless @fields @fields = self . to_s . chop . split ( Regexp . new ( Regexp . escape ( field_separator ) ) ) self . nodes . each_index { | i | self . nodes [ i ] . content = @fields [ i + 1 ] } end return self . nodes [ field_num ] end
616	def parse ( loop_name , str ) loop = @x12_definition [ X12 :: Loop ] [ loop_name ] throw Exception . new ( "Cannot find a definition for loop #{loop_name}" ) unless loop loop = loop . dup loop . parse ( str ) return loop end
617	def factory ( loop_name ) loop = @x12_definition [ X12 :: Loop ] [ loop_name ] throw Exception . new ( "Cannot find a definition for loop #{loop_name}" ) unless loop loop = loop . dup return loop end
618	def process_loop ( loop ) loop . nodes . each { | i | case i when X12 :: Loop then process_loop ( i ) when X12 :: Segment then process_segment ( i ) unless i . nodes . size > 0 else return end } end
619	def process_segment ( segment ) unless @x12_definition [ X12 :: Segment ] && @x12_definition [ X12 :: Segment ] [ segment . name ] initialize ( segment . name + '.xml' ) segment_definition = @x12_definition [ X12 :: Segment ] [ segment . name ] throw Exception . new ( "Cannot find a definition for segment #{segment.name}" ) unless segment_definition else segment_definition = @x12_definition [ X12 :: Segment ] [ segment . name ] end segment_definition . nodes . each_index { | i | segment . nodes [ i ] = segment_definition . nodes [ i ] table = segment . nodes [ i ] . validation if table unless @x12_definition [ X12 :: Table ] && @x12_definition [ X12 :: Table ] [ table ] initialize ( table + '.xml' ) throw Exception . new ( "Cannot find a definition for table #{table}" ) unless @x12_definition [ X12 :: Table ] && @x12_definition [ X12 :: Table ] [ table ] end end } end
620	def render if self . has_content? self . to_a . inject ( '' ) { | loop_str , i | loop_str += i . nodes . inject ( '' ) { | nodes_str , j | nodes_str += j . render } } else '' end end
621	def calculate_sortable_values response_fieldable . input_fields . each do | response_field | if ( x = response_value ( response_field ) ) . present? get_responses [ "#{response_field.id}_sortable_value" ] = response_field . sortable_value ( x ) end end mark_responses_as_changed! end
622	def normalize_responses return if form . blank? form . response_fields . each do | response_field | if ( x = self . response_value ( response_field ) ) response_field . normalize_response ( x , get_responses ) end end mark_responses_as_changed! end
623	def audit_responses form . response_fields . each do | response_field | response_field . audit_response ( self . response_value ( response_field ) , get_responses ) end mark_responses_as_changed! end
624	def tag! ( tag , * args , & block ) text , attributes = nil , { } args . each do | arg | case arg when :: Hash attributes . merge! ( arg ) when :: String text ||= '' text << arg end end @stack << [ tag , attributes , text ? [ text ] : [ ] ] if block _process ( & block ) end if @stack . length > 1 node = @stack . pop @stack . last [ 2 ] << node NodeBuilder . new ( node , self ) else NodeBuilder . new ( @stack . last , self ) end end
625	def << ( * args ) args . each do | arg | if arg . respond_to? ( :to_hexp ) @stack . last [ 2 ] << arg self else :: Kernel . raise :: Hexp :: FormatError , "Inserting literal HTML into a builder with << is deliberately not supported by Hexp" end end end
626	def rewrite ( css_selector = nil , & block ) return Rewriter . new ( self , block ) if css_selector . nil? CssSelection . new ( self , css_selector ) . rewrite ( & block ) end
627	def select ( css_selector = nil , & block ) if css_selector CssSelection . new ( self , css_selector ) . each ( & block ) else Selection . new ( self , block ) end end
628	def add_configuration ( config_hash ) config_hash . each do | key , val | instance_eval { instance_variable_set ( "@#{key}" , val ) } self . class . instance_eval { attr_accessor key } end end
629	def pid_exists ( pid ) return false if pid < 0 return true if pid == 0 :: Process . kill ( 0 , pid ) return true rescue Errno :: ESRCH return false rescue Errno :: EPERM return true rescue RangeError return false end
630	def wait_pid ( pid , timeout = nil ) def check_timeout ( delay , stop_at , timeout ) if timeout raise Timeout :: Error . new ( "when waiting for (pid=#{pid})" ) if Time . now >= stop_at end sleep ( delay ) delay * 2 < 0.04 ? delay * 2 : 0.04 end if timeout waitcall = proc { :: Process . wait ( pid , :: Process :: WNOHANG ) } stop_at = Time . now + timeout else waitcall = proc { :: Process . wait ( pid ) } end delay = 0.0001 loop do begin retpid = waitcall . call ( ) rescue Errno :: EINTR delay = check_timeout ( delay , stop_at , timeout ) next rescue Errno :: ECHILD loop do return nil unless pid_exists ( pid ) delay = check_timeout ( delay , stop_at , timeout ) end end unless retpid delay = check_timeout ( delay , stop_at , timeout ) next end if $? . signaled? return $? . termsig elsif $? . exited? return $? . exitstatus else raise RuntimeError . new ( "unknown process exit status" ) end end end
631	def upload_module_changes ( parent_sha1 , sha1s ) remote_path = fetch_module tmp_git_path = clone_or_fetch_repository ( remote_path , module_tmp_git_path ( @remote_path ) ) RIM :: git_session ( tmp_git_path ) do | dest | local_branch = nil remote_branch = nil infos = nil if @module_info . subdir dest_path = File . join ( [ tmp_git_path ] + @module_info . subdir . split ( "/" ) ) else dest_path = tmp_git_path end RIM :: git_session ( @ws_root ) do | src | infos = get_branches_and_revision_infos ( src , dest , parent_sha1 , sha1s ) if infos . branches . size == 1 remote_branch = infos . branches [ 0 ] if dest . has_remote_branch? ( remote_branch ) infos . rev_infos . each do | rev_info | local_branch = create_update_branch ( dest , infos . parent_sha1 , rev_info . src_sha1 ) if ! local_branch copy_revision_files ( src , rev_info . src_sha1 , dest_path , rev_info . rim_info . ignores ) commit_changes ( dest , local_branch , rev_info . src_sha1 , rev_info . message ) end else raise RimException . new ( "The target revision '#{@module_info.target_revision}' of module #{@module_info.local_path} is not a branch. No push can be performed." ) end elsif infos . branches . size > 1 raise RimException . new ( "There are commits for module #{@module_info.local_path} on multiple target revisions (#{infos.branches.join(", ")})." ) end end if local_branch && dest . rev_sha1 ( local_branch ) != infos . parent_sha1 push_branch = @review && @module_info . remote_branch_format && ! @module_info . remote_branch_format . empty? ? @module_info . remote_branch_format % remote_branch : remote_branch dest . execute ( "git push #{@remote_url} #{local_branch}:#{push_branch}" ) dest . execute ( "git checkout --detach #{local_branch}" ) dest . execute ( "git branch -D #{local_branch}" ) @logger . info ( "Commited changes for module #{@module_info.local_path} to remote branch #{push_branch}." ) else @logger . info ( "No changes to module #{@module_info.local_path}." ) end end end
632	def get_branches_and_revision_infos ( src_session , dest_session , parent_sha1 , sha1s ) infos = [ ] branches = [ ] dest_parent_sha1 = nil ( sha1s . size ( ) - 1 ) . step ( 0 , - 1 ) do | i | info = get_revision_info ( src_session , dest_session , sha1s [ i ] ) if ! info . dest_sha1 && info . rim_info . target_revision infos . unshift ( info ) branches . push ( info . rim_info . target_revision ) if ! branches . include? ( info . rim_info . target_revision ) else dest_parent_sha1 = info . dest_sha1 break end end dest_parent_sha1 = get_riminfo_for_revision ( src_session , parent_sha1 ) . revision_sha1 if ! dest_parent_sha1 dest_parent_sha1 = infos . first . rim_info . revision_sha1 if ! dest_parent_sha1 && ! infos . empty? return Struct . new ( :branches , :parent_sha1 , :rev_infos ) . new ( branches , dest_parent_sha1 , infos ) end
633	def get_revision_info ( src_session , dest_session , src_sha1 ) module_status = StatusBuilder . new . rev_module_status ( src_session , src_sha1 , @module_info . local_path ) rim_info = get_riminfo_for_revision ( src_session , src_sha1 ) dest_sha1 = dest_session . rev_sha1 ( "rim-#{src_sha1}" ) msg = src_session . execute ( "git show -s --format=%B #{src_sha1}" ) RevisionInfo . new ( module_status && module_status . dirty? ? dest_sha1 : rim_info . revision_sha1 , src_sha1 , rim_info , msg ) end
634	def commit_changes ( session , branch , sha1 , msg ) if session . status . lines . any? session . execute ( "git add --all" ) msg_file = Tempfile . new ( 'message' ) begin msg_file << msg msg_file . close session . execute ( "git commit -F #{msg_file.path}" ) ensure msg_file . close ( true ) end session . execute ( "git tag rim-#{sha1} refs/heads/#{branch}" ) end end
635	def get_riminfo_for_revision ( session , sha1 ) session . execute ( "git show #{sha1}:#{File.join(@module_info.local_path, RimInfo::InfoFileName)}" ) do | out , e | return RimInfo . from_s ( ! e ? out : "" ) end end
636	def copy_revision_files ( src_session , src_sha1 , dest_dir , ignores ) Dir . mktmpdir do | tmp_dir | tmp_dir = Dir . glob ( tmp_dir ) [ 0 ] src_session . execute ( "git archive --format tar #{src_sha1} #{@module_info.local_path} | tar -C #{tmp_dir} -xf -" ) tmp_module_dir = File . join ( tmp_dir , @module_info . local_path ) files = FileHelper . find_matching_files ( tmp_module_dir , false , "/**/*" , File :: FNM_DOTMATCH ) files . delete ( "." ) files . delete ( ".." ) files . delete ( RimInfo :: InfoFileName ) files -= FileHelper . find_matching_files ( tmp_module_dir , false , ignores ) prepare_empty_folder ( dest_dir , ".git/**/*" ) files . each do | f | src_path = File . join ( tmp_module_dir , f ) if File . file? ( src_path ) path = File . join ( dest_dir , f ) FileUtils . mkdir_p ( File . dirname ( path ) ) FileUtils . cp ( src_path , path ) end end end end
637	def rev_history_status ( git_session , rev , options = { } ) stop_rev = options [ :stop_rev ] relevant_revs = { } if stop_rev git_session . execute ( "git rev-list #{rev} \"^#{stop_rev}\"" ) . split ( "\n" ) . each do | r | relevant_revs [ r ] = true end elsif options [ :gerrit ] git_session . execute ( "git rev-list #{rev} --not --all --" ) . split ( "\n" ) . each do | r | relevant_revs [ r ] = true end else git_session . all_reachable_non_remote_revs ( rev ) . each do | r | relevant_revs [ r ] = true end end rev = git_session . rev_sha1 ( rev ) build_rev_history_status ( git_session , rev , relevant_revs , { } , :fast => options [ :fast ] ) end
638	def rev_status ( git_session , rev ) mod_dirs = module_dirs ( git_session , rev ) mod_stats = [ ] git_session . within_exported_rev ( rev , mod_dirs ) do | d | mod_dirs . each do | rel_path | mod_stats << build_module_status ( d , d + "/" + rel_path ) end end stat = RevStatus . new ( mod_stats ) stat . git_rev = git_session . rev_sha1 ( rev ) stat end
639	def rev_module_status ( git_session , rev , local_path ) mod_stat = nil if git_session . execute ( "git ls-tree -r --name-only #{rev}" ) . split ( "\n" ) . include? ( File . join ( local_path , ".riminfo" ) ) git_session . within_exported_rev ( rev , [ local_path ] ) do | d | mod_stat = build_module_status ( d , File . join ( d , local_path ) ) end end mod_stat end
640	def fs_status ( dir ) RevStatus . new ( fs_rim_dirs ( dir ) . collect { | d | build_module_status ( dir , d ) } ) end
641	def build_rev_history_status ( gs , rev , relevant_revs , status_cache = { } , options = { } ) return status_cache [ rev ] if status_cache [ rev ] stat = nil if relevant_revs [ rev ] parent_revs = gs . parent_revs ( rev ) if parent_revs . size > 0 parent_stats = parent_revs . collect do | p | build_rev_history_status ( gs , p , relevant_revs , status_cache , options ) end base_stat = parent_stats . first changed_files = gs . changed_files ( rev , parent_revs . first ) module_dirs = base_stat . modules . collect { | m | m . dir } changed_files . each do | f | if File . basename ( f . path ) == RimInfo :: InfoFileName if f . kind == :added module_dirs << File . dirname ( f . path ) elsif f . kind == :deleted module_dirs . delete ( File . dirname ( f . path ) ) end end end check_dirs = module_dirs . select { | d | changed_files . any? { | f | f . path . start_with? ( d ) } } module_stats = [ ] if check_dirs . size > 0 gs . within_exported_rev ( rev , check_dirs ) do | ws | check_dirs . each do | d | module_stats << build_module_status ( ws , File . join ( ws , d ) ) end end end ( module_dirs - check_dirs ) . each do | d | base_mod = base_stat . modules . find { | m | m . dir == d } module_stats << RevStatus :: ModuleStatus . new ( d , base_mod . rim_info , base_mod . dirty? ) end stat = RevStatus . new ( module_stats ) stat . git_rev = gs . rev_sha1 ( rev ) stat . parents . concat ( parent_stats ) else if options [ :fast ] stat = rev_status_fast ( gs , rev ) else stat = rev_status ( gs , rev ) end end else if options [ :fast ] stat = rev_status_fast ( gs , rev ) else stat = rev_status ( gs , rev ) end end status_cache [ rev ] = stat end
642	def rev_status_fast ( git_session , rev ) mod_dirs = module_dirs ( git_session , rev ) mod_stats = [ ] git_session . within_exported_rev ( rev , mod_dirs . collect { | d | "#{d}/#{RimInfo::InfoFileName}" } ) do | temp_dir | mod_dirs . each do | rel_path | mod_stats << RevStatus :: ModuleStatus . new ( rel_path , RimInfo . from_dir ( "#{temp_dir}/#{rel_path}" ) , false ) end end stat = RevStatus . new ( mod_stats ) stat . git_rev = git_session . rev_sha1 ( rev ) stat end
643	def sync ( message = nil , rebase = nil , split = true ) RIM :: git_session ( @ws_root ) do | s | branch = s . current_branch || '' rim_branch = "rim/" + branch branch_sha1 = nil changed_modules = nil if branch . empty? raise RimException . new ( "Not on a git branch." ) elsif branch . start_with? ( "rim/" ) raise RimException . new ( "The current git branch '#{branch}' is a rim integration branch. Please switch to a non rim branch to proceed." ) else branch = "refs/heads/#{branch}" branch_sha1 = s . rev_sha1 ( rim_branch ) remote_rev = get_latest_remote_revision ( s , branch ) rev = get_latest_clean_path_revision ( s , branch , remote_rev ) if ! s . has_branch? ( rim_branch ) || has_ancestor? ( s , branch , s . rev_sha1 ( rim_branch ) ) || ! has_ancestor? ( s , rim_branch , remote_rev ) s . execute ( "git branch -f #{rim_branch} #{rev}" ) branch_sha1 = s . rev_sha1 ( rim_branch ) end remote_url = "file://" + @ws_root @logger . debug ( "Folder for temporary git repositories: #{@rim_path}" ) tmpdir = clone_or_fetch_repository ( remote_url , module_tmp_git_path ( ".ws" ) , "Cloning workspace git..." ) RIM :: git_session ( tmpdir ) do | tmp_session | tmp_session . execute ( "git reset --hard" ) tmp_session . execute ( "git clean -xdf" ) tmp_session . execute ( "git checkout -B #{rim_branch} -f remotes/origin/#{rim_branch}" ) changed_modules = sync_modules ( tmp_session , message ) if ! split tmp_session . execute ( "git reset --soft #{branch_sha1}" ) commit ( tmp_session , message ? message : get_commit_message ( changed_modules ) ) if tmp_session . uncommited_changes? end tmp_session . execute ( "git push #{remote_url} #{rim_branch}:#{rim_branch}" ) end end if ! changed_modules . empty? if rebase s . execute ( "git rebase #{rim_branch}" ) @logger . info ( "Changes have been commited to branch #{rim_branch} and workspace has been rebased successfully." ) else @logger . info ( "Changes have been commited to branch #{rim_branch}. Rebase to apply changes to workspace." ) end else @logger . info ( "No changes." ) end end end
644	def sync_modules ( session , message ) module_helpers = [ ] @module_infos . each do | module_info | module_helpers . push ( SyncModuleHelper . new ( session . execute_dir , @ws_root , module_info , @logger ) ) end changed_modules = [ ] module_helpers . each do | m | @logger . info ( "Synchronizing #{m.module_info.local_path}..." ) if m . sync ( message ) changed_modules << m . module_info end end changed_modules end
645	def has_ancestor? ( session , rev , ancestor ) rev = session . rev_sha1 ( rev ) return rev == ancestor || session . is_ancestor? ( ancestor , rev ) end
646	def get_parent ( session , rev ) parents = session . parent_revs ( rev ) ! parents . empty? ? parents . first : nil end
647	def get_commit_message ( changed_modules ) StringIO . open do | s | s . puts "rim sync." s . puts changed_modules . each do | m | s . puts m . local_path end s . string end end
648	def pmmap_ext ( data ) pmmap_ext = [ 'addr' , 'perms' , 'path' , 'rss' , 'size' , 'pss' , 'shared_clean' , 'shared_dirty' , 'private_clean' , 'private_dirty' , 'referenced' , 'anonymous' , 'swap' ] os_list = [ ] data . each do | datum | os = OpenStruct . new pmmap_ext . each_index { | i | os [ pmmap_ext [ i ] ] = datum [ i ] } os_list . push ( os ) end os_list end
649	def pmmap_grouped ( data ) pmmap_grouped = [ 'rss' , 'size' , 'pss' , 'shared_clean' , 'shared_dirty' , 'private_clean' , 'private_dirty' , 'referenced' , 'anonymous' , 'swap' ] os_list = [ ] data . each do | k , v | os = OpenStruct . new os . path = k pmmap_grouped . each_index { | i | os [ pmmap_grouped [ i ] ] = v [ i ] } os_list . push ( os ) end os_list end
650	def calc_checksum ( mi , dir ) if check_required_attributes ( mi ) sha1 = Digest :: SHA1 . new files = FileHelper . find_matching_files ( dir , false , "/**/*" , File :: FNM_DOTMATCH ) files . delete ( "." ) files . delete ( ".." ) files . delete ( RimInfo :: InfoFileName ) files -= FileHelper . find_matching_files ( dir , false , mi . ignores ) files . sort! files . each do | fn | update_file ( sha1 , dir , fn ) end ChecksumAttributes . each do | a | sha1 . update ( mi . send ( a ) ) end sha1 . hexdigest else nil end end
651	def current_branch out = execute "git branch" out . split ( "\n" ) . each do | l | if ! l . include? ( '(' ) && ( l =~ / \* \s \S / ) return $1 end end nil end
652	def has_remote_branch? ( branch ) out = execute ( "git ls-remote --heads" ) out . split ( "\n" ) . each do | l | return true if l . split ( / \s / ) [ 1 ] == "refs/heads/#{branch}" end false end
653	def rev_sha1 ( rev ) sha1 = nil execute "git rev-list -n 1 #{rev} --" do | out , e | sha1 = out . strip if ! e end sha1 end
654	def rev_infos ( rev , desired ) info = { } desired . each_pair do | key , value | execute "git log -1 --format=#{value} #{rev} --" do | out , e | info [ key ] = out . strip if ! e end end info end
655	def remote_branch_revs out = execute "git show-ref" out . split ( "\n" ) . collect { | l | if l =~ / \/ \/ / l . split [ 0 ] else nil end } . compact end
656	def export_rev ( rev , dir , paths = [ ] ) paths = paths . dup loop do path_args = "" while ! paths . empty? && path_args . size < 6000 path_args << " " path_args << paths . shift end execute "git archive --format tar #{rev} #{path_args} | tar -C #{dir} -xf -" break if paths . empty? end end
657	def within_exported_rev ( rev , paths = [ ] ) Dir . mktmpdir ( "rim" ) do | d | d = Dir . glob ( d ) [ 0 ] c = File . join ( d , "content" ) FileUtils . mkdir ( c ) export_rev ( rev , c , paths ) yield c FileUtils . rm_rf ( c ) retries = 600 while File . exist? ( c ) && retries > 0 sleep ( 0.1 ) FileUtils . rm_rf ( c ) retries -= 1 end if File . exist? ( c ) @logger . warn "could not delete temp dir: #{c}" end end end
658	def upload RIM :: git_session ( @ws_root ) do | s | branch = s . current_branch if branch . nil? raise RimException . new ( "Not on a git branch." ) elsif ! branch . start_with? ( "rim/" ) begin sha1 = s . rev_sha1 ( branch ) @logger . info ( "Uploading modules..." ) upload_modules ( get_upload_revisions ( s , sha1 ) ) ensure s . execute ( "git checkout -B #{branch}" ) end else raise RimException . new ( "The current git branch '#{branch}' is a rim integration branch. Please switch to a non rim branch to proceed." ) end end end
659	def upload_modules ( info ) each_module_parallel ( "uploading" , @module_helpers ) do | m | m . upload ( info . parent , info . sha1s ) end end
660	def get_upload_revisions ( session , rev ) non_remote_revs = { } session . all_reachable_non_remote_revs ( rev ) . each do | r | non_remote_revs [ r ] = true end revisions = [ ] rev = session . rev_sha1 ( rev ) while rev && non_remote_revs [ rev ] revisions . push ( rev ) parents = session . parent_revs ( rev ) rev = parents . size > 0 ? parents . first : nil end Struct . new ( :parent , :sha1s ) . new ( rev , revisions . reverse! ) end
661	def fetch_module FileUtils . mkdir_p git_path RIM :: git_session ( git_path ) do | s | if ! File . exist? ( git_path + "/config" ) s . execute ( "git clone --mirror #{@remote_url} #{git_path}" ) do | out , e | raise RimException . new ( "Remote repository '#{@remote_url}' of module '#{@module_info.local_path}' not found." ) if e end else s . execute ( "git remote update" ) end end git_path end
662	def assign ( attribute , value ) unless value == :skip || attribute == :class if item . respond_to? ( "#{attribute}=" ) item . send ( "#{attribute}=" , value ) elsif item . is_a? ( Hash ) item [ attribute ] = value end end end
663	def debug ( * args ) item = build ( * args ) invalid_item = Array ( item ) . find ( & :invalid? ) if invalid_item if invalid_item . errors . respond_to? ( :messages ) errors = invalid_item . errors . messages else errors = invalid_item . errors end raise "Oops, the #{invalid_item.class} created by the Factory has the following errors: #{errors}" end item end
664	def crank_it ( what , overrides ) if what . to_s =~ / / what = $1 overrides = overrides . merge ( :_return_attributes => true ) end item = "TBD" new_job ( what , overrides ) do item = self . send ( what ) item = apply_traits ( what , item ) end item end
665	def method_missing ( method , * args , & block ) if view_context . respond_to? ( method , true ) view_context . send ( method , * args , & block ) else super end end
666	def present ( object , presenter : nil , ** args ) if object . respond_to? ( :to_ary ) object . map { | item | present ( item , presenter : presenter , ** args ) } else presenter ||= presenter_klass ( object ) wrapper = presenter . new ( object , view_context , ** args ) block_given? ? yield ( wrapper ) : wrapper end end
667	def push ( gem , method , options = { } ) push_command = PUSH_METHODS [ method . to_s ] or raise "Unknown Gem push method #{method.inspect}." push_command += [ gem ] push_command += [ "--as" , options [ :as ] ] if options [ :as ] @cli_facade . execute ( * push_command ) end
668	def interpolate interpolant case @opts [ :type ] when :linear for_each ( interpolant ) { | x | linear_interpolation ( x ) } when :cubic cubic_spline_interpolation interpolant else raise ArgumentError , "1 D interpolation of type #{@opts[:type]} not supported" end end
669	def lines_selector_for ( target , attributes ) if ( klass = @selectors . find { | s | s . handles? target , attributes } ) klass . new ( target , attributes , logger : logger ) end end
670	def run client_ip = @ip key = "request_count:#{client_ip}" result = { status : Constants :: SUCCESS_STATUS , message : Constants :: OK_MESSAGE } requests_count = @storage . get ( key ) unless requests_count @storage . set ( key , 0 ) @storage . expire ( key , @limits [ "time_period_seconds" ] ) end if requests_count . to_i >= @limits [ "max_requests_count" ] result [ :status ] = Constants :: EXPIRED_STATUS result [ :message ] = message ( period ( key ) ) else @storage . incr ( key ) end result end
671	def date_select ( method , options = { } ) options [ :include_blank ] ||= false options [ :start_year ] ||= 1801 options [ :end_year ] ||= Time . now . year options [ :label_for ] = "#{object_name}_#{method}_1i" build_shell ( method , options ) { super } end
672	def label ( method , text = nil , options = { } ) colon = false if options [ :colon ] . nil? options [ :for ] = options [ :label_for ] required = options [ :required ] options . delete :colon options . delete :label_for options . delete :required text = @template . send ( :h , text . blank? ? method . to_s . humanize : text . to_s ) text << ':' . html_safe if colon text << @template . content_tag ( :span , "*" , :class => "required" ) if required super end
673	def read ( raw , predecessors = nil ) if raw . respond_to? ( :read ) raw = raw . read ( self . sizeof ( ) ) end if raw . size < self . sizeof ( ) raise ( ReadError , "Expected #{self.sizeof} bytes, but only got #{raw.size} bytes" ) end vals = if @unpack_cb @unpack_cb . call ( raw , predecessors ) else raw . unpack ( self . format ) end return ( self . claim_value ( vals , predecessors ) ) end
674	def pack_value ( val , obj = nil ) begin if @pack_cb @pack_cb . call ( val , obj ) else varray = val . is_a? ( Array ) ? val : [ val ] varray . pack ( self . format ) end rescue => e raise ( PackError , "Error packing #{val.inspect} as type #{self.name.inspect} -- #{e.class} -> #{e}" ) end end
675	def method_missing ( sym , * args , & block ) return Lebowski :: RSpec :: Matchers :: Be . new ( sym , * args ) if sym . to_s =~ / / return Lebowski :: RSpec :: Matchers :: Has . new ( sym , * args ) if sym . to_s =~ / / return Lebowski :: RSpec :: Operators :: That . new ( sym , * args ) if sym . to_s =~ / / super end
676	def static_files source = File . dirname ( ENGINE . assets_path ) asset_files . map do | file | dir = File . dirname ( file ) file_name = File . basename ( file ) Jekyll :: StaticFile . new @site , source , dir , file_name end end
677	def asset_files asset_files = [ ] Find . find ( ENGINE . assets_path ) . each do | path | next if File . directory? ( path ) next if path . include? ( ENGINE . stylesheets_sass_path ) asset_files << path . sub ( ENGINE . assets_path , 'assets' ) end asset_files end
678	def daily ( time = Date . today , page_size = 50 ) time = time . strftime ( "%Y-%m-%d" ) unless time . is_a? ( String ) report_id = run_report_request ( 'DailyActivityReport' , { 'report_date' => time } , page_size ) meta_data = get_meta_data_request ( report_id ) data = [ ] meta_data [ "numberOfPages" ] . to_i . times do | page_num | data += get_data_request ( report_id , page_num + 1 ) end data end
679	def run_report_request ( report_name , report_params = { } , page_size = 50 ) response = request 'runReportRequest' do | xml | xml . reportName report_name report_params . each do | name , value | xml . reportParam do xml . paramName name xml . paramValue value end end xml . pageSize page_size end response . elements [ "runReportResponse/reportId" ] . get_text . value end
680	def generate_unique ( length = 32 , & blk ) unique = generate_random ( length ) unique = generate_random ( length ) until blk . call ( unique ) unique end
681	def draw_paperback ( qr_code : , sixword_lines : , sixword_bytes : , labels : , passphrase_sha : nil , passphrase_len : nil , sixword_font_size : nil , base64_content : nil , base64_bytes : nil ) unless qr_code . is_a? ( RQRCode :: QRCode ) raise ArgumentError . new ( 'qr_code must be RQRCode::QRCode' ) end pdf . font ( 'Times-Roman' ) debug_draw_axes draw_header ( labels : labels , passphrase_sha : passphrase_sha , passphrase_len : passphrase_len ) add_newline draw_qr_code ( qr_modules : qr_code . modules ) pdf . stroke_color '000000' pdf . fill_color '000000' pdf . start_new_page draw_sixword ( lines : sixword_lines , sixword_bytes : sixword_bytes , font_size : sixword_font_size , is_encrypted : passphrase_len ) if base64_content draw_base64 ( b64_content : base64_content , b64_bytes : base64_bytes , is_encrypted : passphrase_len ) end pdf . number_pages ( '<page> of <total>' , align : :right , at : [ pdf . bounds . right - 100 , - 2 ] ) end
682	def produce_report ( * args ) ` ` unless xcov_available? unless xcov_available? puts "xcov is not available on this machine" return end require "xcov" require "fastlane_core" config = FastlaneCore :: Configuration . create ( Xcov :: Options . available_options , convert_options ( args . first ) ) Xcov . config = config Xcov . ignore_handler = Xcov :: IgnoreHandler . new manager = Xcov :: Manager . new ( config ) report_json = manager . parse_xccoverage process_report ( Xcov :: Report . map ( report_json ) ) end
683	def output_report ( report ) report_markdown = report . markdown_value markdown ( report_markdown ) threshold = Xcov . config [ :minimum_coverage_percentage ] . to_i if ! threshold . nil? && ( report . coverage * 100 ) < threshold fail ( "Code coverage under minimum of #{threshold}%" ) end end
684	def process_report ( report ) file_names = @dangerfile . git . modified_files . map { | file | File . basename ( file ) } file_names += @dangerfile . git . added_files . map { | file | File . basename ( file ) } report . targets . each do | target | target . files = target . files . select { | file | file_names . include? ( file . name ) } end report end
685	def update ( data ) data . each_byte do | b | b = revert_byte ( b ) if REVERSE_DATA @crc = ( ( @table [ ( ( @crc >> 8 ) ^ b ) & 0xff ] ^ ( @crc << 8 ) ) & 0xffff ) end return self end
686	def request ( http_verb , url , options = { } ) full_url = url + hash_to_params ( options ) handle ( access_token . request ( http_verb , full_url ) ) end
687	def string ( opts = { } ) length , any , value = ( opts [ :length ] || 8 ) , opts [ :any ] , opts [ :value ] if value string = value . to_s Proc . new { string } elsif any Proc . new { self . any ( any ) } else Proc . new { Array . new ( length ) { @chars [ rand ( @chars . size - 1 ) ] } . join } end end
688	def convert tag , val return val unless val . kind_of? ( String ) case tag when 'partofset' , 'track' return val end case val when REGEXP_TIMESTAMP year , month , day , hour , minute = $~ . captures [ 0 , 5 ] . map { | cap | cap . to_i } if month == 0 || day == 0 return nil end second = $6 . to_f zone = $7 zone = '+00:00' if zone == 'Z' Time . new ( year , month , day , hour , minute , second , zone ) when REGEXP_RATIONAL return val if $2 . to_i == 0 Rational ( $1 , $2 ) else val end end
689	def to_h @values . inject ( Hash . new ) do | h , a | tag , val = a h [ Values . tag_map [ tag ] ] = convert ( Values . unify_tag ( tag ) , val ) h end end
690	def n ( msg , title = '' , image = nil ) Compat :: UI . notify ( msg , :title => title , :image => image ) end
691	def eager ( command ) require 'pty' begin PTY . spawn command do | r , w , pid | begin $stdout . puts r . each { | line | print line } rescue Errno :: EIO end end rescue PTY :: ChildExited $stdout . puts "The child process exited!" end end
692	def wrap_list ( list , width ) list . map do | text | wrap_text ( text , width ) end . flatten end
693	def save return if @data . empty? output = { } output [ :data ] = @data output [ :generated_at ] = Time . now . to_s output [ :started_at ] = @started_at output [ :format_version ] = '1.0' output [ :rails_version ] = Rails . version output [ :rails_path ] = Rails . root . to_s FileUtils . mkdir_p ( @config . output_path ) filename = "sql_tracker-#{Process.pid}-#{Time.now.to_i}.json" File . open ( File . join ( @config . output_path , filename ) , 'w' ) do | f | f . write JSON . dump ( output ) end end
694	def delete ( key ) ref = @references . delete ( key ) if ref keys_to_id = @references_to_keys_map [ ref . referenced_object_id ] if keys_to_id keys_to_id . delete ( key ) @references_to_keys_map . delete ( ref . referenced_object_id ) if keys_to_id . empty? end ref . object else nil end end
695	def merge ( other_hash , & block ) to_h . merge ( other_hash , & block ) . reduce ( self . class . new ) do | map , pair | map [ pair . first ] = pair . last map end end
696	def add_strong_reference ( obj ) @@lock . synchronize do @@strong_references . last [ obj ] = true unless @@gc_flag_set @@gc_flag_set = true ObjectSpace . define_finalizer ( Object . new , @@finalizer ) end end end
697	def object @ref . __getobj__ rescue => e if ( defined? ( RefError ) && e . is_a? ( RefError ) ) || ( defined? ( :: WeakRef :: RefError ) && e . is_a? ( :: WeakRef :: RefError ) ) nil else raise e end end
698	def delete ( key ) @lock . synchronize do rkey = ref_key ( key ) if rkey @references_to_keys_map . delete ( rkey ) @values . delete ( rkey ) else nil end end end
699	def monitor ( reference ) obj = reference . object if obj @lock . synchronize do @references [ reference . referenced_object_id ] = reference end ObjectSpace . define_finalizer ( obj , @finalizer ) else push ( reference ) end end
700	def client ( options = { } ) @client ||= :: OAuth2 :: Client . new ( client_id , client_secret , { :site => options . fetch ( :site ) { Nimbu . site } , :authorize_url => 'login/oauth/authorize' , :token_url => 'login/oauth/access_token' , :ssl => { :verify => false } } ) end
701	def default_middleware ( options = { } ) Proc . new do | builder | unless options [ :with_attachments ] builder . use Nimbu :: Request :: Json end builder . use Faraday :: Request :: Multipart builder . use Faraday :: Request :: UrlEncoded builder . use Nimbu :: Request :: OAuth2 , oauth_token if oauth_token? builder . use Nimbu :: Request :: BasicAuth , authentication if basic_authed? builder . use Nimbu :: Request :: UserAgent builder . use Nimbu :: Request :: SiteHeader , subdomain builder . use Nimbu :: Request :: ContentLocale , content_locale builder . use Faraday :: Response :: Logger if ENV [ 'DEBUG' ] builder . use Nimbu :: Response :: RaiseError unless options [ :raw ] builder . use Nimbu :: Response :: Mashify builder . use Nimbu :: Response :: Json end builder . adapter adapter end end
702	def load unless valid_params? raise SmartAdapters :: Exceptions :: InvalidRequestParamsException end unless valid_format? raise SmartAdapters :: Exceptions :: InvalidRequestFormatException end adapter_finder . new ( request_manager ) end
703	def error { error : { model : self . object [ "model" ] , model_human : self . object [ "model_human" ] , attribute : self . object [ "attribute" ] , attribute_human : self . object [ "attribute_human" ] , field : self . object [ "field" ] , message : self . object [ "message" ] , full_message : "#{self.object["full_message"]}" } } end
704	def setup ( options = { } ) options . each do | k , v | self . set ( k , v , true ) end options = Nimbu . options . merge ( options ) self . current_options = options Configuration . keys . each do | key | send ( "#{key}=" , options [ key ] ) end process_basic_auth ( options [ :basic_auth ] ) end
705	def arguments ( args = ( not_set = true ) , options = { } , & block ) if not_set @arguments else @arguments = Arguments . new ( self , options ) . parse ( * args , & block ) end end
706	def reset! self . client_id = DEFAULT_CLIENT_ID self . client_secret = DEFAULT_CLIENT_SECRET self . oauth_token = DEFAULT_OAUTH_TOKEN self . endpoint = DEFAULT_ENDPOINT self . site = DEFAULT_SITE self . ssl = DEFAULT_SSL self . user_agent = DEFAULT_USER_AGENT self . connection_options = DEFAULT_CONNECTION_OPTIONS self . mime_type = DEFAULT_MIME_TYPE self . login = DEFAULT_LOGIN self . password = DEFAULT_PASSWORD self . basic_auth = DEFAULT_BASIC_AUTH self . auto_pagination = DEFAULT_AUTO_PAGINATION self . content_locale = DEFAULT_CONTENT_LOCALE self . adapter = DEFAULT_ADAPTER self . subdomain = DEFAULT_SUBDOMAIN self end
707	def invalid_fts_filters ( filters ) filters . select { | filter | category , name , value = filter . values_at ( 'category' , 'name' , 'value' ) category == 'fts' && name == 'search' && value . to_s . length <= 1 } . map { | invalid_fts_filter | error = <<-MSG . gsub ( / \s / , '' ) . strip MSG invalid_fts_filter . merge ( :error => error ) } end
708	def extended ( object ) each_param do | param | object . params [ param . name ] = param . to_instance ( object ) end end
709	def params = ( values ) values . each do | name , value | if has_param? ( name ) get_param ( name ) . value = case value when Parameters :: ClassParam , Parameters :: InstanceParam value . value else value end end end end
710	def parameter ( name , options = { } ) name = name . to_sym meta_def ( name ) do get_param ( name ) . value end meta_def ( "#{name}=" ) do | value | get_param ( name ) . value = value end meta_def ( "#{name}?" ) do ! ! get_param ( name ) . value end define_method ( name ) do get_param ( name ) . value end define_method ( "#{name}=" ) do | value | get_param ( name ) . value = value end define_method ( "#{name}?" ) do ! ! get_param ( name ) . value end new_param = Parameters :: ClassParam . new ( name , options [ :type ] , options [ :description ] , options [ :default ] ) params [ name ] = new_param return new_param end
711	def has_param? ( name ) name = name . to_sym ancestors . each do | ancestor | if ancestor . included_modules . include? ( Parameters ) return true if ancestor . params . has_key? ( name ) end end return false end
712	def get_param ( name ) name = name . to_sym ancestors . each do | ancestor | if ancestor . included_modules . include? ( Parameters ) if ancestor . params . has_key? ( name ) return ancestor . params [ name ] end end end raise ( Parameters :: ParamNotFound , "parameter #{name.to_s.dump} was not found in class #{self}" ) end
713	def set_param ( name , value ) name = name . to_sym ancestors . each do | ancestor | if ancestor . included_modules . include? ( Parameters ) if ancestor . params . has_key? ( name ) return ancestor . params [ name ] . set ( value ) end end end raise ( Parameters :: ParamNotFound , "parameter #{name.to_s.dump} was not found in class #{self}" ) end
714	def each_param ( & block ) ancestors . reverse_each do | ancestor | if ancestor . included_modules . include? ( Parameters ) ancestor . params . each_value ( & block ) end end return self end
715	def link ( * things ) unless none? raise "Illegal state for link: #{state}" end things . each do | thing | case thing when DataMapper :: Adapters :: AbstractAdapter @adapters [ thing ] = :none when DataMapper :: Repository link ( thing . adapter ) when DataMapper :: Model link ( * thing . repositories ) when DataMapper :: Resource link ( thing . model ) when Array link ( * thing ) else raise "Unknown argument to #{self.class}#link: #{thing.inspect} (#{thing.class})" end end if block_given? commit { | * block_args | yield ( * block_args ) } else self end end
716	def commit if block_given? unless none? raise "Illegal state for commit with block: #{state}" end begin self . begin rval = within { | * block_args | yield ( * block_args ) } rescue Exception => exception if begin? rollback end raise exception ensure unless exception if begin? commit end return rval end end else unless begin? raise "Illegal state for commit without block: #{state}" end each_adapter ( :commit_adapter , [ :log_fatal_transaction_breakage ] ) each_adapter ( :close_adapter , [ :log_fatal_transaction_breakage ] ) self . state = :commit end end
717	def within unless block_given? raise 'No block provided' end unless begin? raise "Illegal state for within: #{state}" end adapters = @adapters adapters . each_key do | adapter | adapter . push_transaction ( self ) end begin yield self ensure adapters . each_key do | adapter | adapter . pop_transaction end end end
718	def next_message read_header if @state == :header read_payload_length if @state == :payload_length read_mask_key if @state == :mask read_payload if @state == :payload @state == :complete ? process_frame! : nil rescue StandardError => ex if @on_error @on_error . call ( ex . message ) else raise ex end end
719	def reporter ( query , options = { } , & block ) @report ||= QueryReport :: Report . new ( params , view_context , options ) @report . query = query @report . instance_eval & block render_report ( options ) unless options [ :skip_rendering ] @report end
720	def infer_type ( field_name ) case field_name when :email , :time_zone field_name when %r{ \b \b } :password else type_mappings = { text : :textarea } db_type = @object . column_for_attribute ( field_name ) . type case db_type when :text :textarea when :decimal , :integer , :float :numeric else db_type end end end
721	def validate_instance_node ( instance_node ) validations_passed = ! self . node_validations . collect { | node_validation | node_validation . validate_instance_node ( instance_node , self ) } . include? ( false ) parent_validations_passed = ! self . survey . node_maps . select { | i | i . node == self } . collect { | node_map | if node_map . parent node_map . parent . node . validate_parent_instance_node ( instance_node , self ) else true end } . include? ( false ) validations_passed && parent_validations_passed end
722	def instance_node_path_to_root? ( instance_node ) instance_nodes = instance_node . instance . instance_nodes . select { | i | i . node == self } if self . class . ancestors . include? ( :: ActiveRecordSurvey :: Node :: Answer ) && ( instance_nodes . length === 0 ) return false end if self . class . ancestors . include? ( :: ActiveRecordSurvey :: Node :: Question ) && ( self . answers . length === 0 ) && ( instance_nodes . length === 0 ) return false end paths = self . survey . node_maps . select { | i | i . node == self } . collect { | node_map | if node_map . parent node_map . parent . node . instance_node_path_to_root? ( instance_node ) else true end } paths . include? ( true ) end
723	def build_link ( to_node ) if ! to_node . class . ancestors . include? ( :: ActiveRecordSurvey :: Node :: Question ) raise ArgumentError . new "to_node must inherit from ::ActiveRecordSurvey::Node::Question" end if self . survey . nil? raise ArgumentError . new "A survey is required before calling #build_link" end from_node_maps = self . survey . node_maps . select { | i | i . node == self && ! i . marked_for_destruction? } if from_node_maps . select { | i | i . children . length > 0 } . length > 0 raise RuntimeError . new "This node has already been linked" end to_node_maps = self . survey . node_maps . select { | i | i . node == to_node && ! i . marked_for_destruction? } if to_node_maps . first . nil? to_node_maps << self . survey . node_maps . build ( :survey => self . survey , :node => to_node ) end to_node_map = to_node_maps . first to_node_map . survey = self . survey to_node_maps = to_node_maps . select { | i | i . parent . nil? } while to_node_maps . length < from_node_maps . length do to_node_maps . push ( to_node_map . recursive_clone ) end from_node_maps . each_with_index { | from_node_map , index | from_node_map . children << to_node_maps [ index ] } from_node_maps . each { | node_map | if node_map . has_infinite_loop? raise RuntimeError . new "Infinite loop detected" end } end
724	def before_destroy_rebuild_node_map self . survey . node_maps . select { | i | i . node == self } . each { | node_map | node_map . children . each { | child | node_map . parent . children << child } } true end
725	def validate_instance_node ( instance_node ) super && ( instance_node . value . to_s . empty? || ! instance_node . value . to_s . match ( / \d \. \d / ) . nil? ) end
726	def is_answered_for_instance? ( instance ) if instance_node = self . instance_node_for_instance ( instance ) ! instance_node . value . to_s . empty? && instance_node . value . to_i >= 0 else false end end
727	def is_answered_for_instance? ( instance ) if instance_node = self . instance_node_for_instance ( instance ) instance_node . value . to_s . strip . length > 0 else false end end
728	def recursive_clone node_map = self . survey . node_maps . build ( :survey => self . survey , :node => self . node ) self . survey . node_maps . select { | i | i . parent == self && ! i . marked_for_destruction? } . each { | child_node | child_node . survey = self . survey node_map . children << child_node . recursive_clone } node_map end
729	def ancestors_until_node_not_ancestor_of ( klass ) if ! self . parent || ! self . node . class . ancestors . include? ( klass ) return [ ] end [ self ] + self . parent . ancestors_until_node_not_ancestor_of ( klass ) end
730	def children_until_node_not_ancestor_of ( klass ) if ! self . node . class . ancestors . include? ( klass ) return [ ] end [ self ] + self . children . collect { | i | i . children_until_node_not_ancestor_of ( klass ) } end
731	def has_infinite_loop? ( path = [ ] ) self . survey . node_maps . select { | i | i . parent == self && ! i . marked_for_destruction? } . each { | i | if path . include? ( self . node ) || i . has_infinite_loop? ( path . clone . push ( self . node ) ) return true end } path . include? ( self . node ) end
732	def validate_instance_node ( instance_node , answer_node = nil ) is_valid = ( ! instance_node . value . to_s . empty? && instance_node . value . to_f >= self . value . to_f ) instance_node . errors [ :base ] << { :nodes => { answer_node . id => [ "MINIMUM_VALUE" ] } } if ! is_valid is_valid end
733	def validate_instance_node ( instance_node , question_node = nil ) if ! question_node . class . ancestors . include? ( :: ActiveRecordSurvey :: Node :: Question ) return false end instance = instance_node . instance total_answered = question_node . node_maps . collect { | question_node_map | question_node_map . children . collect { | i | i . children_until_node_not_ancestor_of ( :: ActiveRecordSurvey :: Node :: Answer ) } . flatten . collect { | i | i . node . is_answered_for_instance? ( instance ) } } . flatten . select { | i | i } . count is_valid = ( total_answered >= self . value . to_i ) instance_node . errors [ :base ] << { :nodes => { question_node . id => [ "MINIMUM_ANSWER" ] } } if ! is_valid is_valid end
734	def validate_node ( instance ) ! self . survey . node_maps . select { | i | i . node == self } . collect { | node_map | node_map . parent . node . validate_node ( instance ) } . include? ( false ) end
735	def question self . survey . node_maps . select { | i | i . node == self } . collect { | node_map | if node_map . parent && node_map . parent . node if node_map . parent . node . class . ancestors . include? ( :: ActiveRecordSurvey :: Node :: Answer ) node_map . parent . node . question else node_map . parent . node end else nil end } . first end
736	def next_question self . survey . node_maps . select { | i | i . node == self && ! i . marked_for_destruction? } . each { | answer_node_map | answer_node_map . children . each { | child | if ! child . node . nil? && ! child . marked_for_destruction? if child . node . class . ancestors . include? ( :: ActiveRecordSurvey :: Node :: Question ) return child . node elsif child . node . class . ancestors . include? ( :: ActiveRecordSurvey :: Node :: Answer ) return child . node . next_question end else return nil end } } return nil end
737	def remove_link return true if ( question = self . next_question ) . nil? count = 0 to_remove = [ ] self . survey . node_maps . each { | node_map | if node_map . node == question if count > 0 to_remove . concat ( node_map . self_and_descendants ) else node_map . parent = nil node_map . move_to_root unless node_map . new_record? end count = count + 1 end if node_map . node == self node_map . children = [ ] end } self . survey . node_maps . each { | node_map | if to_remove . include? ( node_map ) node_map . parent = nil node_map . mark_for_destruction end } end
738	def sibling_index node_maps = self . survey . node_maps if node_map = node_maps . select { | i | i . node == self } . first parent = node_map . parent children = node_maps . select { | i | i . parent && i . parent . node === parent . node } children . each_with_index { | nm , i | if nm == node_map return i end } end end
739	def move_up self . survey . node_maps . select { | i | i . node == self } . collect { | node_map | begin node_map . move_left rescue end } end
740	def move_down self . survey . node_maps . select { | i | i . node == self } . collect { | node_map | begin node_map . move_right rescue end } end
741	def validate_instance_node ( instance_node ) super && ( instance_node . value . to_s . empty? || ! instance_node . value . to_s . match ( / \d / ) . nil? ) && ( instance_node . value . to_s . empty? || instance_node . value . to_i >= 1 ) && instance_node . value . to_i <= self . max_rank end
742	def num_above count = 0 self . node_maps . each { | i | if i . parent . node . class . ancestors . include? ( self . class ) count = count + 1 + i . parent . node . num_above end } count end
743	def num_below count = 0 self . node_maps . each { | node_map | node_map . children . each { | child | if child . node . class . ancestors . include? ( self . class ) count = count + 1 + child . node . num_below end } } count end
744	def validate_instance_node ( instance_node , answer_node = nil ) is_valid = ( self . value . to_i >= instance_node . value . to_s . length . to_i ) instance_node . errors [ :base ] << { :nodes => { answer_node . id => [ "MAXIMUM_LENGTH" ] } } if ! is_valid is_valid end
745	def build_first_question ( question_node ) if ! question_node . class . ancestors . include? ( :: ActiveRecordSurvey :: Node :: Question ) raise ArgumentError . new "must inherit from ::ActiveRecordSurvey::Node::Question" end question_node_maps = self . node_maps . select { | i | i . node == question_node && ! i . marked_for_destruction? } if question_node_maps . length === 0 question_node_maps << self . node_maps . build ( :node => question_node , :survey => self ) end end
746	def edges self . node_maps . select { | i | ! i . marked_for_destruction? } . select { | i | i . node && i . parent } . collect { | i | { :source => i . parent . node . id , :target => i . node . id , } } . uniq end
747	def validate_parent_instance_node ( instance_node , child_node ) ! self . node_validations . collect { | node_validation | node_validation . validate_instance_node ( instance_node , self ) } . include? ( false ) end
748	def update_question_type ( klass ) if self . next_questions . length > 0 raise RuntimeError . new "No questions can follow when changing the question type" end nm = self . survey . node_maps answers = self . answers . collect { | answer | nm . select { | i | i . node == answer } } . flatten . uniq . collect { | answer_node_map | node = answer_node_map . node answer_node_map . send ( ( answer_node_map . new_record? ) ? :destroy : :mark_for_destruction ) node } . collect { | answer | answer . type = klass . to_s answer = answer . becomes ( klass ) answer . save if ! answer . new_record? answer } . uniq answers . each { | answer | answer . survey = self . survey self . build_answer ( answer ) } end
749	def remove_answer ( answer_node ) if self . survey . nil? raise ArgumentError . new "A survey must be passed if ActiveRecordSurvey::Node::Question is not yet added to a survey" end if ! answer_node . class . ancestors . include? ( :: ActiveRecordSurvey :: Node :: Answer ) raise ArgumentError . new "::ActiveRecordSurvey::Node::Answer not passed" end if ! self . answers . include? ( answer_node ) raise ArgumentError . new "Answer not linked to question" end answer_node . send ( :remove_answer , self ) end
750	def build_answer ( answer_node ) if self . survey . nil? raise ArgumentError . new "A survey must be passed if ActiveRecordSurvey::Node::Question is not yet added to a survey" end if ! self . answers . select { | answer | answer . class != answer_node . class } . empty? raise ArgumentError . new "Cannot mix answer types on question" end if answer_node . send ( :build_answer , self ) self . survey . node_maps . select { | i | i . node == answer_node && ! i . marked_for_destruction? } . each { | answer_node_map | self . survey . node_maps . select { | j | ! j . marked_for_destruction? && j . parent == answer_node_map . parent && j . node . class . ancestors . include? ( :: ActiveRecordSurvey :: Node :: Question ) } . each { | j | answer_node_map . survey = self . survey j . survey = self . survey answer_node_map . children << j } } true end end
751	def remove_link return true if ( questions = self . next_questions ) . length === 0 self . survey . node_maps . select { | i | i . node == self } . each { | node_map | self . survey . node_maps . select { | j | node_map . children . include? ( j ) } . each { | child | if child . node . class . ancestors . include? ( :: ActiveRecordSurvey :: Node :: Question ) child . parent = nil child . send ( ( child . new_record? ) ? :destroy : :mark_for_destruction ) end } } self . answers . collect { | i | i . remove_link } end
752	def before_destroy_rebuild_node_map self . survey . node_maps . select { | i | i . node == self } . each { | node_map | node_map . children . each { | child | if ! child . node . class . ancestors . include? ( :: ActiveRecordSurvey :: Node :: Answer ) node_map . parent . children << child end } } true end
753	def table_for ( collection , * args , & block ) block = Tabletastic . default_table_block unless block_given? klass = default_class_for ( collection ) options = args . extract_options! initialize_html_options ( options , klass ) result = capture { block . call ( TableBuilder . new ( collection , klass , self ) ) } content_tag ( :table , result , options [ :html ] ) end
754	def default_class_for ( collection ) if collection . respond_to? ( :klass ) collection . klass elsif ! collection . empty? collection . first . class end end
755	def events_for_targets ( * list ) found_events = Array ( list ) . flatten . compact . map { | s | events_for_target ( s ) } . flatten . compact found_events end
756	def writer @writer ||= begin writer_matching_existing_parser = supported_writers . find { | writer | writer . format == format } writer_matching_existing_parser || default_writer end end
757	def animate ( actor_or_actor_name , options , & block ) options [ :actor ] = actor ( actor_or_actor_name ) options [ :context ] = self animation_group = SceneAnimation . build options , & block enqueue animation_group end
758	def on_mouse_movement ( * args , & block ) options = ( args . last . is_a? ( Hash ) ? args . pop : { } ) @mouse_movement_actions << ( block || lambda { | instance | send ( options [ :do ] ) } ) end
759	def notification ( param , & block ) custom_notifications [ param . to_sym ] = custom_notifications [ param . to_sym ] + [ block ] end
760	def fire_events_for_held_buttons held_actions . each do | key , action | execute_block_for_target ( & action ) if window and window . button_down? ( key ) end end
761	def fire_events_for_notification ( event , sender ) notification_actions = custom_notifications [ event ] notification_actions . each do | action | _fire_event_for_notification ( event , sender , action ) end end
762	def _fire_event_for_notification ( event , sender , action ) if action . arity == 2 target . instance_exec ( sender , event , & action ) elsif action . arity == 1 target . instance_exec ( sender , & action ) else target . instance_eval ( & action ) end end
763	def add ( model ) all_models_for ( model ) . each do | model | models_hash [ model . to_s ] = model . to_s name_with_slashes = model . model_name models_hash [ name_with_slashes ] = model . to_s name_with_colons = name_with_slashes . gsub ( '/' , '::' ) models_hash [ name_with_colons ] = model . to_s end end
764	def after_initialize to . each do | attribute , final | start = actor . send ( attribute ) animations . push build_animation_step ( attribute , start , final ) end end
765	def fire_events_for_notification ( event , sender ) current_state . each { | cs | cs . fire_events_for_notification ( event , sender ) } end
766	def add_events_for_target ( target , events ) relay = EventRelay . new ( target , window ) events . each do | target_event | relay . send target_event . event , * target_event . buttons , & target_event . block end current_state . push relay end
767	def method_missing ( name , * params , & block ) options = params . find { | param | param . is_a? Hash } define_control ( name , options ) end
768	def start! @window = Window . new width , height , fullscreen? window . caption = name window . scene = Scenes . generate ( first_scene ) window . show end
769	def show rectangle . color = starting_color color = final_color animate :rectangle , to : { red : color . red , green : color . green , blue : color . blue , alpha : color . alpha } , interval : interval do transition_to next_scene end end
770	def data ( * args , & block ) options = args . extract_options! if block_given? yield self else @table_fields = args . empty? ? orm_fields : args . collect { | f | TableField . new ( f . to_sym ) } end action_cells ( options [ :actions ] , options [ :action_prefix ] ) [ "\n" , head , "\n" , body , "\n" ] . join ( "" ) . html_safe end
771	def cell ( * args , & proc ) options = args . extract_options! options . merge! ( :klass => klass ) args << options @table_fields << TableField . new ( * args , & proc ) return "" end
772	def action_cells ( actions , prefix = nil ) return if actions . blank? actions = [ actions ] if ! actions . respond_to? ( :each ) actions = [ :show , :edit , :destroy ] if actions == [ :all ] actions . each do | action | action_link ( action . to_sym , prefix ) end end
773	def action_link ( action , prefix ) html_class = "actions #{action.to_s}_link" block = lambda do | resource | compound_resource = [ prefix , resource ] . compact compound_resource . flatten! if prefix . kind_of? ( Array ) case action when :show @template . link_to ( link_title ( action ) , compound_resource ) when :destroy @template . link_to ( link_title ( action ) , compound_resource , :method => :delete , :data => { :confirm => confirmation_message } ) else @template . link_to ( link_title ( action ) , @template . polymorphic_path ( compound_resource , :action => action ) ) end end self . cell ( action , :heading => "" , :cell_html => { :class => html_class } , & block ) end
774	def add ( scene ) all_scenes_for ( scene ) . each { | scene | scenes_hash [ scene . scene_name ] = scene . to_s } end
775	def apply_post_filters ( new_scene , options ) post_filters . inject ( new_scene ) { | scene , post | post . filter ( scene , options ) } end
776	def hash_with_missing_scene_default hash = HashWithIndifferentAccess . new do | hash , key | missing_scene = hash [ :missing_scene ] . constantize missing_scene . missing_scene = key . to_sym missing_scene end hash [ :missing_scene ] = "Metro::MissingScene" hash end
777	def all_scenes_for ( scenes ) Array ( scenes ) . map do | scene_class_name | scene = scene_class_name . constantize [ scene ] + all_scenes_for ( scene . scenes ) end . flatten . compact end
778	def actor ( actor_or_actor_name ) if actor_or_actor_name . is_a? String or actor_or_actor_name . is_a? Symbol send ( actor_or_actor_name ) else actor_or_actor_name end end
779	def notification ( event , sender = nil ) sender = sender || UnknownSender state . fire_events_for_notification ( event , sender ) end
780	def after ( ticks , & block ) tick = OnUpdateOperation . new interval : ticks , context : self tick . on_complete ( & block ) enqueue tick end
781	def add_actors_to_scene self . class . actors . each do | scene_actor | actor_instance = scene_actor . create actor_instance . scene = self send "#{scene_actor.name}=" , actor_instance end end
782	def register_animations! self . class . animations . each do | animation | animate animation . actor , animation . options , & animation . on_complete_block end end
783	def register_actor ( actor_factory ) registering_actor = actor ( actor_factory . name ) registering_actor . window = window registering_actor . show drawers . push ( registering_actor ) updaters . push ( registering_actor ) register_events_for_target ( registering_actor , registering_actor . class . events ) end
784	def base_update updaters . each { | updater | updater . update } update updaters . reject! { | updater | updater . update_completed? } end
785	def base_draw drawers . each { | drawer | drawer . draw } draw drawers . reject! { | drawer | drawer . draw_completed? } end
786	def transition_to ( scene_or_scene_name , options = { } ) new_scene = Scenes . generate ( scene_or_scene_name , options ) _prepare_transition ( new_scene ) window . scene = new_scene end
787	def _prepare_transition ( new_scene ) log . debug "Preparing to transition from scene #{self} to #{new_scene}" new_scene . class . actors . find_all { | actor_factory | actor_factory . load_from_previous_scene? } . each do | actor_factory | new_actor = new_scene . actor ( actor_factory . name ) current_actor = actor ( actor_factory . name ) new_actor . _load current_actor . _save end prepare_transition_to ( new_scene ) new_scene . prepare_transition_from ( self ) end
788	def to_hash drawn = drawers . find_all { | draw | draw . saveable_to_view } . inject ( { } ) do | hash , drawer | drawer_hash = drawer . to_hash hash . merge drawer_hash end drawn end
789	def create ( model_name , options = { } ) model_class = Metro :: Models . find ( model_name ) mc = model_class . new options mc . scene = scene mc . window = window mc end
790	def _load ( options = { } ) options . keys . each do | key | property_name = key . to_s . underscore . to_sym if respond_to? "#{property_name}=" send ( "#{property_name}=" , options . delete ( key ) ) else options [ property_name ] = options . delete ( key ) end end properties . merge! options end
791	def activities ( user_id , options = { } ) perform_request ( :get , '/v2/measure' , WithingsSDK :: Activity , 'activities' , { action : 'getactivity' , userid : user_id } . merge ( options ) ) end
792	def body_measurements ( user_id , options = { } ) perform_request ( :get , '/measure' , WithingsSDK :: MeasurementGroup , 'measuregrps' , { action : 'getmeas' , userid : user_id } . merge ( options ) ) end
793	def weight ( user_id , options = { } ) groups = body_measurements ( user_id , options ) groups . map do | group | group . measures . select { | m | m . is_a? WithingsSDK :: Measure :: Weight } . map do | m | WithingsSDK :: Measure :: Weight . new ( m . attrs . merge ( 'weighed_at' => group . date ) ) end end . flatten end
794	def sleep_series ( user_id , options = { } ) perform_request ( :get , '/v2/sleep' , WithingsSDK :: SleepSeries , 'series' , { action : 'get' , userid : user_id } . merge ( options ) ) end
795	def perform_request ( http_method , path , klass , key , options = { } ) if @consumer_key . nil? || @consumer_secret . nil? raise WithingsSDK :: Error :: ClientConfigurationError , "Missing consumer_key or consumer_secret" end options = WithingsSDK :: Utils . normalize_date_params ( options ) request = WithingsSDK :: HTTP :: Request . new ( @access_token , { 'User-Agent' => user_agent } ) response = request . send ( http_method , path , options ) if key . nil? klass . new ( response ) elsif response . has_key? key response [ key ] . collect do | element | klass . new ( element ) end else [ klass . new ( response ) ] end end
796	def set_magic_content_type ( override = false ) if override || file . content_type . blank? || generic_content_type? ( file . content_type ) new_content_type = :: FileMagic . new ( :: FileMagic :: MAGIC_MIME ) . file ( file . path ) . split ( ';' ) . first if file . respond_to? ( :content_type= ) file . content_type = new_content_type else file . instance_variable_set ( :@content_type , new_content_type ) end end rescue :: Exception => e raise CarrierWave :: ProcessingError , I18n . translate ( :" " , e : e , default : 'Failed to process file with FileMagic, Original Error: %{e}' ) end
797	def send_request ( channel_id , method , properties = { } ) Util . error_check :" " , @conn . send_method ( Integer ( channel_id ) , method . to_sym , properties ) nil end
798	def fetch_response ( channel_id , method , timeout : protocol_timeout ) methods = Array ( method ) . map ( & :to_sym ) timeout = Float ( timeout ) if timeout fetch_response_internal ( Integer ( channel_id ) , methods , timeout ) end
799	def on_event ( channel_id , method , callable = nil , & block ) handler = block || callable raise ArgumentError , "expected block or callable as the event handler" unless handler . respond_to? ( :call ) @event_handlers [ Integer ( channel_id ) ] [ method . to_sym ] = handler handler end
800	def download_source Log . debug { " Reading #{@source.url.green}" } zip = Tempfile . new ( 'gtfs' ) zip . binmode zip << open ( @source . url ) . read zip . rewind extract_to_tempfiles ( zip ) Log . debug { "Finished reading #{@source.url.green}" } rescue StandardException => e Log . error ( e . message ) raise e ensure zip . try ( :close ) end
801	def check_files @found_files = [ ] check_required_files check_optional_files @source . feed_definition . files . each do | req | @found_files << req if filenames . include? ( req . filename ) end end
802	def check_columns @found_files . each do | file | @temp_files [ file . filename ] . open do | data | FileReader . new ( data , file , validate : true ) end end end
803	def fetch_http_fallback_identifier ( head_request ) if head_request . key? ( 'last-modified' ) head_request [ 'last-modified' ] elsif head_request . key? ( 'content-length' ) head_request [ 'content-length' ] else Time . now . to_s end end
804	def parameter ( * names ) names . each do | name | define_singleton_method ( name ) do | * values | if ( value = values . first ) instance_variable_set ( "@#{name}" , value ) else instance_variable_get ( "@#{name}" ) end end end end
805	def find_columns ( validate ) @found_columns = [ ] prefix = "#{filename.yellow}:" required = @definition . required_columns unless required . empty? Log . info { "#{prefix} #{'required columns'.magenta}" } if validate missing = check_columns ( validate , prefix , required , :green , :red ) raise RequiredColumnsMissing , missing if validate && missing . present? end optional = @definition . optional_columns unless optional . empty? Log . info { "#{prefix} #{'optional columns'.cyan}" } if validate check_columns ( validate , prefix , optional , :cyan , :light_yellow ) end cols = @definition . columns . collect ( & :name ) headers = @csv_headers . select { | h | cols . include? ( h ) } @col_names ||= @found_columns . map ( & :name ) :: Hash [ * headers . inject ( [ ] ) { | list , c | list << c << @definition [ c ] } ] end
806	def map ( models , options ) models = models . values case options [ :platform ] . downcase when "objc" , "obj-c" , "objective-c" Nidyx :: ObjCMapper . map ( models , options ) end end
807	def generate ( path , name ) object = get_object ( path ) type = object [ TYPE_KEY ] if type == OBJECT_TYPE generate_object ( path , name ) elsif type == ARRAY_TYPE generate_top_level_array ( path ) elsif type . is_a? ( Array ) if type . include? ( OBJECT_TYPE ) raise UnsupportedSchemaError if type . include? ( ARRAY_TYPE ) generate_object ( path , name ) elsif type . include? ( ARRAY_TYPE ) generate_top_leve_array ( path ) else raise UnsupportedSchemaError ; end else raise UnsupportedSchemaError ; end end
808	def resolve_array_refs ( obj ) items = obj [ ITEMS_KEY ] case items when Array return resolve_items_array ( items ) when Hash any_of = items [ ANY_OF_KEY ] return resolve_items_array ( any_of ) if any_of . is_a? ( Array ) resolve_reference_string ( items [ REF_KEY ] ) return [ class_name_from_ref ( items [ REF_KEY ] ) ] . compact else return [ ] end end
809	def run ( schema_path , options ) schema = Nidyx :: Reader . read ( schema_path ) raw_models = Nidyx :: Parser . parse ( schema , options ) models = Nidyx :: Mapper . map ( raw_models , options ) Nidyx :: Output . write ( models , options [ :output_directory ] ) end
810	def read ( path ) schema = nil begin schema = JSON . parse ( IO . read ( path ) ) raise EmptySchemaError if empty_schema? ( schema ) rescue JSON :: JSONError => e puts "Encountered an error reading JSON from #{path}" puts e . message exit 1 rescue EmptySchemaError puts "Schema read from #{path} is empty" exit 1 rescue StandardError => e puts e . message exit 1 end schema end
811	def sign_package params params_str = create_sign_str params if params_str =~ / / key = Wxpay . app_api_key else key = Wxpay . api_key end Digest :: MD5 . hexdigest ( params_str + "&key=#{key}" ) . upcase end
812	def _each_resource_file ( config ) folder = config . folder folder . glob ( "**/*.yml" ) . select ( & to_filter_proc ( config . file_filter ) ) . each do | file | yield file , folder end end
813	def each_resource ( & bl ) return enum_for ( :each_resource ) unless block_given? each_resource_file do | file , folder | yield Webspicy . resource ( file . load , file , self ) end end
814	def to_real_url ( url , test_case = nil , & bl ) case config . host when Proc config . host . call ( url , test_case ) when String url =~ / / ? url : "#{config.host}#{url}" else return url if url =~ / / return yield ( url ) if block_given? raise "Unable to resolve `#{url}` : no host resolver provided\nSee `Configuration#host=" end end
815	def to_filter_proc ( filter ) case ff = filter when NilClass then -> ( f ) { true } when Proc then ff when Regexp then -> ( f ) { ff =~ f . to_s } else -> ( f ) { ff === f } end end
816	def folder ( folder = nil , & bl ) if folder . nil? @folder else folder = folder . is_a? ( String ) ? @folder / folder : Path ( folder ) raise "Folder `#{folder}` does not exists" unless folder . exists? && folder . directory? raise "Folder must be a descendant" unless folder . inside? ( @folder ) child = dup do | c | c . parent = self c . folder = folder end yield ( child ) if block_given? @children << child child end end
817	def data_system schema = self . folder / "schema.fio" if schema . file? Finitio :: DEFAULT_SYSTEM . parse ( schema . read ) elsif not ( self . parent . nil? ) self . parent . data_system else Finitio :: DEFAULT_SYSTEM end end
818	def run ( direction ) self . status . direction = direction self . status . reset! if self . class . rerunnable_safe? && completed? ( direction ) self . status . execution_time = time_it { self . send ( direction ) } self . status . last_succesful_completion = Time . now end
819	def failure = ( exception ) self . status . error = MigrationError . new ( :error_message => exception . message , :error_class => exception . class , :error_backtrace => exception . backtrace ) end
820	def is_runnable? ( direction ) self . class . rerunnable_safe? || ( direction == UP && status . current_status < status_complete ) || ( direction == DOWN && status . current_status > 0 ) end
821	def completed? ( direction ) return false if self . status . execution_time == 0 ( direction == UP && self . status . current_status == self . status_complete ) || ( direction == DOWN && self . status . current_status == 0 ) end
822	def step ( step_message = nil , step_status = 1 ) unless status . status_processed? ( status . direction , step_status ) self . status . message = step_message puts "\t #{step_message}" yield if block_given? self . status . current_status += status . direction_to_i end end
823	def time_it puts "Running #{self.class}[#{self.status.arguments}](#{self.status.direction})" start = Time . now yield if block_given? end_time = Time . now - start puts "Tasks #{self.class} executed in #{end_time} seconds. \n\n" end_time end
824	def super_print ( paragraphes , space_number = 50 , title = true ) puts format_paragraph ( space_number , title , * paragraphes ) end
825	def columns_hash colModel . inject ( { } ) { | h , col | h [ col . name ] = col ; h } end
826	def render @page_list . each do | page | page . render_to_file ( @config . dest_dir ) putc '.' ; $stdout . flush end @dir_list . each do | directory | src = File . join ( @config . pages_dir , directory ) dst = File . join ( @config . dest_dir , directory ) Render :: Asset . render_dir ( src , dst ) putc '.' ; $stdout . flush end if @config . short_paths render_short_path_symlinks end Render :: Apache . write_htaccess ( @config , @config . pages_dir , @config . dest_dir ) puts end
827	def add_page ( page ) @pages_by_name [ page . name ] ||= page @pages_by_path [ page . path . join ( '/' ) ] = page add_aliases ( I18n . default_locale , page , @pages_by_path ) page . locales . each do | locale | next if locale == I18n . default_locale add_aliases ( locale , page , @pages_by_locale_path [ locale ] ) end @page_list << page end
828	def add_aliases ( locale , page , path_hash ) page . aliases ( locale ) . each do | alias_path | alias_path_str = alias_path . join ( '/' ) if path_hash [ alias_path_str ] Amber . logger . warn "WARNING: page `#{page.path.join('/')}` has alias `#{alias_path_str}`, but this path is already taken by `#{path_hash[alias_path_str].path.join('/')}` (locale = #{locale})." else path_hash [ alias_path_str ] = page end end end
829	def parse_headers ( content_file ) headers = [ ] para1 = [ ] para2 = [ ] file_type = type_from_path ( content_file ) File . open ( content_file , :encoding => 'UTF-8' ) do | f | while ( line = f . gets ) =~ / \w / if line !~ / / line = '- ' + line end headers << line end while line = f . gets break unless line =~ / \s / end para1 << line while line = f . gets break if line =~ / \s / para1 << line end while line = f . gets break if line =~ / \s / para2 << line end end headers = headers . join para1 = para1 . join para2 = para2 . join excerpt = "" if file_type == :textile if para1 =~ / \. / excerpt = para2 else excerpt = para1 end elsif file_type == :markdown if para1 =~ / / || para1 =~ / \s /m excerpt = para2 else excerpt = para1 end end return [ headers , excerpt ] end
830	def variable_files if @simple_page directory = File . dirname ( @file_path ) regexp = SIMPLE_VAR_MATCH_RE . call ( @name ) else directory = @file_path regexp = VAR_FILE_MATCH_RE end hsh = { } Dir . foreach ( directory ) do | file | if file && match = regexp . match ( file ) locale = match [ 'locale' ] || I18n . default_locale hsh [ locale . to_sym ] = File . join ( directory , file ) end end hsh end
831	def last_menu_at_depth ( depth ) menu = self depth . times { menu = menu . children . last } menu end
832	def nameize ( str ) str = str . dup str . gsub! ( / \w / , '' ) str . gsub! ( / /u , '' ) str . strip! str . downcase! str . gsub! ( / \ /u , '-' ) CGI . escape ( str ) end
833	def strip_html_tags ( html ) Nokogiri :: HTML :: DocumentFragment . parse ( html , 'UTF-8' ) . children . collect { | child | child . inner_text } . join end
834	def populate_node ( node , options ) @children . each do | item | li = node . document . create_element ( "li" ) li . add_child ( li . document . create_element ( "a" , item . text , :href => "#{options[:href_base]}##{item.anchor}" ) ) if item . children . any? ul = li . document . create_element ( options [ :tag ] ) item . populate_node ( ul , options ) li . add_child ( ul ) end node . add_child ( li ) end end
835	def to_html ( options = { } ) html = [ ] tag = options [ :tag ] indent = options [ :indent ] || 0 str = options [ :indent_str ] || " " html << '%s<%s>' % [ ( str * indent ) , tag ] @children . each do | item | html << '%s<li>' % ( str * ( indent + 1 ) ) html << '%s<a href="%s#%s">%s</a>' % [ str * ( indent + 2 ) , options [ :href_base ] , item . anchor , item . text ] if item . children . any? html << item . to_html ( { :indent => indent + 2 , :indent_str => str , :tag => tag , :href_base => options [ :href_base ] } ) end html << '%s</li>' % ( str * ( indent + 1 ) ) end html << '%s</%s>' % [ ( str * indent ) , tag ] html . join ( "\n" ) end
836	def parent_for ( heading ) heading = heading [ 1 ] . to_i if heading . is_a? ( String ) if children . any? && children . last . level < heading children . last . parent_for ( heading ) else self end end
837	def type_id ( which ) which = which . to_s . humanize unless which . kind_of? ( String ) which . downcase! case which when 'alliance' then 16159 when 'character' then 1377 when 'corporation' then 2 when 'constellation' then 4 when 'region' then 3 when 'solar system' , 'solarsystem' then 5 when 'station' then 3867 else raise ArgumentError , "Unknown type: #{which}" end end
838	def link_to_info ( text , type_id , item_id = nil , * args ) function = "CCPEVE.showInfo(#{type_id.inspect}" function . concat ", #{item_id.inspect}" if item_id function . concat ")" link_to_function text , function , * args end
839	def link_to_route ( text , destination_id , source_id = nil , * args ) function = "CCPEVE.showRouteTo(#{destination_id.inspect}" function . concat ", #{source_id.inspect}" if source_id function . concat ")" link_to_function text , function , * args end
840	def link_to_trust_request ( text , trust_url = "http://#{request.host}/" , * args ) trust_url = url_for ( trust_url . merge ( :only_path => false ) ) if trust_url . kind_of? ( Hash ) link_to_function text , "CCPEVE.requestTrust(#{trust_url.inspect})" , * args end
841	def request_trust ( trust_url = "http://#{request.host}/" , * args ) trust_url = url_for ( trust_url . merge ( :only_path => false ) ) if trust_url . kind_of? ( Hash ) javascript_tag "CCPEVE.requestTrust(#{trust_url.inspect});" , * args end
842	def render_to_file ( dest_dir , options = { } ) render_content_files ( dest_dir , options ) render_assets ( dest_dir ) @props . locales . each do | locale | if aliases ( locale ) . any? link_page_aliases ( dest_dir , aliases ( locale ) , locale ) end end end
843	def symlink ( from_path , to_path ) to_path = realpath ( to_path ) target = from_path . relative_path_from ( to_path ) . to_s . sub ( / \. \. \/ / , '' ) if ! to_path . dirname . directory? Amber . logger . warn { "On page `#{@file_path}`, the parent directories for alias name `#{to_path}` don't exist. Skipping alias." } return end if to_path . exist? && to_path . symlink? File . unlink ( to_path ) end if ! to_path . exist? Amber . logger . debug { "Symlink #{to_path} => #{target}" } FileUtils . ln_s ( target , to_path ) end end
844	def render_content_files ( dest_dir , options ) view = Render :: View . new ( self , @config ) @config . locales . each do | file_locale | content_file = content_file ( file_locale ) next unless content_file dest = destination_file ( dest_dir , file_locale ) unless Dir . exist? ( File . dirname ( dest ) ) FileUtils . mkdir_p ( File . dirname ( dest ) ) end if options [ :force ] || ! File . exist? ( dest ) || File . mtime ( content_file ) > File . mtime ( dest ) File . open ( dest , 'w' ) do | f | layout = @props . layout || 'default' f . write view . render ( { page : self , layout : layout } , { locale : file_locale } ) end end end end
845	def friend name , friend_id , note = nil friend_wrapper ( api_name = name , api_container = @userid , api_note = note , api_type = "friend" ) end
846	def get_user_listing username , opts = { } opts [ :type ] = 'overview' if opts [ :type ] . nil? url = "/user/%s%s.json" % [ username , ( '/' + opts [ :type ] if opts [ :type ] != 'overview' ) ] opts . delete :type query = opts get ( url , query : query ) end
847	def comment text , id logged_in? post ( '/api/comment' , body : { text : text , thing_id : id , uh : @modhash , api_type : 'json' } ) end
848	def submit title , subreddit , opts = { } logged_in? post = { title : title , sr : subreddit , uh : @modhash , kind : ( opts [ :url ] ? "link" : "self" ) , api_type : 'json' } post . merge! opts post ( '/api/submit' , body : post ) end
849	def vote direction , id logged_in? post ( '/api/vote' , body : { id : id , dir : direction , uh : @modhash , api_type : 'json' } ) end
850	def correct? ( str ) str = str . is_a? ( String ) ? str : str . to_s str == ( @answer . is_a? ( String ) ? @answer : @answer . to_s ) end
851	def gotcha ( options = { } ) options [ :label_options ] ||= { } options [ :text_field_options ] ||= { } if gotcha = Gotcha . random field = "gotcha_response[#{gotcha.class.name.to_s}-#{Digest::MD5.hexdigest(gotcha.class.down_transform(gotcha.answer))}]" ( label_tag field , gotcha . question , options [ :label_options ] ) + "\n" + ( text_field_tag field , nil , options [ :text_field_options ] ) else raise "No Gotchas Installed" end end
852	def delete_image subreddit , image_name logged_in? post ( '/api/delete_sr_image' , body : { r : subreddit , img_name : image_name , uh : @modhash , api_type : 'json' } ) end
853	def set_stylesheet stylesheet , subreddit logged_in? post ( '/api/subreddit_stylesheet' , body : { op : 'save' , r : subreddit , stylesheet_contents : stylesheet , uh : @modhash , api_type : 'json' } ) end
854	def subscribe subreddit , action = "sub" logged_in? post ( '/api/subscribe' , body : { action : action , sr : subreddit , uh : @modhash , api_type : 'json' } ) end
855	def my_reddits opts = { } logged_in? url = "/reddits/mine/%s.json" % ( opts [ :condition ] if opts [ :condition ] ) opts . delete :condition query = opts get ( url , query : query ) end
856	def get_reddits opts = { } url = "/reddits/%s.json" % ( opts [ :condition ] if opts [ :condition ] ) opts . delete :condition query = opts get ( url , query : query ) end
857	def add_moderator container , user , subreddit friend_wrapper container : container , name : user , r : subreddit , type : "moderator" end
858	def add_contributor container , user , subreddit friend_wrapper container : container , name : user , r : subreddit , type : "contributor" end
859	def ban_user container , user , subreddit friend_wrapper container : container , name : user , r : subreddit , type : "banned" end
860	def remove_moderator container , user , subreddit unfriend_wrapper container : container , name : user , r : subreddit , type : "moderator" end
861	def remove_contributor container , user , subreddit unfriend_wrapper container : container , name : user , r : subreddit , type : "contributor" end
862	def unban_user container , user , subreddit unfriend_wrapper container : container , name : user , r : subreddit , type : "banned" end
863	def get * args , & block response = self . class . get * args , & block raise WebserverError , response . code unless response . code == 200 response end
864	def log_in username , password login = post ( "/api/login" , :body => { user : username , passwd : password , api_type : 'json' } ) errors = login [ 'json' ] [ 'errors' ] raise errors [ 0 ] [ 1 ] unless errors . size == 0 set_cookies login . headers [ 'set-cookie' ] @modhash = login [ 'json' ] [ 'data' ] [ 'modhash' ] @username = username @userid = 't2_' + get ( '/api/me.json' ) [ 'data' ] [ 'id' ] return login end
865	def auth modhash , cookies set_cookies cookies @modhash = modhash meinfo = get ( "/api/me.json" ) @username = meinfo [ 'data' ] [ 'name' ] @userid = 't2_' + meinfo [ 'data' ] [ 'id' ] end
866	def delete_user password , reason = "deleted by script command" logged_in? delete = post ( '/api/delete_user' , body : { confirm : true , delete_message : reason , passwd : password , uh : @modhash , user : @username , api_type : 'json' } ) return delete end
867	def get_messages where = "inbox" , opts = { } query = { mark : false } query . merge! opts get ( "/message/#{where}.json" , query : query ) end
868	def clear_flair_templates type , subreddit logged_in? post ( '/api/clearflairtemplates' , body : { flair_type : type , r : subreddit , uh : @modhash , api_type : 'json' } ) end
869	def delete_user_flair user , subreddit logged_in? post ( '/api/deleteflair' , body : { name : user , r : subreddit , uh : @modhash , api_type : 'json' } ) end
870	def delete_flair_template id , subreddit logged_in? post ( '/api/deleteflairtemplate' , body : { flair_template_id : id , r : subreddit , uh : @modhash , api_type : 'json' } ) end
871	def flair_config subreddit , opts = { } logged_in? options = { flair_enabled : true , flair_position : 'right' , flair_self_assign_enabled : false , link_flair_position : 'right' , link_flair_self_assign_enabled : false , uh : @modhash , r : subreddit , api_type : 'json' } options . merge! opts post ( '/api/flairconfig' , body : options ) end
872	def flair_csv csv , subreddit logged_in? post ( '/api/flaircsv.json' , body : { flair_csv : csv , r : subreddit , uh : @modhash } ) end
873	def flair_template subreddit , opts = { } logged_in? params = { flair_type : 'USER_FLAIR' , text_editable : false , uh : @modhash , r : subreddit , api_type : 'json' } params . merge! opts post ( '/api/flairtemplate' , body : params ) end
874	def select_flair_template template_id , subreddit , opts = { } logged_in? params = { flair_template_id : template_id , uh : @modhash , r : subreddit , api_type : 'json' } params . merge! opts post ( '/api/selectflair' , body : params ) end
875	def flair_toggle enabled , subreddit logged_in? post ( '/api/setflairenabled' , body : { flair_enabled : enabled , uh : @modhash , r : subreddit , api_type : 'json' } ) end
876	def get_comments opts = { } query = { limit : 100 } query . merge! opts url = "%s/comments/%s%s.json" % [ ( '/r/' + opts [ :subreddit ] if opts [ :subreddit ] ) , opts [ :link_id ] , ( '/blah/' + opts [ :comment_id ] if opts [ :comment_id ] ) ] get ( url , query : query ) end
877	def get_listing opts = { } url = "%s/%s.json" % [ ( '/r/' + opts [ :subreddit ] if opts [ :subreddit ] ) , ( opts [ :page ] if opts [ :page ] ) ] [ :subreddit , :page ] . each { | k | opts . delete k } query = opts get ( url , query : query ) end
878	def distinguish id , how = "yes" logged_in? hows = %w{ yes no admin special } post ( '/api/distinguish' , body : { id : id , how : how , uh : @modhash , api_type : 'json' } ) end
879	def remove id , spam = false logged_in? post ( '/api/remove' , body : { id : id , spam : spam , uh : @modhash , api_type : 'json' } ) end
880	def get_modlog subreddit , opts = { } logged_in? options = { limit : 100 } . merge opts data = Nokogiri :: HTML . parse ( get ( "/r/#{subreddit}/about/log" , query : options ) . body ) . css ( '.modactionlisting tr' ) processed = { data : [ ] , first : data [ 0 ] [ 'data-fullname' ] , first_date : Time . parse ( data [ 0 ] . children [ 0 ] . child [ 'datetime' ] ) , last : data [ - 1 ] [ 'data-fullname' ] , last_date : Time . parse ( data [ - 1 ] . children [ 0 ] . child [ 'datetime' ] ) , } data . each do | tr | processed [ :data ] << { fullname : tr [ 'data-fullname' ] , time : Time . parse ( tr . children [ 0 ] . child [ 'datetime' ] ) , author : tr . children [ 1 ] . child . content , action : tr . children [ 2 ] . child [ 'class' ] . split [ 1 ] , description : tr . children [ 3 ] . content , href : tr . children [ 3 ] . css ( 'a' ) . count == 0 ? nil : tr . children [ 3 ] . css ( 'a' ) [ 0 ] [ 'href' ] } end return processed end
881	def post ( query_params ) servers ||= SERVERS . map { | hostname | "https://#{hostname}/minfraud/chargeback" } url = URI . parse ( servers . shift ) req = Net :: HTTP :: Post . new ( url . path , initheader = { 'Content-Type' => 'application/json' } ) req . basic_auth Maxmind :: user_id , Maxmind :: license_key req . body = query_params h = Net :: HTTP . new ( url . host , url . port ) h . use_ssl = true h . verify_mode = OpenSSL :: SSL :: VERIFY_NONE h . open_timeout = 60 h . read_timeout = self . class . timeout || DefaultTimeout h . ssl_timeout = self . class . timeout || DefaultTimeout h . start { | http | http . request ( req ) } rescue Exception => e retry if servers . size > 0 raise e end
882	def lifespan = ( lifespan ) @lifespan = lifespan @@lifespans . each_with_index do | span , index | if span [ 0 ] == lifespan && lifespan != "Forever" self . expires = DateTime . now . advance ( @@lifespans [ index ] [ 1 ] ) end end end
883	def div cr_scanner = CodeRay . scan ( self . clip , self . language ) if cr_scanner . loc <= 1 return cr_scanner . div else return cr_scanner . div ( :line_numbers => :table ) end end
884	def set_variables ( instance_variables ) instance_variables . each { | name , value | instance_variable_set ( "@#{name}" , value ) } yield ( self ) instance_variables . each { | name , _ | remove_instance_variable ( "@#{name}" ) } self end
885	def render ( object , method , * args , & block ) object . __send__ method , self , * args , & block self end
886	def join ( collection , glue = nil , & it ) glue_block = case glue when String lambda { text glue } when Proc glue else lambda { } end collection . each_with_index do | obj , i | glue_block . call ( ) if i > 0 obj . is_a? ( Proc ) ? obj . call : it . call ( obj ) end end
887	def open_session ( uri ) validate_presence_of uri , 'Channel URI' response = @client . call ( :open_publication_session , message : { 'ChannelURI' => uri } ) response . to_hash [ :open_publication_session_response ] [ :session_id ] . to_s end
888	def post_publication ( session_id , content , topics , expiry = nil ) validate_presence_of session_id , 'Session Id' validate_presence_of content , 'Content' validate_presence_of topics , 'Topics' validate_xml content topics = [ topics ] . flatten xml = Builder :: XmlMarkup . new xml . isbm :SessionID , session_id xml . isbm :MessageContent do xml << content end topics . each do | topic | xml . isbm :Topic , topic end duration = expiry . to_s xml . isbm :Expiry , duration unless duration . nil? response = @client . call ( :post_publication , message : xml . target! ) response . to_hash [ :post_publication_response ] [ :message_id ] . to_s end
889	def expire_publication ( session_id , message_id ) validate_presence_of session_id , 'Session Id' validate_presence_of message_id , 'Message Id' @client . call ( :expire_publication , message : { 'SessionID' => session_id , 'MessageID' => message_id } ) return true end
890	def validate_presence_of ( value , name ) if value . respond_to? ( :each ) value . each do | v | if v . blank? raise ArgumentError , "Values in #{name} must not be blank" end end else if value . blank? raise ArgumentError , "#{name} must not be blank" end end end
891	def validate_xml ( xml ) doc = Nokogiri . XML ( xml ) raise ArgumentError , "XML is not well formed: #{xml}" unless doc . errors . empty? end
892	def default_savon_options ( options ) options [ :logger ] = Rails . logger if options [ :logger ] . nil? && defined? ( Rails ) options [ :log ] = false if options [ :log ] . nil? options [ :pretty_print_xml ] = true if options [ :pretty_print_xml ] . nil? end
893	def read_publication ( session_id ) validate_presence_of session_id , 'Session Id' response = @client . call ( :read_publication , message : { 'SessionID' => session_id } ) extract_message ( response ) end
894	def open_session ( uri , listener_url = nil ) validate_presence_of uri , 'Channel URI' message = { 'ChannelURI' => uri } message [ 'ListenerURL' ] = listener_url if listener_url response = @client . call ( :open_consumer_request_session , message : message ) response . to_hash [ :open_consumer_request_session_response ] [ :session_id ] . to_s end
895	def post_request ( session_id , content , topic , expiry = nil ) validate_presence_of session_id , 'Session Id' validate_presence_of content , 'Content' validate_presence_of topic , 'Topic' validate_xml content xml = Builder :: XmlMarkup . new xml . isbm :SessionID , session_id xml . isbm :MessageContent do xml << content end xml . isbm :Topic , topic duration = expiry . to_s xml . isbm :Expiry , duration unless duration . nil? response = @client . call ( :post_request , message : xml . target! ) response . to_hash [ :post_request_response ] [ :message_id ] . to_s end
896	def expire_request ( session_id , message_id ) validate_presence_of session_id , 'Session Id' validate_presence_of message_id , 'Message Id' @client . call ( :expire_request , message : { 'SessionID' => session_id , 'MessageID' => message_id } ) return true end
897	def read_response ( session_id , request_message_id ) validate_presence_of session_id , 'Session Id' validate_presence_of request_message_id , 'Request Message Id' message = { 'SessionID' => session_id , 'RequestMessageID' => request_message_id } response = @client . call ( :read_response , message : message ) extract_message ( response ) end
898	def remove_response ( session_id , request_message_id ) validate_presence_of session_id , 'Session Id' validate_presence_of request_message_id , 'Request Message Id' message = { 'SessionID' => session_id , 'RequestMessageID' => request_message_id } @client . call ( :remove_response , message : message ) return true end
899	def open_session ( uri , topics , listener_url = nil , xpath_expression = nil , xpath_namespaces = [ ] ) validate_presence_of uri , 'Channel URI' validate_presence_of topics , 'Topics' validate_presence_of xpath_expression , 'XPath Expression' if xpath_namespaces . present? topics = [ topics ] . flatten xml = Builder :: XmlMarkup . new xml . isbm :ChannelURI , uri topics . each do | topic | xml . isbm :Topic , topic end xml . isbm :ListenerURL , listener_url unless listener_url . nil? xml . isbm :XPathExpression , xpath_expression unless xpath_expression . nil? xpath_namespaces . each do | prefix , name | xml . isbm :XPathNamespace do xml . isbm :NamespacePrefix , prefix xml . isbm :NamespaceName , name end end response = @client . call ( :open_provider_request_session , message : xml . target! ) response . to_hash [ :open_provider_request_session_response ] [ :session_id ] . to_s end
900	def post_response ( session_id , request_message_id , content ) validate_presence_of session_id , 'Session Id' validate_presence_of request_message_id , 'Request Message Id' validate_presence_of content , 'Content' validate_xml content xml = Builder :: XmlMarkup . new xml . isbm :SessionID , session_id xml . isbm :RequestMessageID , request_message_id xml . isbm :MessageContent do xml << content end response = @client . call ( :post_response , message : xml . target! ) response . to_hash [ :post_response_response ] [ :message_id ] . to_s end
901	def create_channel ( uri , type , description = nil , tokens = { } ) validate_presence_of uri , 'Channel URI' validate_presence_of type , 'Channel Type' channel_type = type . to_s . downcase . capitalize validate_inclusion_in channel_type , IsbmAdaptor :: Channel :: TYPES , 'Channel Type' message = { 'ChannelURI' => uri , 'ChannelType' => channel_type } message [ 'ChannelDescription' ] = description unless description . nil? message [ 'SecurityToken' ] = security_token_hash ( tokens ) if tokens . any? @client . call ( :create_channel , message : message ) return true end
902	def add_security_tokens ( uri , tokens = { } ) validate_presence_of uri , 'Channel URI' validate_presence_of tokens , 'Security Tokens' message = { 'ChannelURI' => uri , 'SecurityToken' => security_token_hash ( tokens ) } @client . call ( :add_security_tokens , message : message ) return true end
903	def remove_security_tokens ( uri , tokens = { } ) validate_presence_of uri , 'Channel URI' validate_presence_of tokens , 'Security Tokens' message = { 'ChannelURI' => uri , 'SecurityToken' => security_token_hash ( tokens ) } @client . call ( :remove_security_tokens , message : message ) return true end
904	def get_channel ( uri , & block ) validate_presence_of uri , 'Channel URI' response = @client . call ( :get_channel , message : { 'ChannelURI' => uri } , & block ) hash = response . to_hash [ :get_channel_response ] [ :channel ] IsbmAdaptor :: Channel . from_hash ( hash ) end
905	def get_channels ( & block ) response = @client . call ( :get_channels , { } , & block ) channels = response . to_hash [ :get_channels_response ] [ :channel ] channels = [ channels ] . compact unless channels . is_a? ( Array ) channels . map do | hash | IsbmAdaptor :: Channel . from_hash ( hash ) end end
906	def update_backend if Idioma . configuration . redis_backend if i18n_value . present? Idioma :: RedisBackend . update_phrase ( self ) else Idioma :: RedisBackend . delete_phrase ( self ) end end end
907	def set_phrase @phrase = Phrase . find ( params [ :id ] ) rescue ActiveRecord :: RecordNotFound respond_to do | format | format . json { render json : { } . to_json , status : :not_found } format . html { flash [ :error ] = t ( 'idioma.record_not_found' ) redirect_to phrases_path } end end
908	def to_s date = [ ] date << "#{@years}Y" unless @years . nil? date << "#{@months}M" unless @months . nil? date << "#{@days}D" unless @days . nil? time = [ ] time << "#{@hours}H" unless @hours . nil? time << "#{@minutes}M" unless @minutes . nil? time << "#{@seconds}S" unless @seconds . nil? result = nil if ! date . empty? || ! time . empty? result = 'P' result += date . join unless date . empty? result += 'T' + time . join unless time . empty? end result end
909	def to_lat format = :dms , dp = 0 return lat if ! format GeoUnits :: Converter . to_lat lat , format , dp end
910	def projects if @projects . nil? response = self . get ( "projects" ) @projects = response . collect { | project_json | Project . new ( project_json ) } end @projects end
911	def project ( id ) @url = "projects/#{id}" raise OptimizelyError :: NoProjectID , "A Project ID is required to retrieve the project." if id . nil? response = self . get ( @url ) Project . new ( response ) end
912	def experiments ( project_id ) raise OptimizelyError :: NoProjectID , "A Project ID is required to retrieve experiments." if project_id . nil? response = self . get ( "projects/#{project_id}/experiments" ) response . collect { | response_json | Experiment . new ( response_json ) } end
913	def experiment ( id ) @url = "experiments/#{id}" raise OptimizelyError :: NoExperimentID , "An Experiment ID is required to retrieve the experiment." if id . nil? response = self . get ( @url ) Experiment . new ( response ) end
914	def stats ( experiment_id ) @url = "experiments/#{experiment_id}/stats" raise OptimizelyError :: NoExperimentID , "An Experiment ID is required to retrieve the stats." if experiment_id . nil? response = self . get ( @url ) response . collect { | response_json | Stat . new ( response_json ) } end
915	def variations ( experiment_id ) raise OptimizelyError :: NoExperimentID , "An Experiment ID is required to retrieve variations." if experiment_id . nil? response = self . get ( "experiments/#{experiment_id}/variations" ) response . collect { | variation_json | Variation . new ( variation_json ) } end
916	def variation ( id ) @url = "variations/#{id}" raise OptimizelyError :: NoVariationID , "A Variation ID is required to retrieve the variation." if id . nil? response = self . get ( @url ) Variation . new ( response ) end
917	def audiences ( project_id ) raise OptimizelyError :: NoProjectID , "A Project ID is required to retrieve audiences." if project_id . nil? response = self . get ( "projects/#{project_id}/audiences" ) response . collect { | audience_json | Audience . new ( audience_json ) } end
918	def audience ( id ) @url = "audiences/#{id}" raise OptimizelyError :: NoAudienceID , "An Audience ID is required to retrieve the audience." if id . nil? response = self . get ( @url ) Audience . new ( response ) end
919	def get ( url ) uri = URI . parse ( "#{BASE_URL}#{url}/" ) https = Net :: HTTP . new ( uri . host , uri . port ) https . read_timeout = @options [ :timeout ] if @options [ :timeout ] https . verify_mode = OpenSSL :: SSL :: VERIFY_NONE https . use_ssl = true request = Net :: HTTP :: Get . new ( uri . request_uri , @headers ) response = https . request ( request ) if response . code != '200' check_response ( response . code , response . body ) else parse_json ( response . body ) end end
920	def lget ( * keys ) h = keys . flatten . inject ( { } ) { | hh , k | hh [ k ] = nil ; hh } r = @db . mget ( h ) raise 'lget failure' if r == - 1 h end
921	def get_random_number ( bytes ) RbNaCl :: Util . bin2hex ( RbNaCl :: Random . random_bytes ( bytes ) . to_s ) . to_i ( 16 ) end
922	def get_random_number_with_bitlength ( bits ) byte_length = ( bits / 8.0 ) . ceil + 10 random_num = get_random_number ( byte_length ) random_num_bin_str = random_num . to_s ( 2 ) random_num_bin_str . slice ( 0 , bits ) . to_i ( 2 ) end
923	def add ( colname , operator , val , affirmative = true , no_index = false ) colname = colname . to_s val = val . to_s op = operator . is_a? ( Fixnum ) ? operator : OPERATORS [ operator ] op = op | TDBQCNEGATE unless affirmative op = op | TDBQCNOIDX if no_index @query . addcond ( colname , op , val ) end
924	def keys ( options = { } ) if @db . respond_to? :fwmkeys pref = options . fetch ( :prefix , "" ) @db . fwmkeys ( pref , options [ :limit ] || - 1 ) elsif @db . respond_to? :range @db . range ( "[min,max]" , nil ) else raise NotImplementedError , "Database does not support keys()" end end
925	def autocomplete_to_add_item ( name , f , association , source , options = { } ) new_object = f . object . send ( association ) . klass . new options [ :class ] = [ "autocomplete add-item" , options [ :class ] ] . compact . join " " options [ :data ] ||= { } options [ :data ] [ :id ] = new_object . object_id options [ :data ] [ :source ] = source options [ :data ] [ :item ] = f . fields_for ( association , new_object , child_index : options [ :data ] [ :id ] ) do | builder | render ( association . to_s . singularize + "_item" , f : builder ) . gsub "\n" , "" end text_field_tag "autocomplete_nested_content" , nil , options end
926	def fetch ( id ) r = nil begin r = lib . tcidbget ( @db , id ) rescue => e if lib . tcidbecode ( @db ) == 22 then return nil else raise_error end end return r end
927	def search ( expression ) out_count = :: FFI :: MemoryPointer . new :pointer out_list = :: FFI :: MemoryPointer . new :pointer out_list = lib . tcidbsearch2 ( @db , expression , out_count ) count = out_count . read_int results = out_list . get_array_of_uint64 ( 0 , count ) return results end
928	def char_freq ( str ) freqs = Hash . new ( 0 ) ( 1 .. 4 ) . each do | i | str . chars . each_cons ( i ) . inject ( freqs ) do | freq , ngram | ngram = ngram . join freq [ ngram ] = freq [ ngram ] + 1 freq end end freqs end
929	def top ( n , scores ) scores . sort { | a , b | a [ 1 ] <=> b [ 1 ] } . map { | x | x [ 0 ] } . first ( n ) end
930	def recolor ( bg : '#000' , fg : '#fff' , bg_opacity : "1.0" , fg_opacity : "1.0" ) OptionalDeps . require_nokogiri bg . prepend ( '#' ) unless bg . start_with? '#' fg . prepend ( '#' ) unless fg . start_with? '#' doc = Nokogiri :: XML ( self . string ) doc . css ( 'path' ) [ 0 ] [ 'fill' ] = bg doc . css ( 'path' ) [ 1 ] [ 'fill' ] = fg doc . css ( 'path' ) [ 0 ] [ 'fill-opacity' ] = bg_opacity . to_s doc . css ( 'path' ) [ 1 ] [ 'fill-opacity' ] = fg_opacity . to_s @svgstr = doc . to_xml self end
931	def compact_copy ( target_path ) @other_db = Cabinet . new ( target_path ) self . each { | k , v | @other_db [ k ] = v } @other_db . close end
932	def keys ( options = { } ) if @type == "tcf" min , max = "min" , "max" l = lib . tcfdbrange2 ( as_fixed , min , Rufus :: Tokyo . blen ( min ) , max , Rufus :: Tokyo . blen ( max ) , - 1 ) else pre = options . fetch ( :prefix , "" ) l = lib . abs_fwmkeys ( @db , pre , Rufus :: Tokyo . blen ( pre ) , options [ :limit ] || - 1 ) end l = Rufus :: Tokyo :: List . new ( l ) options [ :native ] ? l : l . release end
933	def get4 ( k ) l = lib . tcbdbget4 ( as_btree , k , Rufus :: Tokyo . blen ( k ) ) Rufus :: Tokyo :: List . new ( l ) . release end
934	def []= ( k , v ) clib . tcmapput ( pointer , k , Rufus :: Tokyo :: blen ( k ) , v , Rufus :: Tokyo :: blen ( v ) ) v end
935	def delete ( k ) v = self [ k ] return nil unless v clib . tcmapout ( pointer_or_raise , k , Rufus :: Tokyo :: blen ( k ) ) || raise ( "failed to remove key '#{k}'" ) v end
936	def keys clib . tcmapiterinit ( pointer_or_raise ) a = [ ] klen = FFI :: MemoryPointer . new ( :int ) loop do k = clib . tcmapiternext ( @pointer , klen ) break if k . address == 0 a << k . get_bytes ( 0 , klen . get_int ( 0 ) ) end return a ensure klen . free end
937	def []= ( a , b , c = nil ) i , s = c . nil? ? [ a , b ] : [ [ a , b ] , c ] range = if i . is_a? ( Range ) i elsif i . is_a? ( Array ) start , count = i ( start .. start + count - 1 ) else [ i ] end range = norm ( range ) values = s . is_a? ( Array ) ? s : [ s ] range . each_with_index do | offset , index | val = values [ index ] if val clib . tclistover ( @pointer , offset , val , Rufus :: Tokyo . blen ( val ) ) else outlen_op ( :tclistremove , values . size ) end end self end
938	def keys ( options = { } ) pre = options . fetch ( :prefix , "" ) l = lib . tab_fwmkeys ( @db , pre , Rufus :: Tokyo . blen ( pre ) , options [ :limit ] || - 1 ) l = Rufus :: Tokyo :: List . new ( l ) options [ :native ] ? l : l . release end
939	def lget ( * keys ) keys . flatten . inject ( { } ) { | h , k | k = k . to_s v = self [ k ] h [ k ] = v if v h } end
940	def raise_error err_code = lib . tab_ecode ( @db ) err_msg = lib . tab_errmsg ( err_code ) raise TokyoError . new ( "(err #{err_code}) #{err_msg}" ) end
941	def each ( 0 .. size - 1 ) . each do | i | pk = @list [ i ] if @opts [ :pk_only ] yield ( pk ) else val = @table [ pk ] val [ :pk ] = pk unless @opts [ :no_pk ] yield ( val ) end end end
942	def find ( icon ) str = icon . to_s . downcase file = DB . files [ str ] || DB . files [ str . sub ( / \. / , '' ) ] || not_found ( str , icon ) Icon . new ( file ) end
943	def get_columns ( table_name ) columns_arr = [ ] pst = @db . prepare "SELECT * FROM #{table_name} LIMIT 6" pst . columns . each do | c | columns_arr . push ( c ) end columns_arr end
944	def is_numeric ( table_name , column_name ) if @db . execute ( "SELECT #{column_name} from #{table_name} LIMIT 1" ) . first . first . is_a? Numeric return true else return false end end
945	def deal_with_valid_option ( temp_tables , temp_columns , temp_column_types , res ) if ! temp_tables . empty? check_given_tables_validity ( temp_tables ) temp_tables . each do | t | res << convert_table ( t ) end elsif ! temp_columns . keys . empty? check_given_columns_validity ( temp_columns ) res << convert_from_columns_hash ( temp_columns ) elsif ! temp_column_types . empty? check_given_columns_validity ( temp_column_types ) res << convert_from_column_types_hash ( temp_column_types ) end end
946	def let_context ( * args , & block ) context_string , hash = case args . map ( & :class ) when [ String , Hash ] then [ "#{args[0]} #{args[1]}" , args [ 1 ] ] when [ Hash ] then [ args [ 0 ] . inspect , args [ 0 ] ] end context ( context_string ) do hash . each { | var , value | let ( var ) { value } } instance_eval ( & block ) end end
947	def subject_should_raise ( * args ) error , message = args it_string = "subject should raise #{error}" it_string += " (#{message.inspect})" if message it it_string do expect { subject } . to raise_error error , message end end
948	def subject_should_not_raise ( * args ) error , message = args it_string = "subject should not raise #{error}" it_string += " (#{message.inspect})" if message it it_string do expect { subject } . not_to raise_error error , message end end
949	def login ( user , options = { } ) options [ :scope ] ||= Janus . scope_for ( user ) set_user ( user , options ) Janus :: Manager . run_callbacks ( :login , user , self , options ) end
950	def logout ( * scopes ) scopes = janus_sessions . keys if scopes . empty? scopes . each do | scope | _user = user ( scope ) unset_user ( scope ) Janus :: Manager . run_callbacks ( :logout , _user , self , :scope => scope ) end request . reset_session if janus_sessions . empty? end
951	def set_user ( user , options = { } ) scope = options [ :scope ] || Janus . scope_for ( user ) janus_sessions [ scope . to_s ] = { 'user_class' => user . class . name , 'user_id' => user . id } end
952	def unset_user ( scope ) janus_sessions . delete ( scope . to_s ) @users . delete ( scope . to_sym ) unless @users . nil? end
953	def user ( scope ) scope = scope . to_sym @users ||= { } if authenticated? ( scope ) if @users [ scope ] . nil? begin @users [ scope ] = user_class ( scope ) . find ( session ( scope ) [ 'user_id' ] ) rescue ActiveRecord :: RecordNotFound unset_user ( scope ) else Janus :: Manager . run_callbacks ( :fetch , @users [ scope ] , self , :scope => scope ) end end @users [ scope ] end end
954	def namespace return '#' if Tml . config . disabled? @namespace || Tml . config . cache [ :namespace ] || Tml . config . application [ :key ] [ 0 .. 5 ] end
955	def extract_version ( app , version = nil ) if version Tml . cache . version . set ( version . to_s ) else version_data = app . api_client . get_from_cdn ( 'version' , { t : Time . now . to_i } , { uncompressed : true } ) unless version_data Tml . logger . debug ( 'No releases have been generated yet. Please visit your Dashboard and publish translations.' ) return end Tml . cache . version . set ( version_data [ 'version' ] ) end end
956	def warmup ( version = nil , cache_path = nil ) if cache_path . nil? warmup_from_cdn ( version ) else warmup_from_files ( version , cache_path ) end end
957	def warmup_from_files ( version = nil , cache_path = nil ) t0 = Time . now Tml . logger = Logger . new ( STDOUT ) Tml . logger . debug ( 'Starting cache warmup from local files...' ) version ||= Tml . config . cache [ :version ] cache_path ||= Tml . config . cache [ :path ] cache_path = "#{cache_path}/#{version}" Tml . cache . version . set ( version . to_s ) Tml . logger . debug ( "Warming Up Version: #{Tml.cache.version}" ) application = JSON . parse ( File . read ( "#{cache_path}/application.json" ) ) Tml . cache . store ( Tml :: Application . cache_key , application ) sources = JSON . parse ( File . read ( "#{cache_path}/sources.json" ) ) application [ 'languages' ] . each do | lang | locale = lang [ 'locale' ] language = JSON . parse ( File . read ( "#{cache_path}/#{locale}/language.json" ) ) Tml . cache . store ( Tml :: Language . cache_key ( locale ) , language ) sources . each do | src | source = JSON . parse ( File . read ( "#{cache_path}/#{locale}/sources/#{src}.json" ) ) Tml . cache . store ( Tml :: Source . cache_key ( locale , src ) , source ) end end t1 = Time . now Tml . logger . debug ( "Cache warmup took #{t1-t0}s" ) end
958	def warmup_from_cdn ( version = nil ) t0 = Time . now Tml . logger = Logger . new ( STDOUT ) Tml . logger . debug ( 'Starting cache warmup from CDN...' ) app = Tml :: Application . new ( key : Tml . config . application [ :key ] , cdn_host : Tml . config . application [ :cdn_host ] ) extract_version ( app , version ) Tml . logger . debug ( "Warming Up Version: #{Tml.cache.version}" ) application = app . api_client . get_from_cdn ( 'application' , { t : Time . now . to_i } ) Tml . cache . store ( Tml :: Application . cache_key , application ) sources = app . api_client . get_from_cdn ( 'sources' , { t : Time . now . to_i } , { uncompressed : true } ) application [ 'languages' ] . each do | lang | locale = lang [ 'locale' ] language = app . api_client . get_from_cdn ( "#{locale}/language" , { t : Time . now . to_i } ) Tml . cache . store ( Tml :: Language . cache_key ( locale ) , language ) sources . each do | src | source = app . api_client . get_from_cdn ( "#{locale}/sources/#{src}" , { t : Time . now . to_i } ) Tml . cache . store ( Tml :: Source . cache_key ( locale , src ) , source ) end end t1 = Time . now Tml . logger . debug ( "Cache warmup took #{t1-t0}s" ) end
959	def default_cache_path @cache_path ||= begin path = Tml . config . cache [ :path ] path ||= 'config/tml' FileUtils . mkdir_p ( path ) FileUtils . chmod ( 0777 , path ) path end end
960	def download ( cache_path = default_cache_path , version = nil ) t0 = Time . now Tml . logger = Logger . new ( STDOUT ) Tml . logger . debug ( 'Starting cache download...' ) app = Tml :: Application . new ( key : Tml . config . application [ :key ] , cdn_host : Tml . config . application [ :cdn_host ] ) extract_version ( app , version ) Tml . logger . debug ( "Downloading Version: #{Tml.cache.version}" ) archive_name = "#{Tml.cache.version}.tar.gz" path = "#{cache_path}/#{archive_name}" url = "#{app.cdn_host}/#{Tml.config.application[:key]}/#{archive_name}" Tml . logger . debug ( "Downloading cache file: #{url}" ) open ( path , 'wb' ) do | file | file << open ( url ) . read end Tml . logger . debug ( 'Extracting cache file...' ) version_path = "#{cache_path}/#{Tml.cache.version}" Tml :: Utils . untar ( Tml :: Utils . ungzip ( File . new ( path ) ) , version_path ) Tml . logger . debug ( "Cache has been stored in #{version_path}" ) File . unlink ( path ) begin current_path = 'current' FileUtils . chdir ( cache_path ) FileUtils . rm ( current_path ) if File . exist? ( current_path ) FileUtils . ln_s ( Tml . cache . version . to_s , current_path ) Tml . logger . debug ( "The new version #{Tml.cache.version} has been marked as current" ) rescue Exception => ex Tml . logger . debug ( "Could not generate current symlink to the cache path: #{ex.message}" ) end t1 = Time . now Tml . logger . debug ( "Cache download took #{t1-t0}s" ) end
961	def say ( message , color = nil ) @shell ||= Thor :: Shell :: Basic . new @shell . say message , color end
962	def validate_cache_version ( version ) if Tml . config . cache [ :version ] return Tml . config . cache [ :version ] end return version unless version . is_a? ( Hash ) return 'undefined' unless version [ 't' ] . is_a? ( Numeric ) return version [ 'version' ] if cache . read_only? if version_check_interval == - 1 Tml . logger . debug ( 'Cache version check is disabled' ) return version [ 'version' ] end expires_at = version [ 't' ] + version_check_interval if expires_at < Time . now . to_i Tml . logger . debug ( 'Cache version is outdated, needs refresh' ) return 'undefined' end delta = expires_at - Time . now . to_i Tml . logger . debug ( "Cache version is up to date, expires in #{delta}s" ) version [ 'version' ] end
963	def fetch self . version = begin ver = cache . fetch ( CACHE_VERSION_KEY ) do { 'version' => Tml . config . cache [ :version ] || 'undefined' , 't' => cache_timestamp } end validate_cache_version ( ver ) end end
964	def [] file , * ps , & exe opts = :: Hash === ps . last ? ps . pop : { } opts [ :env ] = self name , type , flg = ps [ 0 ] || opts [ :name ] , ps [ 1 ] || opts [ :type ] , ps [ 2 ] || opts [ :flags ] ps . push opts @dbs [ [ file , name , flg | CREATE ] ] ||= ( type || SBDB :: Unknown ) . new file , * ps , & exe end
965	def run_strategies ( scope ) Janus :: Manager . strategies . each { | name | break if run_strategy ( name , scope ) } end
966	def run_strategy ( name , scope ) strategy = "Janus::Strategies::#{name.to_s.camelize}" . constantize . new ( scope , self ) if strategy . valid? strategy . authenticate! if strategy . success? send ( strategy . auth_method , strategy . user , :scope => scope ) Janus :: Manager . run_callbacks ( :authenticate , strategy . user , self , :scope => scope ) end end strategy . success? end
967	def perform ( script ) export_variables = @params . reverse_merge ( "PARADUCT_JOB_ID" => @job_id , "PARADUCT_JOB_NAME" => job_name ) variable_string = export_variables . map { | key , value | %(export #{key}="#{value}";) } . join ( " " ) Array . wrap ( script ) . inject ( "" ) do | stdout , command | stdout << run_command ( "#{variable_string} #{command}" ) stdout end end
968	def print_hex ( data , chunk_index , cols = 80 ) case hex_style when 'lower' , 'lowercase' print Sixword :: Hex . encode ( data ) when 'finger' , 'fingerprint' newlines_every = cols / 5 if chunk_index != 0 if chunk_index % newlines_every == 0 print "\n" else print ' ' end end print Sixword :: Hex . encode_fingerprint ( data ) when 'colon' , 'colons' print ':' unless chunk_index == 0 print Sixword :: Hex . encode_colons ( data ) end end
969	def read_input_by_6_words word_arr = [ ] while true line = stream . gets if line . nil? break end line . scan ( / \S / ) do | word | word_arr << word if word_arr . length == 6 yield word_arr word_arr . clear end end end if ! word_arr . empty? yield word_arr end end
970	def select ( query , filters ) where , * bind_values = conditions ( query , filters ) [ [ from ( filters ) , where , order_by ( filters ) , limits ( filters ) ] . join ( " " ) , * bind_values ] end
971	def update ( id , attributes ) set_attrs , * bind_values = update_attributes ( attributes ) [ [ "UPDATE #{@index_name} SET" , set_attrs , "WHERE id = ?" ] . join ( " " ) , * bind_values . push ( id ) ] end
972	def query ( sql , * bind_values ) @pool . acquire { | conn | conn . query ( sql , * bind_values ) . first } end
973	def method_missing ( method , * args , & block ) if method . to_s =~ / / if instance_methods ( false ) . detect { | meth | meth . to_s == $1 } Woodhouse . dispatch ( @worker_name , $1 , args . first ) else super end else super end end
974	def add_node ( node ) if node . respond_to? ( :to_sym ) node = Woodhouse :: Layout :: Node . new ( node . to_sym ) end expect_arg :node , Woodhouse :: Layout :: Node , node @nodes << node node end
975	def node ( name ) name = name . to_sym @nodes . detect { | node | node . name == name } end
976	def canonical ( attribute_list ) case attribute_list when nil then { } when Hash then attribute_list when Array attribute_list . map do | attributes | case attributes when Symbol { attributes => AUTO } when Hash attributes else raise "Unexpected attributes #{attributes}" end end . inject ( { } , :merge ) else raise "Unexpected attribute_list #{attribute_list}" end end
977	def imagine ( character_or_model , attributes = nil ) character = to_character ( character_or_model ) prev , @building = @building , [ ] CharacterBuilder . new ( character ) . build ( attributes ) do | ar | ar . save! @building . each do | built | raise ActiveRecord :: RecordInvalid , built unless built . persisted? || built . valid? end Scheherazade . log ( :saving , character , ar ) handle_callbacks ( @building ) end ensure @built . concat ( @building ) @building = prev end
978	def with ( temp_current ) keys = temp_current . keys . map { | k | to_character ( k ) } previous_values = current . values_at ( * keys ) current . merge! ( Hash [ keys . zip ( temp_current . values ) ] ) yield ensure current . merge! ( Hash [ keys . zip ( previous_values ) ] ) end
979	def failure ( exception_class_or_message , message_or_nil = nil ) blank . tap do | d | d . fail ( case exception_class_or_message when Exception raise ArgumentError , "can't specify both exception and message" if message_or_nil exception_class_or_message when Class exception_class_or_message . new ( message_or_nil ) else RuntimeError . new ( exception_class_or_message . to_s ) end ) end end
980	def file_length if self . audio . is_a? ( File ) && self . audio . size > MAX_FILE_SIZE self . errors . add :audio , "It's length is excesive. #{MAX_FILE_SIZE} is the limit." return false end return true end
981	def api_call method , payload raise ArgumentError , "API method not specified." if method . blank? payload ||= { } res = @conn . post method . to_s , payload raise Faraday :: Error , "Wrong response: #{res.inspect}" if ( res . status != 200 ) return res end
982	def multi_search ( queries ) unless queries . kind_of? ( Hash ) raise ArgumentError , "Argument must be a Hash of named queries (#{queries.class} given)" end stmts = [ ] bind_values = [ ] queries . each do | key , args | str , * values = @builder . select ( * extract_query_data ( args ) ) stmts . push ( str , "SHOW META" ) bind_values . push ( * values ) end rs = @conn . multi_query ( stmts . join ( ";\n" ) , * bind_values ) Hash [ ] . tap do | result | queries . keys . each do | key | records , meta = rs . shift , rs . shift result [ key ] = meta_to_hash ( meta ) . tap do | r | r [ :records ] = records . map { | hash | hash . inject ( { } ) { | o , ( k , v ) | o . merge! ( k . to_sym => v ) } } end end end end
983	def has_whereabouts klass = :address , * args options = args . extract_options! unless klass == :address || Object . const_defined? ( klass . to_s . camelize ) create_address_class ( klass . to_s . camelize ) end has_one klass , :as => :addressable , :dependent => :destroy accepts_nested_attributes_for klass if options [ :validate ] && options [ :validate ] . is_a? ( Array ) validators = options [ :validate ] set_validators ( klass , validators ) else validators = [ ] end define_singleton_method validate_singleton_for ( klass ) do validators end if options [ :geocode ] && options [ :geocode ] == true && defined? ( Geocoder ) geocode = true set_geocoding ( klass ) else geocode = false end define_singleton_method geocode_singleton_for ( klass ) do geocode end end
984	def set_validators klass , fields = [ ] _single = validate_singleton_for ( klass ) klass . to_s . camelize . constantize . class_eval do fields . each do | f | validates_presence_of f , :if => lambda { | a | a . addressable_type . constantize . send ( _single ) . include? ( f ) } end end end
985	def create_address_class ( class_name , & block ) klass = Class . new Address , & block Object . const_set class_name , klass end
986	def event_loop Qwirk . logger . debug "#{self}: Starting receive loop" @start_worker_time = Time . now until @stopped || ( config . stopped? && @impl . ready_to_stop? ) Qwirk . logger . debug "#{self}: Waiting for read" @start_read_time = Time . now msg = @impl . receive_message if msg @start_processing_time = Time . now Qwirk . logger . debug { "#{self}: Done waiting for read in #{@start_processing_time - @start_read_time} seconds" } delta = config . timer . measure do @processing_mutex . synchronize do on_message ( msg ) @impl . acknowledge_message ( msg ) end end Qwirk . logger . info { "#{self}::on_message (#{'%.1f' % delta}ms)" } if self . config . log_times Qwirk . logger . flush if Qwirk . logger . respond_to? ( :flush ) end end Qwirk . logger . info "#{self}: Exiting" rescue Exception => e @status = "Terminated: #{e.message}" Qwirk . logger . error "#{self}: Exception, thread terminating: #{e.message}\n\t#{e.backtrace.join("\n\t")}" ensure @status = 'Stopped' Qwirk . logger . flush if Qwirk . logger . respond_to? ( :flush ) config . worker_stopped ( self ) end
987	def arel_attributes_values ( include_primary_key = true , include_readonly_attributes = true , attribute_names = @attributes . keys ) attrs = { } attribute_names . each do | name | if ( column = column_for_attribute ( name ) ) && ( include_primary_key || ! column . primary ) if include_readonly_attributes || ( ! include_readonly_attributes && ! self . class . readonly_attributes . include? ( name ) ) value = read_attribute ( name ) if self . class . columns_hash [ name ] . type == :hstore && value && value . is_a? ( Hash ) value = value . to_hstore elsif value && self . class . serialized_attributes . has_key? ( name ) && ( value . acts_like? ( :date ) || value . acts_like? ( :time ) || value . is_a? ( Hash ) || value . is_a? ( Array ) ) value = value . to_yaml end attrs [ self . class . arel_table [ name ] ] = value end end end attrs end
988	def requires_version ( cmd , version_ ) v = check_version ( version_ ) raise NoMethodError , format ( '%s is not supported in Bugzilla %s' , cmd , v [ 1 ] ) unless v [ 0 ] end
989	def run begin Clacks . logger . info "Clacks v#{Clacks::VERSION} started" if Clacks . config [ :pop3 ] run_pop3 elsif Clacks . config [ :imap ] run_imap else raise "Either a POP3 or an IMAP server must be configured" end rescue Exception => e fatal ( e ) end end
990	def imap_validate_options ( options ) options ||= { } options [ :mailbox ] ||= 'INBOX' options [ :count ] ||= 5 options [ :order ] ||= :asc options [ :what ] ||= :first options [ :keys ] ||= 'ALL' options [ :delete_after_find ] ||= false options [ :mailbox ] = Net :: IMAP . encode_utf7 ( options [ :mailbox ] ) if options [ :archivebox ] options [ :archivebox ] = Net :: IMAP . encode_utf7 ( options [ :archivebox ] ) end options end
991	def imap_find ( imap ) options = Clacks . config [ :find_options ] delete_after_find = options [ :delete_after_find ] begin break if stopping? uids = imap . uid_search ( options [ :keys ] || 'ALL' ) uids . reverse! if options [ :what ] . to_sym == :last uids = uids . first ( options [ :count ] ) if options [ :count ] . is_a? ( Integer ) uids . reverse! if ( options [ :what ] . to_sym == :last && options [ :order ] . to_sym == :asc ) || ( options [ :what ] . to_sym != :last && options [ :order ] . to_sym == :desc ) processed = 0 expunge = false uids . each do | uid | break if stopping? source = imap . uid_fetch ( uid , [ 'RFC822' ] ) . first . attr [ 'RFC822' ] mail = nil begin mail = Mail . new ( source ) mail . mark_for_delete = true if delete_after_find Clacks . config [ :on_mail ] . call ( mail ) rescue StandardError => e Clacks . logger . error ( e . message ) Clacks . logger . error ( e . backtrace ) end begin imap . uid_copy ( uid , options [ :archivebox ] ) if options [ :archivebox ] if delete_after_find && ( mail . nil? || mail . is_marked_for_delete? ) expunge = true imap . uid_store ( uid , "+FLAGS" , [ Net :: IMAP :: DELETED ] ) end rescue StandardError => e Clacks . logger . error ( e . message ) end processed += 1 end imap . expunge if expunge end while uids . any? && processed == uids . length end
992	def rainbow ( str ) i = 0 ret = '' str = str . to_s while ( i < str . length ) ch = str [ i ] palette = $color_db [ 0 ] [ i % $color_db [ 0 ] . length ] ret << ( colora ( palette , str [ i , 1 ] ) ) i += 1 end ret end
993	def large_enough_prime ( input ) standard_primes . each do | prime | return prime if prime > input end fail CannotFindLargeEnoughPrime , "Input too large" end
994	def enhance_content ( value , separator = ', ' ) value . is_a? ( Array ) ? value . join ( separator ) : value end
995	def i_to_s ( input ) if ! input . is_a? ( Integer ) || input < 0 fail NotPositiveInteger , "input must be a non-negative integer" end output = "" while input > 0 input , codepoint = input . divmod ( charset . length ) output . prepend ( codepoint_to_char ( codepoint ) ) end output end
996	def s_to_i ( string ) string . chars . reduce ( 0 ) do | output , char | output * charset . length + char_to_codepoint ( char ) end end
997	def char_to_codepoint ( c ) codepoint = charset . index c if codepoint . nil? fail NotInCharset , "Char \"#{c}\" not part of the supported charset" end codepoint end
998	def subset? ( string ) ( Set . new ( string . chars ) - Set . new ( charset ) ) . empty? end
999	def points ( num_points , prime ) intercept = @coefficients [ 0 ] ( 1 .. num_points ) . map do | x | y = intercept ( 1 ... @coefficients . length ) . each do | i | y = ( y + @coefficients [ i ] * x ** i ) % prime end Point . new ( x , y ) end end
1000	def validate! files = Dir . glob ( File . join ( @directory , '*.xml' ) ) . sort threads = [ ] files . map do | path | threads << Thread . new ( path ) do | path_t | eadid = File . basename ( path_t , '.xml' ) begin ead = Mead :: Ead . new ( { :file => File . open ( path_t ) , :eadid => eadid } ) rescue => e record_invalid ( eadid , ead , e ) next end if ead . valid? @valid << eadid else record_invalid ( eadid , ead ) end end end threads . each { | thread | thread . join } metadata end
1001	def notify_create self . ChannelPublications . each do | publication , options | if options [ :actions ] . include? :create records = self . class . scoped_collection ( options [ :scope ] ) if options [ :scope ] == :all or record_within_scope ( records ) ActionCable . server . broadcast publication , msg : 'create' , id : self . id , data : self end end end end
1002	def notify_update if self . respond_to? ( :saved_changes ) changes = self . saved_changes . transform_values ( & :second ) else changes = self . changes . transform_values ( & :second ) end if ! changes . empty? self . ChannelPublications . each do | publication , options | if options [ :actions ] . include? :update record = record_within_scope ( options [ :records ] ) was_in_scope = record . present? options [ :records ] . delete ( record ) if was_in_scope if options [ :track_scope_changes ] == true is_in_scope = false if options [ :scope ] == :all record = self is_in_scope = true else record = record_within_scope ( self . class . scoped_collection ( options [ :scope ] ) ) if record . present? is_in_scope = true end end else is_in_scope = was_in_scope end if is_in_scope if was_in_scope changes . select! { | k , v | record . respond_to? ( k ) } if ! changes . empty? ActionCable . server . broadcast publication , msg : 'update' , id : self . id , data : changes end else ActionCable . server . broadcast publication , msg : 'create' , id : record . id , data : record end elsif was_in_scope ActionCable . server . broadcast publication , msg : 'destroy' , id : self . id end end end end end
1003	def notify_destroy self . ChannelPublications . each do | publication , options | if options [ :scope ] == :all or options [ :actions ] . include? :destroy if options [ :scope ] == :all or record_within_scope ( self . class . scoped_collection ( options [ :scope ] ) ) . present? ActionCable . server . broadcast publication , msg : 'destroy' , id : self . id end end end end
1004	def logger ( obj ) %w( debug info warn error fatal level ) . each do | m | next if obj . respond_to? ( m ) raise ArgumentError , "logger #{obj} does not respond to method #{m}" end map [ :logger ] = obj end
1005	def fetch_rates if self . class . superclass . eql? ( Object ) raise Exception . new ( "This method should be invoked from CurrencySpy::Scraper sub class" ) else check_currency_code_validity rate_results = { } RATE_DATA . each do | rate | symbol = rate . to_sym if self . class . instance_methods . include? ( symbol ) value = self . send ( symbol ) rate_results [ symbol ] = value unless value . nil? end end rate_results end end
1006	def parse ( target ) if ( width = fmt . width ) > 0 head , tail = src [ 0 ... width ] , src [ width .. - 1 ] || "" else head , tail = src , "" end @prematch , @match , @postmatch = head . partition ( target ) if found? @src = @postmatch + tail @match else nil end end
1007	def grab width = fmt . width if width > 0 result , @src = src [ 0 ... width ] , src [ width .. - 1 ] || "" elsif width == 0 result , @src = src [ 0 ... 1 ] , src [ 1 .. - 1 ] || "" elsif width == - 1 result , @src = src , "" else result , @src = src [ 0 .. width ] , src [ ( width + 1 ) .. - 1 ] || "" end result end
1008	def get_comments ( bugs ) params = { } params [ 'ids' ] = case bugs when Array bugs when Integer || String [ bugs ] else raise ArgumentError , format ( 'Unknown type of arguments: %s' , bugs . class ) end result = comments ( params ) ret = result [ 'bugs' ] unless check_version ( 4.4 ) [ 0 ] ret . each do | _id , o | o [ 'comments' ] . each do | c | c [ 'creation_time' ] = c [ 'time' ] unless c . include? ( 'creation_time' ) end end end ret end
1009	def save_persist_state return unless @persist_file new_persist_options = { } BaseWorker . worker_classes . each do | worker_class | worker_class . each_config ( @adapter_factory . worker_config_class ) do | config_name , ignored_extended_worker_config_class , default_options | static_options = default_options . merge ( @worker_options [ config_name ] || { } ) worker_config = self [ config_name ] hash = { } worker_config . bean_get_attributes do | attribute_info | if attribute_info . attribute [ :config_item ] && attribute_info . ancestry . size == 1 param_name = attribute_info . ancestry [ 0 ] . to_sym value = attribute_info . value hash [ param_name ] = value if static_options [ param_name ] != value end end new_persist_options [ config_name ] = hash unless hash . empty? end end if new_persist_options != @persist_options @persist_options = new_persist_options File . open ( @persist_file , 'w' ) do | out | YAML . dump ( @persist_options , out ) end end end
1010	def read_pages results_projects = database . query ( "SELECT id, identifier, name FROM projects;" ) results_projects . each do | row_project | namespaces << OpenStruct . new ( identifier : row_project [ "identifier" ] , name : row_project [ "name" ] ) end results_wikis = database . query ( "SELECT id, project_id FROM wikis;" ) results_pages = database . query ( "SELECT id, title, wiki_id FROM wiki_pages;" ) results_pages . each do | row_page | results_contents = database . query ( "SELECT * FROM wiki_content_versions WHERE page_id='#{row_page["id"]}' ORDER BY updated_on;" ) wiki_row = nil project_row = nil results_wikis . each do | wiki | wiki_row = wiki if wiki [ "id" ] == row_page [ "wiki_id" ] end if wiki_row results_projects . each do | project | project_row = project if project [ "id" ] == wiki_row [ "project_id" ] end end project_identifier = project_row ? project_row [ "identifier" ] + '/' : "" title = project_identifier + row_page [ "title" ] titles << title @latest_revisions = { } results_contents . each do | row_content | author = authors [ row_content [ "author_id" ] ] ? @authors [ row_content [ "author_id" ] ] : nil page = Page . new ( { :id => row_content [ "id" ] , :title => title , :body => row_content [ "data" ] , :markup => :textile , :latest => false , :time => row_content [ "updated_on" ] , :message => row_content [ "comments" ] , :author => author , :author_name => author . name } ) revisions << page @latest_revisions [ title ] = page end end titles . uniq! @latest_revisions . each { | rev | rev [ 1 ] . set_latest } revisions . sort! { | a , b | a . time <=> b . time } revisions end
1011	def read_response ( timeout , & block ) raise "Invalid call to read_response for #{@producer}, not setup for responding" unless @producer . response_options @producer . impl . with_response ( @adapter_info ) do | consumer | if block_given? return read_multiple_response ( consumer , timeout , & block ) else tri = read_single_response ( consumer , timeout ) if tri response = tri [ 1 ] raise response if response . kind_of? ( Qwirk :: RemoteException ) return response else @timeout = ! tri return nil end end end end
1012	def add_filter ( id , pattern , & block ) filter = LineFilter . new ( id , pattern , block ) @filters << filter end
1013	def write ( template = nil ) if not template . nil? then template = template . to_mixml_template end each_node do | node | if template . nil? then node . write_xml_to ( $stdout ) puts else puts template . evaluate ( node ) end end end
1014	def replace ( template ) template = template . to_mixml_template each_node do | node | value = template . evaluate ( node ) node . replace ( value ) end end
1015	def rename ( template ) template = template . to_mixml_template each_node do | node | value = template . evaluate ( node ) node . name = value end end
1016	def commit_revision ( page , markup ) gollum_page = gollum . page ( page . title ) if gollum_page gollum . update_page ( gollum_page , gollum_page . name , gollum_page . format , page . body , build_commit ( page ) ) else gollum . write_page ( page . title , markup , page . body , build_commit ( page ) ) end end
1017	def commit_history ( revisions , options = { } , & block ) options [ :markup ] = :markdown if ! options [ :markup ] revisions . each_with_index do | page , index | block . call ( page , index ) if block_given? commit_revision ( page , options [ :markup ] ) end end
1018	def scan_spec ( fmt_string ) until fmt_string . empty? if ( match_data = PARSE_REGEX . match ( fmt_string ) ) mid = match_data . to_s pre = match_data . pre_match @specs << FormatLiteral . new ( pre ) unless pre . empty? @specs << case when match_data [ :var ] then FormatVariable . new ( mid ) when match_data [ :set ] then FormatSet . new ( mid ) when match_data [ :rgx ] then FormatRgx . new ( mid ) when match_data [ :per ] then FormatLiteral . new ( "\%" ) else fail "Impossible case in scan_spec." end fmt_string = match_data . post_match else @specs << FormatLiteral . new ( fmt_string ) fmt_string = "" end end end
1019	def to_textile str body = body . dup body . gsub! ( / \r / , '' ) body . gsub! ( / \{ \{ \{ \n \} \} \} / , '@\1@' ) body . gsub! ( / \{ \{ \{ \n \n \} \} \} /m , '<pre><code class="\1">\2</code></pre>' ) body . gsub! ( / \{ \{ \{ \} \} \} /m , '<pre>\1</pre>' ) body . gsub! ( / \[ \[ \] \] / , '' ) body . gsub! ( / \[ \[ \] \] / , '{{toc}}' ) body . gsub! ( / \[ \[ \( \) \] \] / , '!\1!' ) body . gsub! ( / \s \s / , "h5. #{'\1'} \n\n" ) body . gsub! ( / \s \s / , "h4. #{'\1'} \n\n" ) body . gsub! ( / \s \s / , "h3. #{'\1'} \n\n" ) body . gsub! ( / \s \s / , "h2. #{'\1'} \n\n" ) body . gsub! ( / \s \s \s \n / , "h1. #{'\1'} \n\n" ) body . gsub! ( / \| \| / , "|" ) body . gsub! ( / \[ \s \[ \] \s \[ \] \] / , ' "\2":\1' ) body . gsub! ( / \[ \s \s \] / , ' [[\1 | \2]] ' ) body . gsub! ( / \/ \! / , ' \1[[\2]] ' ) body . gsub! ( / \! / , '\1' ) body . gsub! ( / / , '*\1*' ) body . gsub! ( / / , '_\1_' ) body . gsub! ( / / , '@\1@' ) body . gsub! ( / \s \s \s \* / , '***' ) body . gsub! ( / \s \s \* / , '**' ) body . gsub! ( / \s \* / , '*' ) body . gsub! ( / \s \s \s \d \. / , '###' ) body . gsub! ( / \s \s \d \. / , '##' ) body . gsub! ( / \s \d \. / , '#' ) body end
1020	def debug2 ( s , opts = { } ) out = opts . fetch ( :out , $stdout ) tag = opts . fetch ( :tag , '_DFLT_' ) really_write = opts . fetch ( :really_write , true ) write_always = opts . fetch ( :write_always , false ) raise "ERROR: ':tags' must be an array in debug(), maybe you meant to use :tag?" if ( opts [ :tags ] && opts [ :tags ] . class != Array ) final_str = "#RDeb#{write_always ? '!' : ''}[#{opts[:tag] || '-'}] #{s}" final_str = "\033[1;30m" + final_str + "\033[0m" if opts . fetch ( :coloured_debug , true ) if ( debug_tags_enabled? ) puts ( final_str ) if debug_tag_include? ( opts ) else puts ( final_str ) if ( ( really_write && $DEBUG ) || write_always ) && ! opts [ :tag ] end end
1021	def exec ( command , options = { } , & block ) raise ConnectionClosed . new ( 'Connection is closed.' ) unless @channel options = { on_non_zero_exit_code : :default } . merge ( options || { } ) options [ :on_non_zero_exit_code ] = @options [ :on_non_zero_exit_code ] if options [ :on_non_zero_exit_code ] == :default push_buffer if block_given? buffer_input ( & block ) end @channel . send_data command + "\n" wait_for_prompt if block_given? buffer_input end ret = command_output ( command ) pop_merge_buffer if @options [ :retrieve_exit_code ] push_buffer retrieve_command = 'echo $?' @channel . send_data retrieve_command + "\n" wait_for_prompt @last_exit_code = command_output ( retrieve_command ) . strip . to_i pop_discard_buffer if options [ :on_non_zero_exit_code ] == :raise_error raise NonZeroExitCode . new ( "Exit code was #{@last_exit_code}." ) unless @last_exit_code == 0 end end ret end
1022	def upload ( local_file , remote_file ) raise ConnectionClosed . new ( 'Connection is closed.' ) unless @ssh sftp . upload! ( local_file , remote_file ) end
1023	def download ( remote_file , local_file ) raise ConnectionClosed . new ( 'Connection is closed.' ) unless @ssh sftp . download! ( remote_file , local_file ) end
1024	def write_file ( remote_file , data ) raise ConnectionClosed . new ( 'Connection is closed.' ) unless @ssh sftp . file . open ( remote_file , 'w' ) do | f | f . write data end end
1025	def distance ( other ) unless other . is_a? Point raise ArgumentError . new 'other must be a Point.' end dlng = GpsUtils :: to_radians ( other . lng - @lng ) dlat = GpsUtils :: to_radians ( other . lat - @lat ) x = dlng * Math . cos ( dlat / 2 ) y = GpsUtils :: to_radians ( other . lat - @lat ) Math . sqrt ( x ** 2 + y ** 2 ) * GpsUtils :: R end
1026	def cover? ( point ) p = [ point . lat - @nw . lat , point . lng - @se . lng ] p21x = p [ 0 ] * @p21 p41x = p [ 1 ] * @p41 0 < p21x and p21x < @p21ms and 0 <= p41x and p41x <= @p41ms end
1027	def send ( method , * args , & block ) if respond_to? ( method ) super else subject . send ( method , * args , & block ) end end
1028	def output ( elapsed ) case @result when MATCH_SUCCESS color = :green header = 'OK' when MATCH_FAILURE color = :red header = 'FAIL' when MATCH_WARNING color = :light_red header = 'WARN' end header = header . ljust ( 12 ) . colorize ( color ) str_elapsed = "#{elapsed.round(2)}s" name = @name . to_s [ 0 .. 17 ] puts "#{header} #{name.ljust(20)} #{str_elapsed.ljust(9)} #{@message}" end
1029	def get_userinfo ( user ) p = { } ids = [ ] names = [ ] if user . is_a? ( Array ) user . each do | u | names << u if u . is_a? ( String ) id << u if u . is_a? ( Integer ) end elsif user . is_a? ( String ) names << user elsif user . is_a? ( Integer ) ids << user else raise ArgumentError , format ( 'Unknown type of arguments: %s' , user . class ) end result = get ( 'ids' => ids , 'names' => names ) result [ 'users' ] end
1030	def options & block options = Options . new options . instance_eval ( & block ) @options = options . to_hash end
1031	def column name , & block column = Column . new column . instance_eval ( & block ) @colspec << column . to_hash . merge ( { name : name } ) end
1032	def bulk_declare hash , & block hash . keys . each do | key | column = Column . new column . colref hash [ key ] if block column . instance_eval ( & block ) end @colspec << column . to_hash . merge ( { name : key } ) end end
1033	def read args = { } if args . class == Hash hash = @options . merge ( args ) else puts "dreader error at #{__callee__}: this function takes a Hash as input" exit end spreadsheet = Dreader :: Engine . open_spreadsheet ( hash [ :filename ] ) sheet = spreadsheet . sheet ( hash [ :sheet ] || 0 ) @table = Array . new @errors = Array . new first_row = hash [ :first_row ] || 1 last_row = hash [ :last_row ] || sheet . last_row ( first_row .. last_row ) . each do | row_number | r = Hash . new @colspec . each_with_index do | colspec , index | cell = sheet . cell ( row_number , colspec [ :colref ] ) colname = colspec [ :name ] r [ colname ] = Hash . new r [ colname ] [ :row_number ] = row_number r [ colname ] [ :col_number ] = colspec [ :colref ] begin r [ colname ] [ :value ] = value = colspec [ :process ] ? colspec [ :process ] . call ( cell ) : cell rescue => e puts "dreader error at #{__callee__}: 'process' specification for :#{colname} raised an exception at row #{row_number} (col #{index + 1}, value: #{cell})" raise e end begin if colspec [ :check ] and not colspec [ :check ] . call ( value ) then r [ colname ] [ :error ] = true @errors << "dreader error at #{__callee__}: value \"#{cell}\" for #{colname} at row #{row_number} (col #{index + 1}) does not pass the check function" else r [ colname ] [ :error ] = false end rescue => e puts "dreader error at #{__callee__}: 'check' specification for :#{colname} raised an exception at row #{row_number} (col #{index + 1}, value: #{cell})" raise e end end @table << r end @table end
1034	def backtrace_lineno_for_config ( file_path , exception ) if exception . kind_of? SyntaxError if m = / \d / . match ( exception . message ) return m [ 1 ] . to_i end end if ( exception . respond_to? ( :backtrace_locations ) && exception . backtrace_locations && exception . backtrace_locations . length > 0 ) location = exception . backtrace_locations . find do | bt | bt . path == file_path end return location ? location . lineno : nil else exception . backtrace . each do | line | if line . start_with? ( file_path ) if m = / \A \: \d \: / . match ( line ) return m [ 1 ] . to_i break end end end return nil end end
1035	def backtrace_from_config ( file_path , exception ) filtered_trace = [ ] found = false if ( exception . respond_to? ( :backtrace_locations ) && exception . backtrace_locations && exception . backtrace_locations . length > 0 ) exception . backtrace_locations . each do | location | filtered_trace << location ( found = true and break ) if location . path == file_path end else filtered_trace = [ ] exception . backtrace . each do | line | filtered_trace << line ( found = true and break ) if line . start_with? ( file_path ) end end return found ? filtered_trace : [ ] end
1036	def drain_queue ( queue ) result = [ ] queue_size = queue . size begin queue_size . times do result << queue . deq ( :raise_if_empty ) end rescue ThreadError end return result end
1037	def get_hash ( params = { } , sorted = true ) get_nodes ( sorted ) . map { | n | n . to_hash ( params [ n . name ] ) } end
1038	def get_sentence ( params = { } , sorted = true , separator = ' ' ) build_sentence_from_hash ( get_hash ( params , sorted ) ) . select ( & :present? ) . join ( separator ) end
1039	def get_nodes ( sorted = true ) SentenceBuilder :: Helper . to_boolean ( sorted ) ? @nodes . sort_by { | i | i . sort_by_value } : @nodes end
1040	def build_sentence_from_hash ( nodes ) result = [ ] nodes . each do | node | if node [ :current_value ] . nil? if node [ :always_use ] result << node [ :sentence ] end else result << node [ :sentence ] end end result end
1041	def read_pages sql = "SELECT id, tag, body, time, latest, user, note FROM wikka_pages ORDER BY time;" results = database . query ( sql ) results . each do | row | titles << row [ "tag" ] author = authors [ row [ "user" ] ] page = Page . new ( { :id => row [ "id" ] , :title => row [ "tag" ] , :body => row [ "body" ] , :markup => :wikka , :latest => row [ "latest" ] == "Y" , :time => row [ "time" ] , :message => row [ "note" ] , :author => author , :author_name => row [ "user" ] } ) revisions << page end titles . uniq! revisions end
1042	def filter ( params ) results = where ( nil ) params . each do | key , value | results = results . public_send ( key , value ) if value . present? end results end
1043	def sites response = conn . get ( "#{base_url}/site" , { } , query_headers ) body = JSON . parse ( response . body ) body . map { | b | Site . new ( b ) } rescue JSON :: ParserError fail QueryError , "Query Failed! HTTPStatus: #{response.status} - Response: #{body}" end
1044	def site_query ( * args ) response = conn . get ( url_picker ( * args ) , { } , query_headers ) if response . body [ 'SiteId' ] || response . body [ 'PointId' ] JSON . parse ( response . body ) else fail QueryError , "Query Failed! HTTPStatus: #{response.status}" end end
1045	def rate_time regexp = Regexp . new ( currency_code ) page . search ( "//span[@name='pair']" ) . each do | td | if regexp . match ( td . content ) hour = td . next_element . next_element . content return DateTime . parse ( hour ) end end end
1046	def outfile = f io = f . kind_of? ( IO ) ? f : File . new ( f , "w" ) @writer . output = io end
1047	def log msg = "" , obj = nil , level : Level :: DEBUG , classname : nil , & blk log_frames msg , obj , classname : classname , level : level , nframes : 0 , & blk end
1048	def options option_hash = { } my_labels = option_names my_inputs = option_fields my_labels . count . times do | index | option_hash [ my_labels [ index ] ] = my_inputs [ index ] end option_hash end
1049	def selected_options selected = [ ] my_labels = option_names inputs . each_with_index do | field , index | selected << my_labels [ index ] if field . checked? end selected end
1050	def transmit_packet ( packet , options = { } ) options = { cache : false } . merge ( options ) packet = packet . as_json . deep_symbolize_keys if validate_packet ( packet , options ) if options [ :cache ] == true if update_cache ( packet ) transmit packet end else transmit packet end end end
1051	def strict_ancestor_of? ( block_start ) block_start && block_start . parent && ( self == block_start . parent || strict_ancestor_of? ( block_start . parent ) ) end
1052	def built_in_object_ids @built_in_object_ids ||= Hash . new do | hash , key | hash [ key ] = where ( built_in_key : key ) . pluck ( :id ) . first end end
1053	def daemonize ( safe = true ) $stdin . reopen '/dev/null' exit if fork Process . setsid exit if fork unless safe :: Dir . chdir ( '/' ) :: File . umask ( 0000 ) end cfg_defaults = Clacks :: Configurator :: DEFAULTS cfg_defaults [ :stdout_path ] ||= "/dev/null" cfg_defaults [ :stderr_path ] ||= "/dev/null" end
1054	def reopen_io ( io , path ) io . reopen ( :: File . open ( path , "ab" ) ) if path io . sync = true end
1055	def running? ( path ) wpid = :: File . read ( path ) . to_i return if wpid <= 0 Process . kill ( 0 , wpid ) wpid rescue Errno :: EPERM , Errno :: ESRCH , Errno :: ENOENT end
1056	def write_pid ( pid ) :: File . open ( pid , 'w' ) { | f | f . write ( "#{Process.pid}" ) } at_exit { :: File . delete ( pid ) if :: File . exist? ( pid ) rescue nil } end
1057	def parse_mead ( * args ) parts = @mead . split ( '-' ) args . each_with_index do | field , i | instance_variable_set ( '@' + field , parts [ i ] ) end end
1058	def load ( * file_names ) file_names . flatten . each do | file_name | xml = File . open ( file_name , 'r' ) do | file | Nokogiri :: XML ( file ) do | config | if @pretty then config . default_xml . noblanks end end end @documents << Document . new ( file_name , xml ) end end
1059	def save_all output_all do | document , options | File . open ( document . name , 'w' ) do | file | document . xml . write_xml_to ( file , options ) end end end
1060	def print_all output_all do | document , options | if @documents . size > 1 then puts '-' * document . name . length puts document . name puts '-' * document . name . length end puts document . xml . to_xml ( options ) end end
1061	def work ( * file_names , & block ) remove_all file_names . each do | file_name | load ( file_name ) if not block . nil? then execute ( & block ) end flush remove_all end end
1062	def xpath ( * paths , & block ) nodesets = [ ] process do | xml | nodesets << xml . xpath ( * paths ) end selection = Selection . new ( nodesets ) if block_given? then Docile . dsl_eval ( selection , & block ) end selection end
1063	def css ( * selectors , & block ) nodesets = [ ] process do | xml | nodesets << xml . css ( * selectors ) end selection = Selection . new ( nodesets ) if block_given? then Docile . dsl_eval ( selection , & block ) end selection end
1064	def execute ( program = nil , & block ) if not program . nil? then instance_eval ( program ) end if not block . nil? then Docile . dsl_eval ( self , & block ) end end
1065	def with_nodes ( selection ) selection . nodesets . each do | nodeset | nodeset . each do | node | yield node end end end
1066	def tagify input output = input . dup raise StandardError , "@tags is empty!" if @tags . empty? @tags . each { | key , value | output . gsub! ( tag_start . to_s + key . to_s + tag_end . to_s , value . to_s ) } return output end
1067	def option_group ( * args ) selector = if args . first . respond_to? ( :elements ) args . first else extract_selector ( args ) end OptionGroup . new ( self , selector ) end
1068	def execute ( args ) target_file = @config_file . nil? ? "caramel.rb" : @config_file FileUtils . cp ( File . dirname ( __FILE__ ) + "/../caramel.rb" , target_file ) if commandparser . verbosity == :normal puts "Created new configuration file: #{target_file}" end end
1069	def has_machete_workflow_of ( jobs_active_record_relation_symbol ) cattr_accessor :jobs_active_record_relation_symbol self . jobs_active_record_relation_symbol = jobs_active_record_relation_symbol self . send :include , OscMacheteRails :: Workflow :: JobsRelation self . send :include , OscMacheteRails :: Workflow :: BuilderMethods self . send :include , OscMacheteRails :: Workflow :: StatusMethods end
1070	def check_retry if @finished_publishing && @pending_hash . empty? && @exception_count > 0 && ( @retry || @auto_retry ) return if ! @retry && @auto_retry && @exception_count == @exceptions_per_run . last Qwirk . logger . info "#{self}: Retrying exception records, exception count = #{@exception_count}" @exceptions_per_run << @exception_count @exception_count = 0 @finished_publishing = false @fail_thread = Thread . new ( @exceptions_per_run . last ) do | count | begin java . lang . Thread . current_thread . name = "Qwirk fail task: #{task_id}" while ! @stopped && ( count > 0 ) && ( object = @fail_consumer . receive ) count -= 1 publish ( object ) @fail_consumer . acknowledge_message end @finished_publishing = true @pending_hash_mutex . synchronize { check_finish } rescue Exception => e do_stop Qwirk . logger . error "#{self}: Exception, thread terminating: #{e.message}\n\t#{e.backtrace.join("\n\t")}" end end end end
1071	def run program :name , 'mixml' program :version , Mixml :: VERSION program :description , 'XML helper tool' $tool = Mixml :: Tool . new global_option ( '-p' , '--pretty' , 'Pretty print output' ) do | value | $tool . pretty = value end global_option ( '-i' , '--inplace' , 'Replace the processed files with the new files' ) do | value | $tool . save = value $tool . print = ! value end global_option ( '-q' , '--quiet' , 'Do not print nodes' ) do | value | $tool . print = ! value end command :pretty do | c | c . description = 'Pretty print XML files' c . action do | args , options | $tool . pretty = true $tool . work ( args ) end end modify_command :write do | c | c . description = 'Write selected nodes to the console' c . suppress_output = true c . optional_expression = true end select_command :remove do | c | c . description = 'Remove nodes from the XML documents' end modify_command :replace do | c | c . description = 'Replace nodes in the XML documents' end modify_command :append do | c | c . description = 'Append child nodes in the XML documents' end modify_command :rename do | c | c . description = 'Rename nodes in the XML documents' end modify_command :value do | c | c . description = 'Set node values' end command :execute do | c | c . description = 'Execute script on the XML documents' c . option '-s' , '--script STRING' , String , 'Script file to execute' c . option '-e' , '--expression STRING' , String , 'Command to execute' c . action do | args , options | script = options . expression || File . read ( options . script ) $tool . work ( args ) do execute ( script ) end end end run! end
1072	def list entities = @db . list out entities = entities . is_a? ( Fixnum ) ? @db . list [ 0 ... entities ] : entities entities . reject { | e | e [ :status ] == :removed } . each_with_index do | e , i | out " [#{i}]" . blue + "#{e.sticky?? " + ".bold : " "}" + e [ :title ] . underline + " #{e[:tags].join(' ')}" . cyan end . tap do | list | out " ..." if @db . list . length > entities . length && ! entities . length . zero? out " there are no koi in the water" . green if list . size . zero? end out entities end
1073	def method_missing meth , * args , & blk if meth . to_s . end_with? ( '?' ) && Status . include? ( s = meth . to_s . chop . to_sym ) self [ :status ] == s else super end end
1074	def v3_get ( path , options = { } ) get_params = { :method => "get" } get_params [ :params ] = options unless options . empty? v3_do_request ( get_params , path , :cache => true ) end
1075	def v3_put ( path , options = { } ) expire_matching "#{parent_path(path)}.*" put_params = { :method => "put" , :body => options [ :body ] ? options [ :body ] : form_encode ( options ) } if options [ :content_type ] put_params [ :headers ] = { :' ' => content_type ( options [ :content_type ] ) } end v3_do_request ( put_params , path ) end
1076	def v3_do_request ( params , path , options = { } ) req = Typhoeus :: Request . new ( "https://#{v3_hostname}#{path}" , v3_defaults . merge ( params ) ) response = do_request ( req , :xml , options ) options [ :return_obj ] == true ? response : response . body end
1077	def add ( token , timestamp = nil ) @net . call_callbacks ( :place , :add , Event . new ( @name , [ token ] , @net ) ) unless @net . nil? if timestamp . nil? @marking . add token else @marking . add token , timestamp end end
1078	def authorize client_id = Google :: Auth :: ClientId . from_file ( CLIENT_SECRETS_PATH ) token_store = Google :: Auth :: Stores :: FileTokenStore . new ( file : CREDENTIALS_PATH ) authorizer = Google :: Auth :: UserAuthorizer . new ( client_id , SCOPE , token_store ) user_id = 'default' credentials = authorizer . get_credentials ( user_id ) if credentials . nil? url = authorizer . get_authorization_url ( base_url : OOB_URI ) puts 'Open the following URL in the browser and enter the ' "resulting code after authorization:\n" + url code = STDIN . gets credentials = authorizer . get_and_store_credentials_from_code ( user_id : user_id , code : code , base_url : OOB_URI ) end credentials end
1079	def get ( path , data = { } ) format = data . delete ( :format ) || @format get_params = { :method => "get" , :verbose => DEBUG } get_params [ :params ] = data unless data . empty? get = Typhoeus :: Request . new ( "#{protocol}#{@server}#{path}" , get_params ) do_request ( get , format , :cache => true ) end
1080	def post ( path , data = { } ) format = data . delete ( :format ) || @format expire_matching "#{raw_path(path)}.*" query_params = { } query_params [ :returnUnit ] = data . delete ( :returnUnit ) if data [ :returnUnit ] query_params [ :returnPerUnit ] = data . delete ( :returnPerUnit ) if data [ :returnPerUnit ] post_params = { :verbose => DEBUG , :method => "post" , :body => form_encode ( data ) } post_params [ :params ] = query_params unless query_params . empty? post = Typhoeus :: Request . new ( "#{protocol}#{@server}#{path}" , post_params ) do_request ( post , format ) end
1081	def raw_post ( path , body , options = { } ) format = options . delete ( :format ) || @format expire_matching "#{raw_path(path)}.*" post = Typhoeus :: Request . new ( "#{protocol}#{@server}#{path}" , :verbose => DEBUG , :method => "post" , :body => body , :headers => { :' ' => options [ :content_type ] || content_type ( format ) } ) do_request ( post , format ) end
1082	def put ( path , data = { } ) format = data . delete ( :format ) || @format expire_matching "#{parent_path(path)}.*" query_params = { } query_params [ :returnUnit ] = data . delete ( :returnUnit ) if data [ :returnUnit ] query_params [ :returnPerUnit ] = data . delete ( :returnPerUnit ) if data [ :returnPerUnit ] put_params = { :verbose => DEBUG , :method => "put" , :body => form_encode ( data ) } put_params [ :params ] = query_params unless query_params . empty? put = Typhoeus :: Request . new ( "#{protocol}#{@server}#{path}" , put_params ) do_request ( put , format ) end
1083	def raw_put ( path , body , options = { } ) format = options . delete ( :format ) || @format expire_matching "#{parent_path(path)}.*" put = Typhoeus :: Request . new ( "#{protocol}#{@server}#{path}" , :verbose => DEBUG , :method => "put" , :body => body , :headers => { :' ' => options [ :content_type ] || content_type ( format ) } ) do_request ( put , format ) end
1084	def authenticate request = Typhoeus :: Request . new ( "#{protocol}#{@server}/auth/signIn" , :method => "post" , :verbose => DEBUG , :headers => { :Accept => content_type ( :xml ) , } , :body => form_encode ( :username => @username , :password => @password ) ) hydra . queue ( request ) hydra . run response = request . response @auth_token = response . headers_hash [ 'AuthToken' ] d { request . url } d { response . code } d { @auth_token } connection_failed if response . code == 0 unless authenticated? raise AMEE :: AuthFailed . new ( "Authentication failed. Please check your username and password. (tried #{@username},#{@password})" ) end if response . body . is_json? @version = JSON . parse ( response . body ) [ "user" ] [ "apiVersion" ] . to_f elsif response . body . is_xml? @version = REXML :: Document . new ( response . body ) . elements [ 'Resources' ] . elements [ 'SignInResource' ] . elements [ 'User' ] . elements [ 'ApiVersion' ] . text . to_f else @version = 1.0 end end
1085	def response_ok? ( response , request ) d { request . object_id } d { request } d { response . object_id } d { response . code } d { response . headers_hash } d { response . body } case response . code . to_i when 502 , 503 , 504 raise AMEE :: ConnectionFailed . new ( "A connection error occurred while talking to AMEE: HTTP response code #{response.code}.\nRequest: #{request.method.upcase} #{request.url.gsub(request.host, '')}" ) when 408 raise AMEE :: TimeOut . new ( "Request timed out." ) when 404 raise AMEE :: NotFound . new ( "The URL was not found on the server.\nRequest: #{request.method.upcase} #{request.url.gsub(request.host, '')}" ) when 403 raise AMEE :: PermissionDenied . new ( "You do not have permission to perform the requested operation.\nRequest: #{request.method.upcase} #{request.url.gsub(request.host, '')}\n#{request.body}\Response: #{response.body}" ) when 401 authenticate return false when 400 if response . body . include? "would have resulted in a duplicate resource being created" raise AMEE :: DuplicateResource . new ( "The specified resource already exists. This is most often caused by creating an item that overlaps another in time.\nRequest: #{request.method.upcase} #{request.url.gsub(request.host, '')}\n#{request.body}\Response: #{response.body}" ) else raise AMEE :: BadRequest . new ( "Bad request. This is probably due to malformed input data.\nRequest: #{request.method.upcase} #{request.url.gsub(request.host, '')}\n#{request.body}\Response: #{response.body}" ) end when 200 , 201 , 204 return response when 0 connection_failed end raise AMEE :: UnknownError . new ( "An error occurred while talking to AMEE: HTTP response code #{response.code}.\nRequest: #{request.method.upcase} #{request.url}\n#{request.body}\Response: #{response.body}" ) end
1086	def do_request ( request , format = @format , options = { } ) v3_request = request . url . include? ( "/#{v3_hostname}/" ) if ! @auth_token && ! v3_request d "Authenticating first before we hit #{request.url}" authenticate end request . headers [ 'Accept' ] = content_type ( format ) request . headers [ 'X-AMEE-Source' ] = @amee_source if @amee_source path_and_query = '/' + request . url . split ( '/' , 4 ) [ 3 ] if options [ :cache ] response = cache ( path_and_query ) { run_request ( request , :xml ) } else response = run_request ( request , :xml ) end response end
1087	def run_request ( request , format ) v3_request = request . url . include? ( "/#{v3_hostname}/" ) retries = [ 1 ] * @retries begin begin d "Queuing the request for #{request.url}" add_authentication_to ( request ) if @auth_token && ! v3_request hydra . queue request hydra . run end while ! response_ok? ( request . response , request ) @auth_token = request . response . headers_hash [ 'AuthToken' ] return request . response rescue AMEE :: ConnectionFailed , AMEE :: TimeOut => e if delay = retries . shift sleep delay retry else raise end end end
1088	def timed_place ( name , keys = { } ) place = create_or_find_place ( name , keys , TimedPlace ) @timed_places [ place ] = true place end
1089	def transition ( name ) t = find_transition name if t . nil? t = Transition . new name , self @transitions << t end t end
1090	def sim @stopped = catch :stop_simulation do begin fired = fire_transitions advanced = move_clock_to find_next_time end while fired || advanced end @stopped = false if @stopped == nil rescue StandardError => e raise SimulationError . new ( e ) end
1091	def output ( place , & block ) raise "This is not a Place object!" unless place . kind_of? Place raise "Tried to define output arc without expression! Block is required!" unless block_given? @outputs << OutputArc . new ( place , block ) end
1092	def fire ( clock = 0 ) mapping = Enumerator . new do | y | get_sentry . call ( input_markings , clock , y ) end . first return false if mapping . nil? tcpn_binding = TCPNBinding . new mapping , input_markings call_callbacks :before , Event . new ( @name , tcpn_binding , clock , @net ) tokens_for_outputs = @outputs . map do | o | o . block . call ( tcpn_binding , clock ) end mapping . each do | place_name , token | unless token . kind_of? Token t = if token . instance_of? Array token else [ token ] end t . each do | t | unless t . kind_of? Token raise InvalidToken . new ( "#{t.inspect} put by sentry for transition `#{name}` in binding for `#{place_name}`" ) end end end deleted = find_input ( place_name ) . delete ( token ) if deleted . nil? raise InvalidToken . new ( "#{token.inspect} put by sentry for transition `#{name}` does not exists in `#{place_name}`" ) end end @outputs . each do | o | token = tokens_for_outputs . shift o . place . add token unless token . nil? end call_callbacks :after , Event . new ( @name , mapping , clock , @net ) true rescue InvalidToken raise rescue RuntimeError => e raise FiringError . new ( self , e ) end
1093	def send_request ( text ) begin request = Net :: HTTP :: Post . new ( @url . path , { 'Content-Type' => 'text/xml' , 'SOAPAction' => '"http://typograf.artlebedev.ru/webservices/ProcessText"' } ) request . body = form_xml ( text , @options ) response = Net :: HTTP . new ( @url . host , @url . port ) . start do | http | http . request ( request ) end rescue StandardError => exception raise NetworkError . new ( exception . message , exception . backtrace ) end if ! response . is_a? ( Net :: HTTPOK ) raise NetworkError , "#{response.code}: #{response.message}" end if RESULT =~ response . body body = $1 . gsub ( / / , '>' ) . gsub ( / / , '<' ) . gsub ( / / , '&' ) body . force_encoding ( "UTF-8" ) . chomp else raise NetworkError , "Can't match result #{response.body}" end end
1094	def install_librarian ( opts = { } ) librarian_version = opts [ :librarian_version ] ||= nil hosts . each do | host | install_package host , 'rubygems' install_package host , 'git' if librarian_version on host , "gem install --no-ri --no-rdoc librarian-puppet -v '#{librarian_version}'" else on host , 'gem install --no-ri --no-rdoc librarian-puppet' end end end
1095	def librarian_install_modules ( directory , module_name ) hosts . each do | host | sut_dir = File . join ( '/tmp' , module_name ) scp_to host , directory , sut_dir on host , "cd #{sut_dir} && librarian-puppet install --clean --verbose --path #{host['distmoduledir']}" puppet_module_install ( :source => directory , :module_name => module_name ) end end
1096	def get_crisis ( identifier , params = nil ) return nil if identifier . nil? or identifier . empty? endpoint = "/v1/crises/#{identifier}.json?auth_token=#{@auth_token}" endpoint += "&#{URI.encode_www_form params}" if params response = self . get ( endpoint ) Sigimera :: Crisis . new JSON . parse response . body if response and response . body end
1097	def get_crises_stat response = self . get ( "/v1/stats/crises.json?auth_token=#{@auth_token}" ) JSON . parse response . body if response and response . body end
1098	def get_user_stat response = self . get ( "/v1/stats/users.json?auth_token=#{@auth_token}" ) JSON . parse response . body if response and response . body end
1099	def posify * source_methods , & block include ModelClassAdditions self . pose_content = proc do text_chunks = source_methods . map { | source | send ( source ) } text_chunks << instance_eval ( & block ) if block text_chunks . reject ( & :blank? ) . join ( ' ' ) end end
1100	def add ( objects ) unless objects . kind_of? Array objects = [ objects ] end objects . each do | object | value = object if object . instance_of? Hash value = object [ :val ] end add_token prepare_token ( value ) end end
1101	def delete ( tokens ) unless tokens . instance_of? Array tokens = [ tokens ] end removed = tokens . map do | token | validate_token! ( token ) delete_token ( token ) end if removed . size == 1 removed . first else removed end end
1102	def add_joins arel @query . joins . inject ( arel ) do | memo , join_data | add_join memo , join_data end end
1103	def add_wheres arel @query . where . inject ( arel ) { | memo , where | memo . where where } end
1104	def load_classes result return if @query . ids_requested? result . each do | clazz , ids | if ids . size > 0 result [ clazz ] = clazz . where ( id : ids ) if @query . has_select result [ clazz ] = result [ clazz ] . select ( @query . options [ :select ] ) end end end end
1105	def search_word word empty_result . tap do | result | data = Assignment . joins ( :word ) . select ( 'pose_assignments.posable_id, pose_assignments.posable_type' ) . where ( 'pose_words.text LIKE ?' , "#{word}%" ) . where ( 'pose_assignments.posable_type IN (?)' , @query . class_names ) data = add_joins data data = add_wheres data Assignment . connection . select_all ( data . to_sql ) . each do | pose_assignment | result [ pose_assignment [ 'posable_type' ] ] << pose_assignment [ 'posable_id' ] . to_i end end end
1106	def search_words { } . tap do | result | @query . query_words . each do | query_word | search_word ( query_word ) . each do | class_name , ids | merge_search_result_word_matches result , class_name , ids end end end end
1107	def client_login_authorization_header ( http_method , uri ) if @user && @password && ! @auth_token email = CGI . escape ( @user ) password = CGI . escape ( @password ) http = Net :: HTTP . new ( 'www.google.com' , 443 ) http . use_ssl = true http . verify_mode = OpenSSL :: SSL :: VERIFY_NONE resp , data = http . post ( '/accounts/ClientLogin' , "accountType=HOSTED_OR_GOOGLE&Email=#{email}&Passwd=#{password}&service=wise" , { 'Content-Type' => 'application/x-www-form-urlencoded' } ) handle_response ( resp ) @auth_token = ( data || resp . body ) [ / /n , 1 ] end @auth_token ? { 'Authorization' => "GoogleLogin auth=#{@auth_token}" } : { } end
1108	def app_folder ( app_name = self . current_app ) if self . type == :multi if app_name . in? self . main_apps "#{self.folder}/main_apps/#{app_name}" elsif app_name . in? self . engines "#{self.folder}/engines/#{app_name}" end elsif self . type == :single self . folder end end
1109	def app_version_file ( app_name = self . current_app ) Dir . glob ( "#{app_folder(app_name)}/lib/**/version.rb" ) . min_by do | filename | filename . chars . count end end
1110	def app_version ( app_name = self . current_app ) if File . exists? app_version_file ( app_name ) . to_s File . read ( app_version_file ( app_name ) ) . match ( / \. \n / ) . try ( :captures ) . try ( :first ) else ` ` . split ( "\n" ) . first end end
1111	def bump_app_version_to ( version ) if File . exists? self . app_version_file version_file = self . app_version_file version_content = File . read ( "#{version_file}" ) File . open ( version_file , 'w+' ) do | f | f . puts version_content . gsub ( / \. \n / , "VERSION = '#{version}'\n" ) end end end
1112	def load_project config_file = Dir . glob ( "#{Dir.pwd}/**/dev.yml" ) . first raise ExecutionError . new "No valid configuration files found. Searched for a file named 'dev.yml' " "in folder #{Dir.pwd} and all its subdirectories." if config_file . nil? @project = Dev :: Project . new ( config_file ) end
1113	def help puts print "Dev" . green print " - available commands:\n" puts print "\tversion\t\t" . limegreen print "Prints current version.\n" puts print "\tfeature\t\t" . limegreen print "Opens or closes a feature for the current app.\n" print "\t\t\tWarning: the app is determined from the current working directory!\n" print "\t\t\tExample: " print "dev feature open my-new-feature" . springgreen print " (opens a new feature for the current app)" print ".\n" print "\t\t\tExample: " print "dev feature close my-new-feature" . springgreen print " (closes a developed new feature for the current app)" print ".\n" puts print "\thotfix\t\t" . limegreen print "Opens or closes a hotfix for the current app.\n" print "\t\t\tWarning: the app is determined from the current working directory!\n" print "\t\t\tExample: " print "dev hotfix open 0.2.1" . springgreen print " (opens a new hotfix for the current app)" print ".\n" print "\t\t\tExample: " print "dev hotfix close 0.2.1" . springgreen print " (closes a developed new hotfix for the current app)" print ".\n" puts print "\trelease\t\t" . limegreen print "Opens or closes a release for the current app.\n" print "\t\t\tWarning: the app is determined from the current working directory!\n" print "\t\t\tExample: " print "dev release open 0.2.0" . springgreen print " (opens a new release for the current app)" print ".\n" print "\t\t\tExample: " print "dev release close 0.2.0" . springgreen print " (closes a developed new release for the current app)" print ".\n" puts print "\tpull\t\t" . limegreen print "Pulls specified app's git repository, or pulls all apps if none are specified.\n" print "\t\t\tWarning: the pulled branch is the one the app is currently on!\n" print "\t\t\tExample: " print "dev pull [myapp]" . springgreen print ".\n" puts print "\tpush\t\t" . limegreen print "Commits and pushes the specified app.\n" print "\t\t\tWarning: the pushed branch is the one the app is currently on!\n" print "\t\t\tExample: " print "dev push myapp \"commit message\"" . springgreen print ".\n" puts print "\ttest\t\t" . limegreen print "Runs the app's test suite. Tests must be written with rspec.\n" print "\t\t\tIt is possibile to specify which app's test suite to run.\n" print "\t\t\tIf nothing is specified, all main app's test suites are run.\n" print "\t\t\tExample: " print "dev test mymainapp myengine" . springgreen print " (runs tests for 'mymainapp' and 'myengine')" print ".\n" print "\t\t\tExample: " print "dev test" . springgreen print " (runs tests for all main apps and engines within this project)" print ".\n" puts end
1114	def add ( objects , timestamp = @time ) unless objects . kind_of? Array objects = [ objects ] end objects . each do | object | if object . instance_of? Hash timestamp = object [ :ts ] || 0 object = object [ :val ] end token = prepare_token ( object , timestamp ) timestamp = token . timestamp if timestamp > @time add_to_waiting token else add_token token end end end
1115	def time = ( time ) if time < @time raise InvalidTime . new ( "You are trying to put back clock from #{@time} back to #{time}" ) end @time = time @waiting . keys . sort . each do | timestamp | if timestamp > @time @next_time = timestamp break end @waiting [ timestamp ] . each { | token | add_token token } @waiting . delete timestamp end @next_time = 0 if @waiting . empty? @time end
1116	def send_message data , binary = false if established? unless @closing @socket . send_data ( @encoder . encode ( data . to_s , binary ? BINARY_FRAME : TEXT_FRAME ) ) end else raise WebSocketError . new "can't send on a closed channel" end end
1117	def post ( options ) uri = new_uri params = merge_params ( options ) response = Net :: HTTP . post_form ( uri , params ) unless response . is_a? ( Net :: HTTPSuccess ) raise "#{response.code} #{response.message}\n#{response.body}" end response . body end
1118	def delete ( options = { } ) uri = new_uri params = merge_params ( options ) uri . query = URI . encode_www_form ( params ) http = Net :: HTTP . new ( uri . host , uri . port ) request = Net :: HTTP :: Delete . new ( uri ) response = http . request ( request ) unless response . is_a? ( Net :: HTTPSuccess ) raise "#{response.code} #{response.message}\n#{response.body}" end true end
1119	def instance_metadata ( name ) instance = instance ( name ) config = { } if instance . configured? config = instance . configfile_hash config [ "ensure" ] = :present else config [ "ensure" ] = :absent end config [ "name" ] = name config end
1120	def instances_metadata ( ) instance_wildcard = File . join ( @vagrant_vm_dir , "*" , :: Vagrantomatic :: Instance :: VAGRANTFILE ) instances = { } Dir . glob ( instance_wildcard ) . each { | f | elements = f . split ( File :: SEPARATOR ) name = elements [ elements . size - 2 ] instances [ name ] = instance_metadata ( name ) } instances end
1121	def csv_read ( path ) lines = begin if path =~ / \. / Zlib :: GzipReader . open ( path ) do | f | CSV . new ( f ) . read end else CSV . read ( path ) end end keys = lines . shift . map ( & :to_sym ) klass = Struct . new ( * keys ) lines . map { | i | klass . new ( * i ) } end
1122	def csv_write ( path , rows , cols : nil ) atomic_write ( path ) do | tmp | CSV . open ( tmp . path , "wb" ) { | f | csv_write0 ( f , rows , cols : cols ) } end end
1123	def csv_to_s ( rows , cols : nil ) string = "" f = CSV . new ( StringIO . new ( string ) ) csv_write0 ( f , rows , cols : cols ) string end
1124	def add_value ( name , type , subtype = nil ) if type . class == RustyJson :: RustStruct || subtype . class == RustyJson :: RustStruct if type . class == RustyJson :: RustStruct t = type type = type . name struct = t elsif subtype . class == RustyJson :: RustStruct s = subtype subtype = subtype . name struct = s end @structs << struct RustStruct . add_type ( struct . name , struct . name ) end @values [ name ] = [ type , subtype ] true end
1125	def rotate ( hsh ) current_ec2 , new_ec2 = hsh . first cur_instances = EC2 . by_tags ( "Name" => current_ec2 . to_s ) new_instances = EC2 . by_tags ( "Name" => new_ec2 . to_s ) register_and_wait new_instances deregister cur_instances end
1126	def wait_for_state ( instances , exp_state ) time = 0 all_good = false loop do all_good = instances . all? do | i | state = i . elb_health [ :state ] puts "#{i.id}: #{state}" exp_state == state end break if all_good || time > timeout sleep 1 time += 1 end unless all_good raise "Instances are out of service" end end
1127	def read ( path ) owconnect do | socket | owwrite ( socket , :path => path , :function => READ ) return to_number ( owread ( socket ) . data ) end end
1128	def write ( path , value ) owconnect do | socket | owwrite ( socket , :path => path , :value => value . to_s , :function => WRITE ) return owread ( socket ) . return_value end end
1129	def dir ( path ) owconnect do | socket | owwrite ( socket , :path => path , :function => DIR ) fields = [ ] while true response = owread ( socket ) if response . data fields << response . data else break end end return fields end end
1130	def sum_totals_by_model @sum_totals_by_model ||= begin totals = Hash . new { | hash , key | hash [ key ] = Hash . new ( 0 ) } @queries_by_model . each do | model , queries | totals [ model ] [ :query_count ] = queries . length queries . each do | query | query . statistics . each do | stat , value | totals [ model ] [ stat ] += value end end totals [ model ] [ :datastore_interaction_time ] = totals [ model ] [ :datastore_interaction_time ] end totals end end
1131	def sum_totals @sum_totals ||= begin totals = Hash . new ( 0 ) sum_totals_by_model . each do | _ , model_totals | model_totals . each do | stat , value | totals [ stat ] += value end end totals end end
1132	def to_label s = '%016x%08x' sec = tai_second ts = if sec >= 0 sec + EPOCH else EPOCH - sec end Label . new s % [ ts , tai_nanosecond ] end
1133	def put ( name , object ) raise "This ObjectContext already has an instance or configuration for '#{name.to_s}'" if directly_has? ( name ) Conject . install_object_context ( object , self ) object . instance_variable_set ( :@_conject_contextual_name , name . to_s ) @cache [ name . to_sym ] = object end
1134	def configure_objects ( confs = { } ) confs . each do | key , opts | key = key . to_sym @object_configs [ key ] = { } unless has_config? ( key ) @object_configs [ key ] . merge! ( opts ) end end
1135	def httperf warm_up = false httperf_cmd = build_httperf_cmd if warm_up status "\n#{httperf_cmd} (warm up run)" IO . popen ( "#{httperf_cmd} 2>&1" ) else IO . popen ( "#{httperf_cmd} 2>&1" ) do | pipe | status "\n#{httperf_cmd}" @results << ( httperf_result = HttperfResult . new ( { :rate => @current_rate , :server => @current_job . server , :port => @current_job . port , :uri => @current_job . uri , :num_conns => @current_job . num_conns , :description => @current_job . description } ) ) HttperfResultParser . new ( pipe ) . parse ( httperf_result ) end end end
1136	def url ( path , params = { } ) params = params . inject ( { } , & @@stringify ) path = path . gsub ( @@placeholder ) { params . delete ( $1 , & @@required ) } params = params . inject ( '' , & @@parameterize ) [ path , params ] . reject ( & :nil? ) . reject ( & :empty? ) . join ( '?' ) end
1137	def url? ( string ) return false unless string . to_s =~ url_pattern return false if string . to_s =~ @@placeholder true end
1138	def assit_equal ( expected , actual , message = "Object expected to be equal" ) if ( expected != actual ) message << " expected #{expected} but was #{actual}" assit ( false , message ) end end
1139	def assit_kind_of ( klass , object , message = "Object of wrong type" ) if ( ! object . kind_of? ( klass ) ) message << " (Expected #{klass} but was #{object.class})" assit ( false , message ) end end
1140	def assit_real_string ( object , message = "Not a non-empty string." ) unless ( object && object . kind_of? ( String ) && object . strip != "" ) assit ( false , message ) end end
1141	def assit_block ( & block ) errors = [ ] assit ( ( block . call ( errors ) && errors . size == 0 ) , errors . join ( ', ' ) ) end
1142	def poll interval : 10 , & block raise '#poll requires a block' unless block_given? response_id = 0 loop do res = self . sync response_id if res response_id = res [ 'rid' ] yield res end sleep interval end end
1143	def sync response_id = 0 req = self . class . get '/sync/maindata' , format : :json , query : { rid : response_id } res = req . parsed_response if req . success? return res end end
1144	def add_trackers torrent_hash , urls urls = Array ( urls ) urls = urls . map { | url | url . gsub ( '&' , '%26' ) } urls = urls . join ( '%0A' ) options = { body : "hash=#{torrent_hash}&urls=#{urls}" } self . class . post ( '/command/addTrackers' , options ) end
1145	def download urls urls = Array ( urls ) urls = urls . join ( '%0A' ) options = { body : "urls=#{urls}" } self . class . post ( '/command/download' , options ) end
1146	def delete_torrent_and_data torrent_hashes torrent_hashes = Array ( torrent_hashes ) torrent_hashes = torrent_hashes . join ( '|' ) options = { body : "hashes=#{torrent_hashes}" } self . class . post ( '/command/deletePerm' , options ) end
1147	def set_location ( torrent_hashes , path ) torrent_hashes = Array ( torrent_hashes ) torrent_hashes = torrent_hashes . join ( '|' ) options = { body : { "hashes" => torrent_hashes , "location" => path } , } self . class . post ( '/command/setLocation' , options ) end
1148	def increase_priority torrent_hashes torrent_hashes = Array ( torrent_hashes ) torrent_hashes = torrent_hashes . join ( '|' ) options = { body : "hashes=#{torrent_hashes}" } self . class . post ( '/command/increasePrio' , options ) end
1149	def decrease_priority torrent_hashes torrent_hashes = Array ( torrent_hashes ) torrent_hashes = torrent_hashes . join ( '|' ) options = { body : "hashes=#{torrent_hashes}" } self . class . post ( '/command/decreasePrio' , options ) end
1150	def maximize_priority torrent_hashes torrent_hashes = Array ( torrent_hashes ) torrent_hashes = torrent_hashes . join ( '|' ) options = { body : "hashes=#{torrent_hashes}" } self . class . post ( '/command/topPrio' , options ) end
1151	def minimize_priority torrent_hashes torrent_hashes = Array ( torrent_hashes ) torrent_hashes = torrent_hashes . join ( '|' ) options = { body : "hashes=#{torrent_hashes}" } self . class . post ( '/command/bottomPrio' , options ) end
1152	def set_file_priority torrent_hash , file_id , priority query = [ "hash=#{torrent_hash}" , "id=#{file_id}" , "priority=#{priority}" ] options = { body : query . join ( '&' ) } self . class . post ( '/command/setFilePrio' , options ) end
1153	def set_download_limit torrent_hash , limit query = [ "hashes=#{torrent_hash}" , "limit=#{limit}" ] options = { body : query . join ( '&' ) } self . class . post ( '/command/setTorrentsDlLimit' , options ) end
1154	def set_upload_limit torrent_hash , limit query = [ "hashes=#{torrent_hash}" , "limit=#{limit}" ] options = { body : query . join ( '&' ) } self . class . post ( '/command/setTorrentsUpLimit' , options ) end
1155	def md5_file ( path ) File . open ( path ) do | f | digest , buf = Digest :: MD5 . new , "" while f . read ( 4096 , buf ) digest . update ( buf ) end digest . hexdigest end end
1156	def keys ( * a ) if block_given? bucket . keys ( * a ) do | keys | if keys . kind_of? Array keys . each do | key | yield key end else yield keys end end else bucket . keys ( * a ) end end
1157	def each bucket . keys do | keys | keys . each do | key | if x = self [ key ] yield x end end end end
1158	def run ( command , args = nil ) cmd = CommandLine . new ( command , args ) vputs ( cmd ) cmd . run end
1159	def clicks ( options = { } ) options = update_by_expire_time options if clicks_not_latest? ( options ) @rsqoot_clicks = get ( 'clicks' , options , SqootClick ) @rsqoot_clicks = @rsqoot_clicks . clicks if @rsqoot_clicks @rsqoot_clicks = @rsqoot_clicks . clicks . map ( & :click ) if @rsqoot_clicks . clicks end logger ( uri : sqoot_query_uri , records : @rsqoot_clicks , type : 'clicks' , opts : options ) @rsqoot_clicks end
1160	def build_instances ( template = nil ) build_args = if template == :template [ build_options . first . merge ( count : 1 ) ] else build_options end build_args . map do | args | instances = create_instance args apply_tags ( instances ) instances end . flatten end
1161	def scope ( scope_name , scope_enum_keys ) target_enum = @record_class . defined_enums [ @enum_name . to_s ] sub_enum_values = target_enum . values_at ( * scope_enum_keys ) if @record_class . defined_enum_scopes . has_key? ( scope_name ) fail ArgumentError , "Conflicting scope names. A scope named #{scope_name} has already been defined" elsif sub_enum_values . include? ( nil ) unknown_key = scope_enum_keys [ sub_enum_values . index ( nil ) ] fail ArgumentError , "Unknown key - #{unknown_key} for enum #{@enum_name}" elsif @record_class . respond_to? ( scope_name . to_s . pluralize ) fail ArgumentError , "Scope name - #{scope_name} conflicts with a class method of the same name" elsif @record_class . instance_methods . include? ( "#{scope_name}?" . to_sym ) fail ArgumentError , "Scope name - #{scope_name} conflicts with the instance method - #{scope_name}?" end sub_enum_entries = target_enum . slice ( * scope_enum_keys ) @record_class . defined_enum_scopes [ scope_name ] = sub_enum_entries @record_class . send ( :define_method , "#{scope_name}?" ) { sub_enum_entries . include? self . role } @record_class . scope scope_name . to_s . pluralize , -> { @record_class . where ( "#{@enum_name}" => sub_enum_entries . values ) } @scope_names << scope_name end
1162	def configure configuration = { :options => { :verbose => false , :coloring => 'AUTO' } , :mount => { :source => { :name => nil } , :mountpoint => { :name => nil } , :passphrasefile => { :name => 'passphrase' } , :keyfile => { :name => 'encfs6.xml' } , :cmd => nil , :executable => nil } , :unmount => { :mountpoint => { :name => nil } , :cmd => nil , :executable => nil } , :copy => { :source => { :name => nil } , :destination => { :name => nil } , :cmd => nil , :executable => nil } } config = @options [ :config ] unless config config = [ File . join ( @working_dir , "revenc.conf" ) , File . join ( @working_dir , ".revenc.conf" ) , File . join ( @working_dir , "config" , "revenc.conf" ) , File . expand_path ( File . join ( "~" , ".revenc.conf" ) ) ] . detect { | filename | File . exists? ( filename ) } end if config && File . exists? ( config ) @options [ :config ] = config config_contents = YAML :: load ( File . open ( config ) ) configuration . merge! ( config_contents . symbolize_keys! ) if config_contents && config_contents . is_a? ( Hash ) else raise "config file not found" if @options [ :config ] end @options = configuration [ :options ] . merge! ( @options ) @options . symbolize_keys! @options [ :mount ] = configuration [ :mount ] . recursively_symbolize_keys! if configuration [ :mount ] @options [ :unmount ] = configuration [ :unmount ] . recursively_symbolize_keys! if configuration [ :unmount ] @options [ :copy ] = configuration [ :copy ] . recursively_symbolize_keys! if configuration [ :copy ] end
1163	def mark_new_entries ( response ) digests = summary_digests response . entries . each do | e | seen = digests . include? ( digest_for ( e ) ) e . instance_variable_set ( :@_seen , seen ) end response end
1164	def set_header_options ( curl ) summary = summary_for_feed unless summary . nil? curl . headers [ 'If-None-Match' ] = summary [ :etag ] unless summary [ :etag ] . nil? curl . headers [ 'If-Modified-Since' ] = summary [ :last_modified ] unless summary [ :last_modified ] . nil? end curl end
1165	def store_summary_to_backend ( feed , curl ) headers = HttpHeaders . new ( curl . header_str ) summary = { } summary . merge! ( :etag => headers . etag ) unless headers . etag . nil? summary . merge! ( :last_modified => headers . last_modified ) unless headers . last_modified . nil? new_digest_set = feed . entries . map do | e | digest_for ( e ) end new_digest_set = summary_for_feed [ :digests ] . unshift ( new_digest_set ) new_digest_set = new_digest_set [ 0 .. @options [ :retained_digest_size ] ] summary . merge! ( :digests => new_digest_set ) set_summary ( summary ) end
1166	def error_manager ( uri , response ) case response when Net :: HTTPSuccess then begin data = JSON . parse ( response . body ) rescue data = { } end data [ 'headers' ] = response . to_hash ( ) return data when Net :: HTTPBadRequest raise Ropenstack :: MalformedRequestError , response . body when Net :: HTTPNotFound raise Ropenstack :: NotFoundError , "URI: #{uri} \n" + response . body when Net :: HTTPUnauthorized raise Ropenstack :: UnauthorisedError , response . body else raise Ropenstack :: RopenstackError , response . body end end
1167	def do_request ( uri , request , manage_errors = true , timeout = 10 ) begin http = build_http ( uri , timeout ) if ( manage_errors ) return error_manager ( uri , http . request ( request ) ) else http . request ( request ) return { "Success" => true } end rescue Timeout :: Error raise Ropenstack :: TimeoutError , "It took longer than #{timeout} to connect to #{uri.to_s}" rescue Errno :: ECONNREFUSED raise Ropenstack :: TimeoutError , "It took longer than #{timeout} to connect to #{uri.to_s}" end end
1168	def get_request ( uri , token = nil , manage_errors = true ) request = Net :: HTTP :: Get . new ( uri . request_uri , initheader = build_headers ( token ) ) return do_request ( uri , request , manage_errors ) end
1169	def delete_request ( uri , token = nil , manage_errors = true ) request = Net :: HTTP :: Delete . new ( uri . request_uri , initheader = build_headers ( token ) ) return do_request ( uri , request , manage_errors ) end
1170	def put_request ( uri , body , token = nil , manage_errors = true ) request = Net :: HTTP :: Put . new ( uri . request_uri , initheader = build_headers ( token ) ) request . body = body . to_json return do_request ( uri , request , manage_errors ) end
1171	def post_request ( uri , body , token = nil , manage_errors = true ) request = Net :: HTTP :: Post . new ( uri . request_uri , initheader = build_headers ( token ) ) request . body = body . to_json return do_request ( uri , request , manage_errors ) end
1172	def article ( id ) url = index . knowledgeManagement . articles . article url = url ( url , ArticleID : id ) decorate ( get ( url ) . body ) { | o | autodefine ( o ) } end
1173	def upload_image_from_file ( name , disk_format , container_format , minDisk , minRam , is_public , file ) data = { "name" => name , "disk_format" => disk_format , "container_format" => container_format , "minDisk" => minDisk , "minRam" => minRam , "public" => is_public } imagesBefore = images ( ) post_request ( address ( "images" ) , data , @token , false ) imagesAfter = images ( ) foundNewImage = true image = nil imagesAfter . each do | imageA | imagesBefore . each do | imageB | if ( imageA == imageB ) foundNewImage = false end end if ( foundNewImage ) image = imageA break end end return put_octect ( address ( image [ "file" ] ) , file . read , false ) end
1174	def put_octect ( uri , data , manage_errors ) headers = build_headers ( @token ) headers [ "Content-Type" ] = 'application/octet-stream' req = Net :: HTTP :: Put . new ( uri . request_uri , initheader = headers ) req . body = data return do_request ( uri , req , manage_errors , 0 ) end
1175	def relative_path ( path ) path = File . expand_path ( path ) root = full_path ( "" ) if path . size >= root . size && path [ 0 ... root . size ] == root path [ 0 ... root . size ] = "" path = "/" if path . size == 0 path end end
1176	def index ( path ) @entries = [ ] Dir . entries ( path ) . each do | entry | relative_path = relative_path ( File . join ( path , entry ) ) if entry != "." && relative_path @entries << { :name => entry , :href => relative_path } end end @path = path haml :index end
1177	def accessors_from_headers! raise "Can't define accessors from headers in a table without headers" unless @has_headers self . accessors = headers . map { | val | ( val && ! val . empty? ) ? val . to_s . downcase . tr ( '^a-z0-9_' , '_' ) . squeeze ( '_' ) . gsub ( / \A \z / , '' ) . to_sym : nil } end
1178	def << ( row ) index = @data . size begin row = row . to_ary rescue NoMethodError raise ArgumentError , "Row must be provided as Array or respond to `to_ary`, but got #{row.class} in row #{index}" unless row . respond_to? ( :to_ary ) raise end raise InvalidColumnCount . new ( index , row . size , column_count ) if @data . first && row . size != @data . first . size @data << row @rows << Row . new ( self , index , row ) self end
1179	def html ( id , time ) inline_footnote_label = Build . tag ( "span" , Build . tag ( "sup" , id . to_s ) , :class => "inline-footnote-number" ) Build . tag ( "a" , inline_footnote_label , :href => "#footnote#{id}#{time}" ) end
1180	def footnote_html ( id , time ) footnote_label = Build . tag ( "span" , Build . tag ( "sup" , id . to_s ) , :class => "footnote-number" ) footnote_content = sequence . elements . map { | s | s . html } . join Build . tag ( "div" , footnote_label + footnote_content , :id => "footnote#{id}#{time}" , :class => "footnote" ) end
1181	def instance_action ( id , action , param ) case action when "RESTART" post_request ( address ( "/instances/" + id + "/action" ) , { :restart => { } } , @token ) when "RESIZE" if param . is_a? String post_request ( address ( "/instances/" + id + "/action" ) , { :resize => { :flavorRef => param } } , @token ) elsif param . is_a? Int post_request ( address ( "/instances/" + id + "/action" ) , { :resize => { :volume => { :size => param } } } , @token ) else raise Ropenstack :: RopenstackError , "Invalid Parameter Passed" end else raise Ropenstack :: RopenstackError , "Invalid Action Passed" end end
1182	def add ( error_on , message = "Unknown error" ) if error_on . is_a? ( Symbol ) error_on_str = error_on . to_s else error_on_str = underscore ( error_on . class . name ) end error_on_str = error_on_str . gsub ( / \/ / , '_' ) error_on_str = error_on_str . gsub ( / / , ' ' ) error_on_str = error_on_str . gsub ( / / , '' ) . strip @errors [ error_on_str ] ||= [ ] @errors [ error_on_str ] << message . to_s end
1183	def coords_of_neighbors ( x , y ) coords_of_neighbors = [ ] ( x - 1 ) . upto ( x + 1 ) . each do | neighbors_x | ( y - 1 ) . upto ( y + 1 ) . each do | neighbors_y | next if ( x == neighbors_x ) && ( y == neighbors_y ) coords_of_neighbors << [ neighbors_x , neighbors_y ] end end coords_of_neighbors end
1184	def merchant ( id , options = { } ) options = update_by_expire_time options if merchant_not_latest? ( id ) @rsqoot_merchant = get ( "merchants/#{id}" , options , SqootMerchant ) @rsqoot_merchant = @rsqoot_merchant . merchant if @rsqoot_merchant end logger ( uri : sqoot_query_uri , records : [ @rsqoot_merchant ] , type : 'merchants' , opts : options ) @rsqoot_merchant end
1185	def encode data , opcode = TEXT_FRAME frame = [ ] frame << ( opcode | 0x80 ) packr = "CC" if opcode == TEXT_FRAME data . force_encoding ( "UTF-8" ) if ! data . valid_encoding? raise "Invalid UTF!" end end len = data ? data . bytesize : 0 if len <= 125 frame << ( len | 0x80 ) elsif len < 65536 frame << ( 126 | 0x80 ) frame << len packr << "n" else frame << ( 127 | 0x80 ) frame << len packr << "L!>" end key = rand ( 2 ** 31 ) frame << key packr << "N" len . times do | i | frame << ( ( data . getbyte ( i ) ^ ( key >> ( ( 3 - ( i % 4 ) ) * 8 ) ) ) & 0xFF ) end frame . pack ( "#{packr}C*" ) end
1186	def challah_permission unless included_modules . include? ( InstanceMethods ) include InstanceMethods extend ClassMethods end class_eval do validates_presence_of :name , :key validates_uniqueness_of :name , :key validates_format_of :key , :with => / / , :message => :invalid_key has_many :permission_roles , :dependent => :destroy has_many :roles , :through => :permission_roles , :order => 'roles.name' has_many :permission_users , :dependent => :destroy has_many :users , :through => :permission_users , :order => 'users.last_name, users.first_name' default_scope order ( 'permissions.name' ) attr_accessible :name , :description , :key , :locked after_create :add_to_admin_role end end
1187	def post hash = { } , payload raise 'Payload cannot be blank' if payload . nil? || payload . empty? hash . symbolize_keys! call ( :post , hash [ :endpoint ] , ( hash [ :args ] || { } ) . merge ( { :method => :post } ) , payload ) end
1188	def create_network ( name , tenant , admin_state_up = true ) data = { 'network' => { 'name' => name , 'tenant_id' => tenant , 'admin_state_up' => admin_state_up } } return post_request ( address ( "networks" ) , data , @token ) end
1189	def create_port ( network , subnet = nil , device = nil , device_owner = nil ) data = { 'port' => { 'network_id' => network , } } unless device_owner . nil? data [ 'port' ] [ 'device_owner' ] = device_owner end unless device . nil? data [ 'port' ] [ 'device_id' ] = device end unless subnet . nil? data [ 'port' ] [ 'fixed_ips' ] = [ { 'subnet_id' => subnet } ] end puts data return post_request ( address ( "ports" ) , data , @token ) end
1190	def move_port_to_subnets ( port_id , subnet_ids ) id_list = Array . new ( ) subnet_ids . each do | id | id_list << { "subnet_id" => id } end return update_port ( port_id , id_list ) end
1191	def json ( data = { } , options = { } ) response [ CONTENT_TYPE ] = APPLICATION_JSON response . status = options [ :status ] if options . has_key? ( :status ) response . write self . class . json_serializer . dump ( data ) end
1192	def redirect_to ( url , options = { } ) full_url = absolute_url ( url , options ) response [ LOCATION ] = full_url respond_with 302 full_url end
1193	def servers ( id ) endpoint = "/servers" unless id . nil? endpoint = endpoint + "/" + id end return get_request ( address ( endpoint ) , @token ) end
1194	def create_server ( name , image , flavor , networks = nil , keypair = nil , security_group = nil , metadata = nil ) data = { "server" => { "name" => name , "imageRef" => image , "flavorRef" => flavor , } } unless networks . nil? data [ "server" ] [ "networks" ] = networks end unless keypair . nil? data [ "server" ] [ "key_name" ] = keypair end unless security_group . nil? data [ "server" ] [ "security_group" ] = security_group end return post_request ( address ( "/servers" ) , data , @token ) end
1195	def action ( id , act , * args ) data = case act when "reboot" then { 'reboot' => { "type" => args [ 0 ] } } when "vnc" then { 'os-getVNCConsole' => { "type" => "novnc" } } when "stop" then { 'os-stop' => 'null' } when "start" then { 'os-start' => 'null' } when "pause" then { 'pause' => 'null' } when "unpause" then { 'unpause' => 'null' } when "suspend" then { 'suspend' => 'null' } when "resume" then { 'resume' => 'null' } when "create_image" then { 'createImage' => { 'name' => args [ 0 ] , 'metadata' => args [ 1 ] } } else raise "Invalid Action" end return post_request ( address ( "/servers/" + id + "/action" ) , data , @token ) end
1196	def delete_image ( id ) uri = URI . parse ( "http://" + @location . host + ":" + @location . port . to_s + "/v2/images/" + id ) return delete_request ( uri , @token ) end
1197	def get ( path , opts = { } , wrapper = :: Hashie :: Mash ) uri , headers = url_generator ( path , opts ) begin json = JSON . parse uri . open ( headers ) . read result = wrapper . new json @query_options = result . query result rescue => e logger ( error : e ) nil end end
1198	def set_basepath if self . parent . nil? self . basepath = self . basename self . basedirpath ||= '' else self . basepath = self . parent . basepath + '/' + self . basename self . basedirpath ||= self . parent . basepath + '/' end end
1199	def commissions ( options = { } ) options = update_by_expire_time options if commissions_not_latest? ( options ) @rsqoot_commissions = get ( 'commissions' , options , SqootCommission ) @rsqoot_commissions = @rsqoot_commissions . commissions if @rsqoot_commissions end logger ( uri : sqoot_query_uri , records : @rsqoot_commissions , type : 'commissions' , opts : options ) @rsqoot_commissions end
1200	def leagues ( opts = { } ) season = opts . fetch ( :season ) { Time . now . year } json_response get ( "competitions/?season=#{season}" ) end
1201	def match ( * args , & block ) z = Module . new do include Ov extend self def try ( * args , & block ) let :anon_method , * args , & block end def otherwise ( & block ) let :otherwise , & block end instance_eval & block end begin z . anon_method ( * args ) rescue Ov :: NotImplementError => e z . otherwise end end
1202	def fetch ( column , * default_value , & default_block ) raise ArgumentError , "Must only provide at max one default value or one default block" if default_value . size > ( block_given? ? 0 : 1 ) index = case column when Symbol then @table . index_for_accessor ( column ) when String then @table . index_for_header ( column ) when Integer then column else raise InvalidColumnSpecifier , "Invalid index type, expected Symbol, String or Integer, but got #{column.class}" end @data . fetch ( index , * default_value , & default_block ) end
1203	def at ( column ) case column when Symbol then at_accessor ( column ) when String then at_header ( column ) when Integer then at_index ( column ) when Range then @data [ column ] else raise InvalidColumnSpecifier , "Invalid index type, expected Symbol, String or Integer, but got #{column.class}" end end
1204	def values_at ( * columns ) result = [ ] columns . each do | column | data = at ( column ) if column . is_a? ( Range ) result . concat ( data ) if data else result << data end end result end
1205	def method_missing ( name , * args , & block ) return super unless @table . accessors? name =~ / \w / name_mod , assign = $1 , $2 index = @table . index_for_accessor ( name_mod ) arg_count = assign ? 1 : 0 return super unless index raise ArgumentError , "Wrong number of arguments (#{args.size} for #{arg_count})" if args . size > arg_count if assign then @data [ index ] = args . first else @data [ index ] end end
1206	def authorize ( auth = { } ) @authentication ||= TaskMapper :: Authenticator . new ( auth ) auth = @authentication if ( auth . account . nil? and auth . subdomain . nil? ) or auth . username . nil? or auth . password . nil? raise "Please provide at least an account (subdomain), username and password)" end UnfuddleAPI . protocol = auth . protocol if auth . protocol? UnfuddleAPI . account = auth . account || auth . subdomain UnfuddleAPI . authenticate ( auth . username , auth . password ) end
1207	def routers ( id = nil ) endpoint = "routers" unless id . nil? endpoint = endpoint + "/" + id end return get_request ( address ( endpoint ) , @token ) end
1208	def create_router ( name , admin_state_up = true ) data = { 'router' => { 'name' => name , 'admin_state_up' => admin_state_up , } } return post_request ( address ( "routers" ) , data , @token ) end
1209	def delete_router_interface ( router , id , type ) data = case type when 'port' then { 'port_id' => id } when 'subnet' then { 'subnet_id' => id } else raise "Invalid Interface Type" end return put_request ( address ( "routers/" + router + "/remove_router_interface" ) , data , @token ) end
1210	def where ( method ) @complete , @result = nil , nil z = find_or_next ( method ) { | method | self . find { | m | m . eql? ( method ) } } . find_or_next ( method ) { | method | self . find { | m | m . eql0? ( method ) } } . find_or_next ( method ) { | method | self . find { | m | m . like? ( method ) } } . find_or_next ( method ) { | method | self . find { | m | m . like0? ( method ) } } . get end
1211	def load config_files . each do | file | config = YAML :: load ( File . open ( file ) ) @config . merge! config end end
1212	def providers ( options = { } ) options = update_by_expire_time options query = options . delete ( :query ) if providers_not_latest? ( options ) @rsqoot_providers = get ( 'providers' , options , SqootProvider ) @rsqoot_providers = @rsqoot_providers . providers . map ( & :provider ) if @rsqoot_providers end result = query . present? ? query_providers ( query ) : @rsqoot_providers logger ( uri : sqoot_query_uri , records : result , type : 'providers' , opts : options ) result end
1213	def categories ( options = { } ) options = update_by_expire_time options query = options . delete ( :query ) if categories_not_latest? ( options ) @rsqoot_categories = get ( 'categories' , options , SqootCategory ) @rsqoot_categories = @rsqoot_categories . categories . map ( & :category ) if @rsqoot_categories end result = query . present? ? query_categories ( query ) : @rsqoot_categories logger ( uri : sqoot_query_uri , records : result , type : 'categories' , opts : options ) result end
1214	def challah_role unless included_modules . include? ( InstanceMethods ) include InstanceMethods extend ClassMethods end class_eval do validates :name , :presence => true , :uniqueness => true has_many :permission_roles , :dependent => :destroy has_many :permissions , :through => :permission_roles , :order => 'permissions.name' has_many :users , :order => 'users.first_name, users.last_name' default_scope order ( 'roles.name' ) after_save :save_permission_keys attr_accessible :description , :default_path , :locked , :name end end
1215	def check_for_upgrade if plan_id_changed? old_plan = Plan . find ( plan_id_was ) if plan_id_was . present? self . upgraded = true if old_plan . nil? || old_plan . order < plan . order end end
1216	def method_missing ( name , * args , & block ) obj = __getobj__ __substitute_self__ ( obj . __send__ ( name , * args , & block ) , obj ) end
1217	def deals ( options = { } ) options = update_by_expire_time options if deals_not_latest? ( options ) uniq = ! ! options . delete ( :uniq ) @rsqoot_deals = get ( 'deals' , options , SqootDeal ) || [ ] @rsqoot_deals = @rsqoot_deals . deals . map ( & :deal ) unless @rsqoot_deals . empty? @rsqoot_deals = uniq_deals ( @rsqoot_deals ) if uniq end logger ( uri : sqoot_query_uri , records : @rsqoot_deals , type : 'deals' , opts : options ) @rsqoot_deals end
1218	def deal ( id , options = { } ) options = update_by_expire_time options if deal_not_latest? ( id ) @rsqoot_deal = get ( "deals/#{id}" , options , SqootDeal ) @rsqoot_deal = @rsqoot_deal . deal if @rsqoot_deal end logger ( uri : sqoot_query_uri , records : [ @rsqoot_deal ] , type : 'deal' , opts : options ) @rsqoot_deal end
1219	def total_sqoot_deals ( options = { } ) @total_deals ||= [ ] @cached_pages ||= [ ] page = options [ :page ] || 1 check_query_change options unless page_cached? page @total_deals += deals ( options ) @total_deals . uniq! @cached_pages << page . to_s @cached_pages . uniq! end @total_deals end
1220	def uniq_deals ( deals = [ ] ) titles = deals . map ( & :title ) . uniq titles . map do | title | deals . map do | deal | deal if deal . try ( :title ) == title end . compact . last end . flatten end
1221	def load_cookies ( file ) now = :: Time . now io = case file when String open ( file ) else file end io . each_line do | line | line . chomp! line . gsub! ( / / , '' ) fields = line . split ( "\t" ) next if fields . length != 7 name , value , domain , for_domain , path , secure , version = fields [ 5 ] , fields [ 6 ] , fields [ 0 ] , ( fields [ 1 ] == "TRUE" ) , fields [ 2 ] , ( fields [ 3 ] == "TRUE" ) , 0 expires_seconds = fields [ 4 ] . to_i expires = ( expires_seconds == 0 ) ? nil : :: Time . at ( expires_seconds ) next if expires and ( expires < now ) cookies . add ( name , value , domain : domain , path : path , expires : expires , secure : secure ) end io . close if String === file self end
1222	def dump_cookies ( file ) io = case file when String open ( file , "w" ) else file end cookies . to_a . each do | cookie | io . puts ( [ cookie [ :domain ] , "FALSE" , cookie [ :path ] , cookie [ :secure ] ? "TRUE" : "FALSE" , cookie [ :expires ] . to_i . to_s , cookie [ :name ] , cookie [ :value ] ] . join ( "\t" ) ) end io . close if String === file self end
1223	def set2 ( selector , value = nil ) elem = element ( xpath : selector ) . to_subtype case elem when Watir :: Radio elem . set when Watir :: Select elem . select value when Watir :: Input elem . set value when Watir :: TextArea elem . set value else elem . click end end
1224	def update_by_expire_time ( options = { } ) @expired_in = options [ :expired_in ] if options [ :expired_in ] . present? time = Time . now . to_i / expired_in . to_i options . merge ( expired_in : time ) end
1225	def get ( options = { } ) uri = new_uri params = merge_params ( options ) uri . query = URI . encode_www_form ( params ) Net :: HTTP . start ( uri . host , uri . port , :use_ssl => uri . scheme == 'https' ) do | http | request = Net :: HTTP :: Get . new ( uri ) response = http . request ( request ) unless response . is_a? ( Net :: HTTPSuccess ) raise "#{response.code} #{response.message}\n#{response.body}" end return response . body end end
1226	def images ( id , tenant_id ) if id . nil? return get_request ( address ( tenant_id , "images/detail" ) , @token ) else return get_request ( address ( tenant_id , "images/" + id ) , @token ) end end
1227	def image_create ( name , disk_format , container_format , create_image , tenant_id ) data = { :name => name , :disk_format => disk_format , :container_format => container_format } unless create_image . nil? data [ :create_image ] = create_image end post_request ( address ( tenant_id , "images" ) , data , @token ) end
1228	def replace_memberships ( id , memberships , tenant_id ) data = { :memberships => memberships } put_request ( address ( tenant_id , "images/" + id + "/members" ) , data , @token ) end
1229	def add_member ( id , member_id , can_share , tenant_id ) if can_share . nil? data = { :member => { :can_share => false } } else data = { :member => { :can_share => can_share } } end put_request ( address ( tenant_id , "images/" + id + "/members/" + member_id ) , data , @token ) end
1230	def mkdir ( dir , owner : nil , mode : nil ) FileUtils . mkdir_p ( dir , verbose : verbose? ) chown ( dir , owner ) if owner chmod ( dir , mode ) if mode end
1231	def cp ( src , dst , mkdir : false , owner : nil , mode : nil ) mkdir_if_necessary ( File . dirname ( dst ) ) if mkdir FileUtils . cp_r ( src , dst , preserve : true , verbose : verbose? ) chown ( dst , owner ) if owner && ! File . symlink? ( dst ) chmod ( dst , mode ) if mode end
1232	def mv ( src , dst , mkdir : false ) mkdir_if_necessary ( File . dirname ( dst ) ) if mkdir FileUtils . mv ( src , dst , verbose : verbose? ) end
1233	def ln ( src , dst ) FileUtils . ln_sf ( src , dst , verbose : verbose? ) rescue Errno :: EEXIST => e raise e if ! ( File . symlink? ( dst ) && src == File . readlink ( dst ) ) end
1234	def chmod ( file , mode ) return if File . stat ( file ) . mode == mode FileUtils . chmod ( mode , file , verbose : verbose? ) end
1235	def rm_and_mkdir ( dir ) raise "don't do this" if dir == "" FileUtils . rm_rf ( dir , verbose : verbose? ) mkdir ( dir ) end
1236	def copy_metadata ( src , dst ) stat = File . stat ( src ) File . chmod ( stat . mode , dst ) File . utime ( stat . atime , stat . mtime , dst ) end
1237	def atomic_write ( path ) tmp = Tempfile . new ( File . basename ( path ) ) yield ( tmp ) tmp . close chmod ( tmp . path , 0o644 ) mv ( tmp . path , path ) ensure rm_if_necessary ( tmp . path ) end
1238	def handle_requests until @requestmq . empty? request = @requestmq . deq ( true ) begin request . response = @app . call ( request . env ) rescue Exception => e request . exception = e ensure body = request . response . try ( :last ) body . close if body . respond_to? :close end end end
1239	def configfile_hash config = { } begin json = File . read ( configfile ) config = JSON . parse ( json ) rescue Errno :: ENOENT @logger . debug "#{configfile} does not exist" @force_save = true rescue JSON :: ParserError @logger . debug "JSON parse error in #{configfile}" @force_save = true end config end
1240	def email_addresses ( text ) text . gsub ( @regex [ :mail ] ) do text = $& if auto_linked? ( $` , $' ) text else display_text = ( block_given? ) ? yield ( text ) : text "<a href='mailto:#{text}'>#{display_text}</a>" end end end
1241	def plural ( rule , replacement ) @uncountables . delete ( rule ) if rule . is_a? ( String ) @uncountables . delete ( replacement ) @plurals . insert ( 0 , [ rule , replacement ] ) end
1242	def singular ( rule , replacement ) @uncountables . delete ( rule ) if rule . is_a? ( String ) @uncountables . delete ( replacement ) @singulars . insert ( 0 , [ rule , replacement ] ) end
1243	def irregular ( singular , plural ) @uncountables . delete ( singular ) @uncountables . delete ( plural ) if singular [ 0 , 1 ] . upcase == plural [ 0 , 1 ] . upcase plural ( Regexp . new ( "(#{singular[0,1]})#{singular[1..-1]}$" , "i" ) , '\1' + plural [ 1 .. - 1 ] ) singular ( Regexp . new ( "(#{plural[0,1]})#{plural[1..-1]}$" , "i" ) , '\1' + singular [ 1 .. - 1 ] ) else plural ( Regexp . new ( "#{singular[0,1].upcase}(?i)#{singular[1..-1]}$" ) , plural [ 0 , 1 ] . upcase + plural [ 1 .. - 1 ] ) plural ( Regexp . new ( "#{singular[0,1].downcase}(?i)#{singular[1..-1]}$" ) , plural [ 0 , 1 ] . downcase + plural [ 1 .. - 1 ] ) singular ( Regexp . new ( "#{plural[0,1].upcase}(?i)#{plural[1..-1]}$" ) , singular [ 0 , 1 ] . upcase + singular [ 1 .. - 1 ] ) singular ( Regexp . new ( "#{plural[0,1].downcase}(?i)#{plural[1..-1]}$" ) , singular [ 0 , 1 ] . downcase + singular [ 1 .. - 1 ] ) end end
1244	def execute raise errors . to_sentences unless valid? result = false mutex = Mutagem :: Mutex . new ( 'revenc.lck' ) lock_successful = mutex . execute do result = system_cmd ( cmd ) end raise "action failed, lock file present" unless lock_successful result end
1245	def output opts = options if opts . format FileUtils . mkdir_p opts . output_dir formatted_output end @results . clear end
1246	def run while @jobs . length > 0 do @current_job = @jobs . pop @current_rate = @current_job . high_rate . to_i httperf true ( @current_job . low_rate . to_i .. @current_job . high_rate . to_i ) . step ( @current_job . rate_step . to_i ) do | rate | @current_rate = rate httperf end output end end
1247	def authenticate ( username , password , tenant = nil ) data = { "auth" => { "passwordCredentials" => { "username" => username , "password" => password } } } unless tenant . nil? data [ "auth" ] [ "tenantName" ] = tenant end @data = post_request ( address ( "/tokens" ) , data , @token ) end
1248	def add_to_services ( name , type , description ) data = { 'OS-KSADM:service' => { 'name' => name , 'type' => type , 'description' => description } } return post_request ( address ( "/OS-KSADM/services" ) , data , token ( ) ) end
1249	def add_endpoint ( region , service_id , publicurl , adminurl , internalurl ) data = { 'endpoint' => { 'region' => region , 'service_id' => service_id , 'publicurl' => publicurl , 'adminurl' => adminurl , 'internalurl' => internalurl } } return post_request ( address ( "/endpoints" ) , data , token ( ) ) end
1250	def get_endpoints ( token = nil ) if token . nil? return get_request ( address ( "/endpoints" ) , token ( ) ) else return get_request ( address ( "/tokens/#{token}/endpoints" ) , token ( ) ) end end
1251	def disable_method ( method_name , message = nil ) disabled_methods [ method_name ] ||= DisabledMethod . new ( self , method_name , message ) disabled_methods [ method_name ] . disable! end
1252	def to_proc disabled_method = self Proc . new do | * args , & block | disabled_method . execute ( self , * args , & block ) end end
1253	def execute ( object , * args , & block ) if disabled? raise NoMethodError , message else object . send ( aliased_name , * args , & block ) end end
1254	def alias_method! klass . send ( :define_method , replacement_name , & self ) klass . send ( :alias_method , aliased_name , method_name ) klass . send ( :alias_method , method_name , replacement_name ) end
1255	def secret_to_public ( secret , form = :byte ) publickey = p_secret_to_public ( change_argument_format ( secret , form ) ) return change_result_format ( publickey , form ) end
1256	def point_equal ( pa , pb ) return false if ( pa [ 0 ] * pb [ 2 ] - pb [ 0 ] * pa [ 2 ] ) % @@p != 0 return false if ( pa [ 1 ] * pb [ 2 ] - pb [ 1 ] * pa [ 2 ] ) % @@p != 0 return true end
1257	def recover_x ( y , sign ) return nil if y >= @@p x2 = ( y * y - 1 ) * modp_inv ( @@d * y * y + 1 ) if x2 . equal? 0 then unless sign . equal? 0 then return nil else return 0 end end x = pow_mod ( x2 , ( ( @@p + 3 ) / 8 ) , @@p ) x = x * @@modp_sqrt_m1 % @@p unless ( ( x * x - x2 ) % @@p ) . equal? 0 return nil unless ( ( x * x - x2 ) % @@p ) . equal? 0 x = @@p - x unless ( x & 1 ) . equal? sign return x end
1258	def point_decompress ( s ) raise ArgumentError , "Invalid input length for decompression" unless s . length . equal? 32 y = int_form_bytes ( s ) sign = y >> 255 y &= ( 1 << 255 ) - 1 x = recover_x ( y , sign ) if x . nil? then return nil else return [ x , y , 1 , x * y % @@p ] end end
1259	def p_secret_to_public ( secret ) expanded = secret_expand ( secret ) a = expanded . first return point_compress ( point_mul ( a , @@G ) ) end
1260	def part ( name ) parts . select { | p | p . name . downcase == name . to_s . downcase } . first end
